{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_autoencoder_classifier.ipynb_",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "of0wOmbU9pup"
      },
      "source": [
        "import torch \n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "import random\n",
        "import torch.autograd as autograd         \n",
        "from torch import Tensor                 \n",
        "import torch.nn as nn                     \n",
        "import torch.nn.functional as F           \n",
        "import torch.optim as optim               \n",
        "\n",
        "import torchvision\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.transforms as transforms  \n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt        "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8DyEebGA55S"
      },
      "source": [
        "import Models"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJgMEE03ioVN"
      },
      "source": [
        "import train \n",
        "import test\n",
        "from train import *\n",
        "from test import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV_sYpgehP4l",
        "outputId": "5c9d254c-8e70-4e94-962c-97200ab88bb3"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9uANps_EGn9"
      },
      "source": [
        "data_dir = 'dataset'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBF8kPae9qnl"
      },
      "source": [
        "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
        "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tM2iXYcMbcI"
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Set the train transform\n",
        "train_dataset.transform = train_transform\n",
        "# Set the test transform\n",
        "test_dataset.transform = test_transform"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsl3BgjpOq-6"
      },
      "source": [
        "m=len(train_dataset)\n",
        "\n",
        "#random_split randomly split a dataset into non-overlapping new datasets of given lengths\n",
        "#train (55,000 images), val split (5,000 images)\n",
        "train_data, val_data = torch.utils.data.random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
        "\n",
        "batch_size=256\n",
        "\n",
        "# The dataloaders handle shuffling, batching, etc...\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "GMBKRV05RAG6",
        "outputId": "0d045078-b438-4f22-c1f0-5409314f28a9"
      },
      "source": [
        "images, labels = iter(train_loader).next()\n",
        "img = images[0][0].numpy()\n",
        "print(labels[0])\n",
        "plt.imshow(img)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6b7caafd10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSMzBYybc-Tf"
      },
      "source": [
        "# model = Autoencoder(latent_space=8, mode='decoder').to(device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMBwn257gRlU",
        "outputId": "41efbfd6-391b-453a-82c2-f6daaeb404b7"
      },
      "source": [
        "model2 = Models.AutoEncoderClassifier(latent_space=8).to(device)\n",
        "print(model2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoEncoderClassifier(\n",
            "  (encoder): Encoder(\n",
            "    (encoder): Sequential(\n",
            "      (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "      (3): ReLU()\n",
            "      (4): Linear(in_features=64, out_features=16, bias=True)\n",
            "      (5): ReLU()\n",
            "      (6): Linear(in_features=16, out_features=8, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (decoder): Sequential(\n",
            "      (0): Linear(in_features=8, out_features=16, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=16, out_features=64, bias=True)\n",
            "      (3): ReLU()\n",
            "      (4): Linear(in_features=64, out_features=128, bias=True)\n",
            "      (5): ReLU()\n",
            "      (6): Linear(in_features=128, out_features=784, bias=True)\n",
            "      (7): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (clf): Classifier(\n",
            "    (classifier): Sequential(\n",
            "      (0): Linear(in_features=8, out_features=64, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "      (3): ReLU()\n",
            "      (4): Linear(in_features=32, out_features=10, bias=True)\n",
            "      (5): LogSoftmax(dim=1)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6CgMXd_SFLi",
        "outputId": "7e5b9be8-483b-45f4-ab20-cd3c5d1f9eae"
      },
      "source": [
        "for param in model2.named_parameters():\n",
        "  print(param)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('encoder.encoder.0.weight', Parameter containing:\n",
            "tensor([[ 0.0142,  0.0087, -0.0357,  ..., -0.0263,  0.0060,  0.0039],\n",
            "        [ 0.0103,  0.0356,  0.0210,  ..., -0.0140,  0.0240,  0.0322],\n",
            "        [-0.0054,  0.0077,  0.0088,  ...,  0.0332,  0.0337, -0.0311],\n",
            "        ...,\n",
            "        [ 0.0203,  0.0126, -0.0319,  ...,  0.0258, -0.0238, -0.0239],\n",
            "        [ 0.0003,  0.0206, -0.0031,  ...,  0.0236,  0.0008, -0.0047],\n",
            "        [-0.0162, -0.0195,  0.0143,  ...,  0.0134,  0.0330,  0.0240]],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.0.bias', Parameter containing:\n",
            "tensor([-0.0084, -0.0113, -0.0170, -0.0219,  0.0060,  0.0169, -0.0223, -0.0273,\n",
            "         0.0223, -0.0299,  0.0313,  0.0169, -0.0162, -0.0282, -0.0335,  0.0201,\n",
            "        -0.0035, -0.0142, -0.0044,  0.0101, -0.0175,  0.0226, -0.0234, -0.0144,\n",
            "        -0.0019,  0.0157, -0.0356, -0.0153, -0.0177,  0.0064, -0.0315,  0.0284,\n",
            "        -0.0048,  0.0353,  0.0223,  0.0347, -0.0211, -0.0033,  0.0098, -0.0297,\n",
            "        -0.0246,  0.0313,  0.0325,  0.0330, -0.0006,  0.0079, -0.0072,  0.0293,\n",
            "         0.0144,  0.0285,  0.0095, -0.0176, -0.0143, -0.0142,  0.0324,  0.0136,\n",
            "        -0.0195,  0.0309,  0.0065,  0.0040, -0.0140, -0.0157,  0.0347,  0.0349,\n",
            "        -0.0006,  0.0257,  0.0004, -0.0133, -0.0239,  0.0113, -0.0350,  0.0051,\n",
            "         0.0093, -0.0078,  0.0205,  0.0315, -0.0308,  0.0261,  0.0086,  0.0328,\n",
            "        -0.0276, -0.0257, -0.0239, -0.0056,  0.0192,  0.0107, -0.0355,  0.0082,\n",
            "        -0.0332,  0.0214, -0.0064, -0.0086,  0.0229,  0.0274,  0.0030, -0.0353,\n",
            "         0.0129, -0.0121, -0.0252,  0.0338,  0.0122,  0.0086,  0.0304,  0.0136,\n",
            "         0.0264,  0.0116,  0.0135, -0.0170, -0.0040,  0.0051,  0.0123, -0.0288,\n",
            "        -0.0322,  0.0353, -0.0160, -0.0213, -0.0242, -0.0144,  0.0080,  0.0193,\n",
            "         0.0280, -0.0353, -0.0062,  0.0021,  0.0070, -0.0024, -0.0028,  0.0302],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.2.weight', Parameter containing:\n",
            "tensor([[ 0.0573, -0.0717,  0.0032,  ..., -0.0180,  0.0086, -0.0329],\n",
            "        [-0.0444, -0.0152,  0.0809,  ...,  0.0151, -0.0688, -0.0733],\n",
            "        [ 0.0824, -0.0739,  0.0107,  ...,  0.0778,  0.0182,  0.0740],\n",
            "        ...,\n",
            "        [ 0.0418, -0.0476,  0.0814,  ...,  0.0456,  0.0797, -0.0641],\n",
            "        [ 0.0735,  0.0051, -0.0449,  ..., -0.0404, -0.0348, -0.0495],\n",
            "        [ 0.0546, -0.0222,  0.0880,  ..., -0.0567, -0.0399, -0.0860]],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.2.bias', Parameter containing:\n",
            "tensor([ 0.0813,  0.0538, -0.0701, -0.0884,  0.0051, -0.0830, -0.0515,  0.0472,\n",
            "        -0.0271, -0.0585,  0.0167, -0.0623,  0.0592, -0.0481,  0.0332, -0.0544,\n",
            "        -0.0777, -0.0129, -0.0324, -0.0567,  0.0697,  0.0186, -0.0550,  0.0399,\n",
            "        -0.0532,  0.0840,  0.0248, -0.0718,  0.0871,  0.0407, -0.0799, -0.0704,\n",
            "        -0.0775, -0.0149,  0.0306, -0.0367, -0.0362, -0.0754, -0.0844, -0.0835,\n",
            "        -0.0739, -0.0847, -0.0041, -0.0065, -0.0239, -0.0557,  0.0674, -0.0329,\n",
            "        -0.0132, -0.0442, -0.0333,  0.0038,  0.0401,  0.0857, -0.0287,  0.0646,\n",
            "         0.0554, -0.0433,  0.0131, -0.0765,  0.0485,  0.0293,  0.0147,  0.0121],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.4.weight', Parameter containing:\n",
            "tensor([[ 0.0690, -0.0392,  0.0489,  ..., -0.1121,  0.1208,  0.0287],\n",
            "        [-0.0550,  0.0455,  0.0412,  ..., -0.1149,  0.0773, -0.0012],\n",
            "        [-0.0433,  0.1038, -0.1045,  ..., -0.0245,  0.0475,  0.0792],\n",
            "        ...,\n",
            "        [ 0.1238,  0.1027,  0.0214,  ..., -0.0126, -0.0850,  0.0109],\n",
            "        [-0.0199,  0.0181,  0.0794,  ..., -0.0737,  0.1123,  0.0315],\n",
            "        [-0.0880,  0.0110, -0.0563,  ..., -0.0887,  0.0922, -0.0682]],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.4.bias', Parameter containing:\n",
            "tensor([-0.0320,  0.1235,  0.0440,  0.0265,  0.0890,  0.0738,  0.1038,  0.1086,\n",
            "        -0.0538, -0.0610, -0.1011, -0.0659,  0.0799,  0.0539,  0.0184, -0.0800],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.6.weight', Parameter containing:\n",
            "tensor([[-0.2412, -0.2218, -0.1851,  0.2040, -0.0464,  0.2396, -0.0589, -0.1470,\n",
            "          0.2457,  0.1845, -0.0896,  0.0228,  0.1773,  0.1110,  0.1350, -0.1003],\n",
            "        [-0.2429, -0.1641,  0.0836, -0.0656, -0.2247,  0.2397,  0.0370,  0.0361,\n",
            "          0.1060,  0.0559,  0.0713, -0.0534, -0.1394, -0.0436, -0.0677,  0.2219],\n",
            "        [-0.2100, -0.0429, -0.1750, -0.0940, -0.0075, -0.0959, -0.1761, -0.2197,\n",
            "         -0.2280, -0.0062,  0.1451, -0.2373, -0.0266,  0.1470, -0.0542, -0.1809],\n",
            "        [ 0.0377, -0.1373, -0.2372, -0.1009, -0.1067, -0.1509, -0.0318, -0.0750,\n",
            "          0.0854, -0.2051, -0.1027, -0.2183, -0.0192, -0.2305, -0.2146,  0.1277],\n",
            "        [-0.0924,  0.0582, -0.1198,  0.1455,  0.2333, -0.0617, -0.1145,  0.1152,\n",
            "         -0.2188, -0.1383, -0.2331, -0.2489,  0.0503, -0.1086, -0.2307,  0.1640],\n",
            "        [ 0.2159,  0.0202, -0.1187, -0.0104, -0.2125, -0.0456, -0.1068,  0.0828,\n",
            "         -0.2134,  0.1338,  0.0817,  0.1054, -0.2076, -0.1420, -0.0018,  0.1704],\n",
            "        [-0.2174, -0.1389,  0.0460, -0.1896, -0.0015,  0.0455, -0.1501,  0.0450,\n",
            "         -0.1144, -0.1010,  0.0163, -0.2345,  0.1664, -0.0420, -0.1509, -0.0245],\n",
            "        [-0.2129,  0.1162, -0.0622,  0.2321, -0.0099, -0.0426, -0.2052, -0.0694,\n",
            "         -0.1050,  0.0387, -0.2374, -0.0737, -0.1761,  0.0927,  0.1879, -0.0139]],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.6.bias', Parameter containing:\n",
            "tensor([-0.1864,  0.2484,  0.1480, -0.0089, -0.0140,  0.2379,  0.1212, -0.0041],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.0.weight', Parameter containing:\n",
            "tensor([[ 0.2947,  0.2790,  0.0704, -0.0705, -0.2642,  0.0314, -0.1386,  0.2802],\n",
            "        [-0.1611,  0.1065,  0.0410, -0.0159, -0.0407, -0.1560,  0.2110, -0.1585],\n",
            "        [ 0.3450, -0.0964,  0.1269, -0.1570,  0.0334,  0.1411, -0.3532, -0.1131],\n",
            "        [-0.2143,  0.0186,  0.2204, -0.0902, -0.2485, -0.0268,  0.2952, -0.1785],\n",
            "        [-0.0891, -0.0673,  0.3331, -0.0373,  0.0480,  0.1456, -0.3304,  0.3162],\n",
            "        [ 0.2080,  0.3378, -0.2645, -0.0028, -0.0380, -0.1611, -0.3106, -0.2822],\n",
            "        [-0.1540, -0.3044, -0.1516,  0.2460, -0.2568, -0.0376,  0.1860, -0.1637],\n",
            "        [-0.3340,  0.3503, -0.0845, -0.2862, -0.1143,  0.2438, -0.1532,  0.1003],\n",
            "        [ 0.0730, -0.0623, -0.1897,  0.1543, -0.2728, -0.0062,  0.2133,  0.2535],\n",
            "        [-0.0294,  0.0186, -0.1372, -0.0687, -0.1218,  0.0387, -0.1628, -0.2790],\n",
            "        [-0.1106,  0.2453,  0.1793,  0.3524,  0.2843, -0.0607,  0.1189,  0.1446],\n",
            "        [-0.1071, -0.3061, -0.2022, -0.0402,  0.1060,  0.1883, -0.1571,  0.0047],\n",
            "        [ 0.3254,  0.2449,  0.2803,  0.1071,  0.2049,  0.3148,  0.1045, -0.1768],\n",
            "        [ 0.3345,  0.2124, -0.0107, -0.1838, -0.3137, -0.1185,  0.1531,  0.0696],\n",
            "        [-0.2944,  0.0407,  0.3450,  0.1489, -0.3144,  0.1724,  0.0310,  0.2292],\n",
            "        [ 0.0540,  0.0450,  0.2552,  0.3056,  0.1389,  0.0248, -0.1447,  0.0168]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.0.bias', Parameter containing:\n",
            "tensor([-0.0062,  0.1833, -0.2392, -0.0385, -0.0621, -0.2033,  0.2760,  0.1489,\n",
            "         0.0630,  0.0841,  0.1915,  0.1953, -0.1487, -0.1080, -0.2690,  0.3456],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.2.weight', Parameter containing:\n",
            "tensor([[ 0.1883,  0.1617,  0.2382,  ..., -0.0568, -0.1502,  0.2364],\n",
            "        [-0.2297,  0.1824, -0.0724,  ..., -0.0726,  0.2185,  0.1890],\n",
            "        [ 0.2482, -0.1918, -0.2087,  ..., -0.0194, -0.0967, -0.1679],\n",
            "        ...,\n",
            "        [ 0.1173, -0.1391, -0.1635,  ...,  0.2332,  0.2129, -0.2093],\n",
            "        [-0.2164,  0.1750, -0.1110,  ...,  0.1037,  0.0968, -0.1877],\n",
            "        [ 0.1189, -0.1306,  0.0801,  ...,  0.1061,  0.1330,  0.0637]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.2.bias', Parameter containing:\n",
            "tensor([-0.0677, -0.0578,  0.0792,  0.0608, -0.1106,  0.2403,  0.2361,  0.0433,\n",
            "        -0.2393,  0.1699, -0.2115,  0.1779,  0.1781,  0.1873, -0.0292,  0.0556,\n",
            "        -0.1620, -0.2387, -0.1173,  0.0621, -0.0072, -0.2447, -0.1663, -0.1836,\n",
            "         0.0790, -0.1138,  0.1059, -0.0483, -0.0213,  0.0715, -0.1446, -0.2352,\n",
            "         0.2056,  0.1724,  0.2153, -0.0224, -0.1625,  0.0615,  0.0680, -0.1536,\n",
            "        -0.2008,  0.0507,  0.1264, -0.0183,  0.2054, -0.0027, -0.0555,  0.2016,\n",
            "         0.1291,  0.0656,  0.1591, -0.1274,  0.1895, -0.0983, -0.0135,  0.2475,\n",
            "         0.2248, -0.1793,  0.1793,  0.0480,  0.0809, -0.0337, -0.0160,  0.2054],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.4.weight', Parameter containing:\n",
            "tensor([[ 0.0159,  0.0026, -0.0059,  ..., -0.0384,  0.0924,  0.1119],\n",
            "        [ 0.1120, -0.1236,  0.0056,  ...,  0.0379,  0.1002,  0.0485],\n",
            "        [-0.0112, -0.0080, -0.0408,  ..., -0.0292, -0.0153, -0.0081],\n",
            "        ...,\n",
            "        [-0.0320, -0.0276, -0.0387,  ...,  0.1056,  0.0285,  0.0010],\n",
            "        [-0.0826, -0.0812, -0.0731,  ..., -0.0274, -0.0613, -0.0296],\n",
            "        [ 0.0680,  0.0354,  0.0327,  ..., -0.0872,  0.0859, -0.0795]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.4.bias', Parameter containing:\n",
            "tensor([-0.1013,  0.0486, -0.0296,  0.0513,  0.0425,  0.0073, -0.0995,  0.0085,\n",
            "        -0.0075,  0.0697, -0.0116,  0.0051, -0.0872,  0.0542,  0.0896, -0.0805,\n",
            "        -0.0418, -0.0760, -0.0817, -0.0411,  0.0920,  0.1041, -0.0439,  0.0483,\n",
            "         0.1086,  0.1000,  0.0227,  0.0689,  0.1082, -0.0717, -0.1105,  0.0739,\n",
            "        -0.0538,  0.1137, -0.0767, -0.0370,  0.0535,  0.1090,  0.0957, -0.1066,\n",
            "        -0.0238, -0.0548, -0.0970, -0.0840,  0.0242, -0.0403,  0.0572, -0.0047,\n",
            "        -0.0037, -0.0203, -0.0005, -0.0734,  0.0093,  0.0066, -0.1220,  0.1143,\n",
            "         0.1180,  0.0928, -0.0911,  0.0605,  0.0580,  0.0106, -0.1168, -0.0652,\n",
            "         0.0722, -0.1047,  0.0251, -0.0995, -0.0549,  0.1002,  0.0044, -0.0605,\n",
            "         0.0780, -0.0458, -0.0252, -0.0170, -0.0333,  0.0321, -0.0816, -0.0632,\n",
            "        -0.0762,  0.0602,  0.0292,  0.0457, -0.0817,  0.0648,  0.1055, -0.0772,\n",
            "        -0.0362,  0.0663, -0.0068,  0.1024, -0.0653,  0.1100, -0.1025, -0.0132,\n",
            "         0.1002,  0.1043, -0.0786, -0.0845, -0.0173,  0.0613, -0.0649,  0.0731,\n",
            "        -0.0383, -0.0603,  0.0720, -0.0504, -0.1035,  0.0678,  0.1180,  0.0514,\n",
            "        -0.0183,  0.0149, -0.0630, -0.0997,  0.0664, -0.0839,  0.0627, -0.0952,\n",
            "        -0.0708,  0.1185,  0.0717, -0.0833, -0.0389, -0.0392, -0.1234,  0.0180],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.6.weight', Parameter containing:\n",
            "tensor([[ 0.0312, -0.0012,  0.0287,  ..., -0.0787, -0.0137, -0.0624],\n",
            "        [ 0.0197, -0.0719,  0.0666,  ...,  0.0102,  0.0504, -0.0718],\n",
            "        [-0.0121,  0.0655,  0.0801,  ..., -0.0454,  0.0828,  0.0412],\n",
            "        ...,\n",
            "        [-0.0685,  0.0216, -0.0622,  ...,  0.0195,  0.0858,  0.0287],\n",
            "        [-0.0359,  0.0651, -0.0490,  ..., -0.0501, -0.0761,  0.0100],\n",
            "        [ 0.0234, -0.0057, -0.0773,  ..., -0.0087,  0.0095, -0.0568]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.6.bias', Parameter containing:\n",
            "tensor([ 3.2761e-02,  2.9048e-02,  1.6362e-02, -2.3731e-02, -5.0221e-02,\n",
            "         6.6651e-03,  4.6062e-02, -6.7329e-02, -3.3184e-02, -4.2496e-03,\n",
            "         7.2045e-02, -2.1812e-03, -8.7918e-02,  7.3278e-02,  2.6553e-02,\n",
            "        -4.6131e-02,  8.6418e-02, -5.0459e-02, -5.6809e-02, -3.3512e-02,\n",
            "        -1.3314e-02,  8.4449e-02, -7.2025e-02,  2.2067e-02, -6.0797e-02,\n",
            "        -4.4795e-02, -6.8605e-02, -3.3206e-02, -1.2214e-02,  6.0249e-02,\n",
            "         2.8759e-02, -4.0932e-02, -2.3458e-02, -4.3371e-02, -5.3463e-02,\n",
            "        -5.8814e-02, -5.4742e-04, -5.8795e-02,  3.7072e-02, -5.8351e-02,\n",
            "         6.4834e-02, -5.6515e-02, -1.2523e-03,  4.9541e-02,  9.2758e-03,\n",
            "        -1.7825e-03, -8.1011e-02, -4.6235e-03,  3.1952e-02,  8.6611e-02,\n",
            "        -7.8927e-03,  4.1432e-03,  1.5951e-02, -6.4109e-02, -5.4281e-02,\n",
            "        -4.3501e-02,  6.2967e-02, -8.1402e-02,  3.3763e-02, -2.1747e-02,\n",
            "         2.7756e-02, -6.6751e-03, -3.2764e-02,  7.4815e-02,  2.5435e-02,\n",
            "        -4.7506e-02,  8.8169e-03,  3.2638e-02,  2.9173e-02, -9.8346e-03,\n",
            "         3.9409e-02,  4.8115e-02, -1.7380e-03, -5.9489e-03, -6.7561e-02,\n",
            "        -3.6499e-02, -5.0793e-02, -7.7345e-02,  1.9956e-02,  7.6440e-03,\n",
            "        -5.8534e-02, -3.4803e-02, -4.3824e-02, -3.9613e-02,  7.4899e-02,\n",
            "         3.1277e-02,  5.7708e-02, -2.8883e-02,  6.9099e-02,  8.0509e-02,\n",
            "         9.0445e-03, -7.7591e-02, -2.8343e-02,  1.1152e-02, -1.8912e-02,\n",
            "        -4.1393e-02, -6.1312e-02,  3.9316e-02, -2.5513e-02, -6.7168e-02,\n",
            "         3.7832e-02, -6.7893e-02, -3.2358e-02, -8.8352e-02,  7.1780e-02,\n",
            "        -5.5010e-02, -5.7669e-02,  8.3184e-02, -5.0338e-02, -7.0811e-02,\n",
            "         1.8895e-02, -1.2179e-02,  2.8634e-02,  6.9994e-02,  4.6842e-03,\n",
            "         3.3376e-02, -3.0286e-02, -3.4356e-02,  5.3128e-02, -2.7416e-03,\n",
            "         4.1912e-02, -2.1977e-02, -5.9548e-02,  5.3912e-02,  5.9415e-02,\n",
            "        -5.4825e-02, -8.6842e-02,  6.9118e-03,  3.6620e-02, -6.9040e-02,\n",
            "         6.1291e-02,  5.6833e-02, -7.9629e-02, -2.0399e-02,  3.8831e-03,\n",
            "        -4.7877e-02, -6.3405e-02, -4.9157e-02,  1.0304e-03,  3.8893e-03,\n",
            "        -5.4973e-02, -1.2169e-02,  3.0993e-02, -2.1281e-02,  7.0523e-02,\n",
            "         8.0318e-02, -1.7241e-02, -1.9769e-03, -1.7825e-02, -3.4417e-02,\n",
            "        -3.2657e-02,  3.0389e-02,  1.6121e-02, -8.6266e-02, -8.0087e-03,\n",
            "         2.0026e-02, -3.4437e-02, -2.1559e-02, -8.1832e-03, -3.8859e-02,\n",
            "        -8.8351e-02, -7.6899e-02,  8.3030e-02,  7.5566e-02, -1.9223e-03,\n",
            "         6.3647e-03, -6.5164e-02,  7.7565e-02,  3.3780e-02,  3.1409e-02,\n",
            "         3.6441e-02,  7.7580e-02, -1.0871e-02, -7.9084e-02,  7.0127e-02,\n",
            "        -5.4890e-02, -3.0761e-02, -3.1846e-02, -2.6548e-03, -1.8771e-02,\n",
            "        -4.9558e-02, -7.0151e-02,  8.8334e-02,  2.1857e-03, -7.9334e-03,\n",
            "         3.3849e-02,  6.2344e-02, -8.5499e-02, -6.7147e-02,  7.9650e-03,\n",
            "        -5.5640e-02,  1.3443e-02, -7.6880e-02,  5.0058e-02,  5.6635e-02,\n",
            "         3.5707e-02,  2.1786e-02,  8.0149e-02,  1.7214e-02, -6.0006e-02,\n",
            "        -1.3247e-02,  7.1609e-03, -1.4491e-03,  9.1196e-04,  8.0196e-02,\n",
            "         6.2405e-02,  5.5416e-02,  4.0803e-02, -4.4551e-02, -7.1529e-02,\n",
            "        -3.9210e-02, -9.6634e-03, -5.9208e-02, -4.3995e-02,  5.9634e-02,\n",
            "        -6.1871e-02, -4.8178e-02,  3.9334e-02, -1.4866e-02,  5.7450e-02,\n",
            "        -7.6900e-02, -5.6421e-02, -8.6762e-02,  7.6952e-02, -7.9665e-02,\n",
            "        -7.8920e-03,  7.2689e-02, -7.4755e-02, -5.7263e-02, -3.9939e-02,\n",
            "         4.4703e-02,  5.1225e-02, -6.1639e-02, -6.2737e-02,  6.9173e-02,\n",
            "         5.7922e-03, -7.0613e-02,  5.9120e-02, -6.8789e-02,  2.2703e-02,\n",
            "        -7.3512e-02,  1.9677e-02,  1.6055e-02, -8.4311e-02, -5.0772e-02,\n",
            "        -5.8830e-02,  2.3528e-02, -3.0949e-02, -4.2829e-02, -7.3992e-02,\n",
            "        -6.4612e-02,  3.7884e-03,  2.7920e-02, -9.1802e-03,  5.6255e-02,\n",
            "         5.9078e-02,  4.5872e-02, -3.1256e-02, -1.4163e-02,  1.2417e-02,\n",
            "        -7.7037e-02, -5.9222e-02, -5.2084e-02, -7.3975e-02,  5.7204e-02,\n",
            "         5.8708e-02, -3.9153e-02, -6.1720e-02,  1.8180e-02,  4.8464e-02,\n",
            "        -6.6172e-03, -2.9807e-02, -2.7271e-02,  8.3515e-02,  8.5087e-02,\n",
            "        -2.0491e-02,  6.2284e-03,  4.9990e-02, -1.2681e-03, -6.4207e-02,\n",
            "        -8.7843e-02,  6.5900e-02, -6.8866e-02, -6.5246e-02, -4.5969e-02,\n",
            "         3.0532e-02,  2.2094e-02, -1.2093e-02,  8.3471e-02, -2.0765e-02,\n",
            "         5.7629e-02, -2.7854e-02, -2.2400e-02, -8.5168e-02, -2.8940e-02,\n",
            "        -2.5204e-02, -6.1881e-02, -2.7604e-02, -2.9782e-02, -1.7567e-02,\n",
            "        -7.2036e-02, -9.6049e-03, -7.5252e-02, -6.1021e-02,  2.2052e-02,\n",
            "         7.3096e-03,  5.7491e-03, -4.1993e-02, -7.2554e-02, -6.2478e-02,\n",
            "         2.6820e-03, -6.1848e-02, -3.9827e-02, -3.4244e-02,  6.9135e-02,\n",
            "        -8.6984e-02,  2.8760e-02, -6.6109e-02,  2.9091e-02, -4.8032e-02,\n",
            "         8.6795e-02, -8.2121e-04,  3.8512e-02, -3.6359e-02, -1.3881e-02,\n",
            "         2.5226e-02, -2.0908e-02,  8.0108e-02,  6.7134e-02, -6.8425e-02,\n",
            "         7.9800e-02,  3.7088e-02,  1.4248e-02,  2.5163e-02,  2.6620e-03,\n",
            "        -3.5811e-02, -4.7246e-02, -6.3725e-02, -6.9806e-02, -6.7065e-02,\n",
            "        -7.3142e-02, -7.9143e-02, -6.1019e-02, -5.0704e-02,  4.9646e-02,\n",
            "         5.6701e-02, -3.5365e-02, -3.0092e-03, -6.4261e-02,  2.0957e-02,\n",
            "        -7.0317e-02, -6.1582e-02, -1.3436e-02,  2.1165e-02, -3.2343e-02,\n",
            "         2.1419e-02,  6.7237e-02, -5.9372e-02, -5.4327e-02, -4.3690e-02,\n",
            "        -1.2282e-02,  2.5114e-02, -4.4934e-02, -7.4955e-02, -4.3740e-02,\n",
            "        -4.8641e-02, -6.2528e-03, -6.7091e-02, -6.4646e-03, -3.0732e-03,\n",
            "         7.8888e-02, -6.3235e-02,  5.0943e-02,  1.4993e-03,  5.7383e-02,\n",
            "         2.2268e-02,  3.8931e-02, -1.6344e-02, -6.2046e-02, -3.6279e-03,\n",
            "        -2.1158e-02,  3.8421e-02, -3.0041e-02, -2.5212e-02,  3.6336e-02,\n",
            "         1.9400e-02,  4.4411e-02,  4.4399e-02, -2.0482e-02,  5.3247e-02,\n",
            "        -6.1889e-02, -6.4457e-03, -2.0596e-02,  2.3089e-02,  5.8569e-02,\n",
            "        -1.4289e-02, -6.1777e-02,  7.3147e-02,  1.8353e-02,  8.5355e-02,\n",
            "        -3.8125e-04,  5.1676e-03,  7.3977e-03,  2.9768e-02,  5.3388e-02,\n",
            "         1.9253e-04, -7.1546e-02, -8.5052e-02, -2.7149e-02,  8.6743e-02,\n",
            "        -5.2939e-02,  8.0885e-02,  3.2370e-02,  7.5890e-02,  9.9563e-03,\n",
            "         2.7249e-02,  8.2587e-02,  4.9578e-02, -3.7737e-02,  4.0531e-02,\n",
            "        -8.8339e-03,  7.5662e-03, -2.5428e-02,  3.9613e-02, -3.6609e-02,\n",
            "         5.7765e-02, -5.0682e-02,  1.9831e-02,  1.2796e-02, -6.5800e-02,\n",
            "         2.2159e-02,  2.4585e-02, -2.5839e-02, -3.6935e-02,  2.7618e-02,\n",
            "        -3.0314e-03, -3.3522e-02,  6.3421e-02, -2.6091e-03, -4.4832e-02,\n",
            "         7.0769e-02, -8.3194e-02, -1.3830e-02,  7.5027e-02,  7.3620e-03,\n",
            "        -5.7204e-02,  8.0935e-02,  4.1088e-02, -7.3450e-02,  7.0446e-02,\n",
            "        -7.7395e-02, -2.2316e-02,  2.5773e-02,  1.3538e-02, -1.7408e-02,\n",
            "         6.2187e-02, -6.8460e-02,  3.3906e-02, -3.2847e-02, -1.7060e-02,\n",
            "        -2.0259e-02,  6.4351e-02,  6.7636e-02,  4.6136e-02,  5.3075e-02,\n",
            "        -3.8052e-03, -7.1589e-02, -2.0294e-02, -1.7663e-02,  1.2553e-02,\n",
            "        -4.5173e-02,  5.2374e-02,  5.3910e-02, -6.1004e-02,  8.1211e-02,\n",
            "        -7.2472e-03,  6.1157e-02,  4.8754e-02,  7.6642e-02,  7.9633e-02,\n",
            "         2.5726e-02,  5.8445e-02, -8.8029e-02, -2.4626e-02,  2.0616e-02,\n",
            "        -2.8501e-03,  3.1396e-02, -6.9192e-02,  5.9434e-02, -5.5668e-02,\n",
            "         7.6738e-02,  8.0725e-02,  6.3528e-04,  3.2221e-04, -5.5014e-02,\n",
            "        -5.9706e-02, -4.5144e-02, -7.2898e-02,  8.0464e-02, -4.0255e-02,\n",
            "         8.6804e-02, -2.3707e-02,  4.3123e-02,  4.2713e-02, -1.1945e-02,\n",
            "        -8.0252e-02, -8.0743e-04,  7.4368e-02,  8.6785e-02,  1.4436e-02,\n",
            "        -1.9916e-02,  2.4967e-02,  2.5454e-02, -8.6261e-02, -4.4418e-03,\n",
            "         1.8220e-02,  5.4287e-02, -3.3765e-02, -3.6698e-02, -6.5043e-02,\n",
            "         5.9226e-02,  7.9110e-02, -7.4005e-02,  3.7422e-02,  2.5442e-02,\n",
            "        -3.0582e-02, -8.9709e-03,  8.3618e-03, -4.7238e-02, -7.9869e-02,\n",
            "         1.5842e-02, -1.0935e-02,  7.9790e-02, -1.0796e-02, -1.6543e-04,\n",
            "        -4.1528e-02, -5.4513e-02, -3.2482e-02, -4.1217e-02,  2.7555e-02,\n",
            "         8.4869e-03,  9.7832e-03,  8.5015e-02,  1.2381e-02, -1.5886e-02,\n",
            "        -7.1394e-03,  5.1134e-02,  5.7048e-02,  4.0512e-02,  3.7142e-02,\n",
            "         2.5361e-02,  6.6633e-02, -4.2505e-02,  4.3827e-02,  7.6611e-02,\n",
            "         6.4031e-02,  5.0049e-02,  4.1541e-02, -2.3536e-04, -4.1992e-02,\n",
            "        -1.1910e-02, -2.1581e-02, -7.8476e-02,  8.0924e-02,  5.7193e-02,\n",
            "         1.3987e-02,  1.3151e-03, -8.4912e-04,  6.4073e-02, -3.8844e-02,\n",
            "         3.5120e-02, -6.6399e-02,  7.1936e-02,  3.7756e-02, -8.5658e-02,\n",
            "        -1.1376e-02, -3.8668e-02, -7.5712e-02, -6.6483e-02,  8.0601e-02,\n",
            "         2.7582e-02, -7.2188e-02, -8.0552e-02, -8.5298e-03, -9.6415e-03,\n",
            "        -6.0603e-02,  2.9299e-02,  4.7732e-02, -6.4200e-02, -6.3032e-02,\n",
            "        -3.7841e-02,  8.1666e-02,  6.6237e-03, -4.6557e-02, -8.3158e-02,\n",
            "         6.9398e-04, -4.8681e-02, -2.6859e-03, -5.6256e-02, -5.3768e-02,\n",
            "        -2.1524e-02,  7.1784e-02, -5.0941e-02, -5.9531e-02, -4.8781e-02,\n",
            "        -8.7731e-03,  8.8219e-02, -7.8865e-02,  4.3482e-03, -8.3639e-02,\n",
            "         3.6044e-02,  3.0922e-02, -3.6654e-02,  6.4722e-02, -8.7685e-03,\n",
            "        -1.2500e-02,  7.9723e-02, -5.7057e-02,  6.5013e-02,  1.5165e-02,\n",
            "         8.2490e-02, -9.4339e-03,  4.9393e-02, -8.6323e-02, -3.8882e-02,\n",
            "         3.3221e-03,  9.6467e-04, -4.1161e-02, -2.6060e-02, -4.3089e-02,\n",
            "         2.7047e-02,  3.2176e-02,  2.9564e-02,  3.0681e-02,  7.0104e-02,\n",
            "         3.0514e-02,  3.7313e-02, -3.3027e-02,  8.2180e-02, -5.4798e-02,\n",
            "         1.9735e-02, -7.7251e-03, -7.1951e-02, -6.4267e-02,  1.6623e-02,\n",
            "        -6.1094e-02, -5.3759e-02,  2.4831e-02,  8.2797e-02,  7.3100e-02,\n",
            "         6.5076e-04,  5.5181e-02,  4.1787e-03,  4.3949e-02, -6.3763e-02,\n",
            "         2.1401e-02, -8.4522e-02,  6.9901e-03,  1.8815e-02,  6.9676e-02,\n",
            "        -4.3377e-02, -6.0236e-02, -1.3669e-02,  5.7662e-04, -6.5730e-02,\n",
            "         8.1351e-02,  2.8065e-02, -2.7158e-02,  4.8606e-03,  1.5524e-02,\n",
            "        -7.8764e-02, -4.9628e-02,  4.6319e-02, -5.8176e-02, -6.4541e-02,\n",
            "         8.3319e-02,  8.9466e-03, -5.7539e-02, -5.3421e-02, -7.6882e-02,\n",
            "        -1.8255e-02,  6.8745e-02, -7.0571e-02,  1.0664e-03,  1.1869e-02,\n",
            "        -2.6390e-02, -3.9872e-02, -7.7143e-02, -3.9717e-02,  3.1062e-02,\n",
            "        -4.4768e-02,  1.5096e-02, -4.3319e-02, -6.2425e-02,  7.9911e-02,\n",
            "         7.2607e-02, -7.5590e-02,  3.2857e-02, -2.3608e-02, -3.7818e-02,\n",
            "        -5.2324e-02, -5.3756e-02,  7.6902e-02, -7.3943e-02, -4.2073e-02,\n",
            "         2.9255e-02, -2.8723e-02, -7.1200e-02,  5.1634e-02,  1.5672e-02,\n",
            "         4.8364e-02,  4.4767e-02, -5.0455e-03, -5.7831e-02, -6.8332e-02,\n",
            "        -7.5418e-02, -4.6627e-02, -1.7501e-02,  2.6726e-02,  1.7102e-02,\n",
            "         4.0342e-02,  5.1243e-02,  8.0668e-02,  4.1852e-02, -4.5623e-02,\n",
            "        -6.5439e-02, -2.9480e-02, -6.8787e-02, -5.6062e-02, -8.1820e-02,\n",
            "        -3.4412e-02,  8.6875e-03, -1.1943e-02, -2.0653e-02, -7.1117e-03,\n",
            "        -3.8670e-05, -1.7985e-02, -1.2209e-02,  3.2835e-02,  5.3700e-02,\n",
            "         2.8008e-02, -5.2482e-02,  4.2398e-02,  8.6753e-02, -8.1152e-02,\n",
            "        -4.6371e-03, -1.7025e-02, -6.6967e-02, -6.2681e-02, -2.8033e-02,\n",
            "        -2.9895e-02,  6.4070e-02,  2.5699e-02,  7.6426e-02, -4.8586e-03,\n",
            "         7.3592e-02, -7.7766e-02, -7.3799e-02,  1.8781e-02, -7.6490e-02,\n",
            "         8.3115e-02, -6.2197e-02, -3.5917e-02, -8.0584e-02, -6.3633e-02,\n",
            "         8.4784e-02, -5.1744e-02,  2.3596e-02, -7.7268e-02,  4.9936e-02,\n",
            "         3.6646e-03,  6.6477e-02,  7.9050e-02, -8.5397e-02, -3.6970e-02,\n",
            "         2.9541e-02,  5.3108e-02,  4.3458e-02, -1.3007e-02,  2.9693e-02,\n",
            "        -6.6300e-02, -1.6043e-02,  1.9324e-02,  5.0059e-02],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.0.weight', Parameter containing:\n",
            "tensor([[ 4.7013e-02,  3.3946e-01, -3.4599e-01, -1.7618e-01, -2.8881e-01,\n",
            "         -3.4877e-01, -1.0118e-01, -3.0927e-01],\n",
            "        [ 2.8559e-01, -1.7288e-01,  2.8011e-01,  1.4481e-01, -1.9936e-01,\n",
            "          2.8065e-01,  3.2695e-01,  3.3923e-01],\n",
            "        [ 4.3318e-02, -3.5171e-01, -2.1191e-01, -2.3646e-01, -2.2356e-01,\n",
            "         -4.4451e-03, -1.3715e-01,  2.4635e-01],\n",
            "        [ 2.5953e-01,  3.4152e-01, -2.2127e-01,  8.5971e-02, -1.3760e-01,\n",
            "         -2.9540e-01, -4.8023e-02,  2.8237e-01],\n",
            "        [-2.6619e-01,  2.1653e-01, -2.6232e-01, -2.7501e-01, -1.0314e-01,\n",
            "          3.1993e-01, -2.5691e-01,  1.3695e-01],\n",
            "        [ 3.2272e-01, -2.2238e-01, -1.8271e-01, -2.8956e-01,  5.0314e-02,\n",
            "         -3.3232e-01,  1.2323e-01,  3.0065e-01],\n",
            "        [-3.4074e-01,  3.3640e-01, -9.7145e-03,  4.1841e-02, -1.5750e-01,\n",
            "         -3.0758e-01,  3.2920e-01, -3.3360e-01],\n",
            "        [ 6.4003e-02, -4.6218e-02, -3.2688e-01, -2.7977e-02, -1.2449e-01,\n",
            "         -6.8677e-02, -2.2301e-01,  5.2083e-02],\n",
            "        [ 3.4978e-01, -3.9263e-02, -9.9840e-02, -2.6182e-02,  3.4211e-01,\n",
            "         -2.4499e-01, -2.2547e-02, -3.3091e-01],\n",
            "        [-1.2611e-01,  1.6385e-01, -1.3812e-01, -1.6059e-01,  1.4070e-01,\n",
            "         -8.1587e-02,  3.5547e-04, -1.9683e-01],\n",
            "        [-1.0835e-02,  1.0703e-01, -3.4715e-01,  2.3952e-01,  3.4513e-01,\n",
            "          2.4532e-01,  3.0525e-01, -1.3975e-01],\n",
            "        [ 3.4929e-01, -3.9428e-02, -3.0129e-01,  2.3211e-01, -5.2591e-02,\n",
            "          3.2536e-01, -2.9896e-02, -2.9106e-01],\n",
            "        [-2.6223e-01,  2.2580e-01,  6.9887e-02,  7.7045e-03, -7.6000e-02,\n",
            "          3.1145e-01, -6.0866e-02, -2.0827e-01],\n",
            "        [-1.1482e-01,  3.3827e-01,  1.6937e-01,  3.0829e-01,  2.3693e-01,\n",
            "          5.3876e-02, -1.1755e-01, -1.9362e-01],\n",
            "        [ 9.4581e-02,  6.4576e-02,  2.7254e-01,  2.0194e-01,  1.0994e-01,\n",
            "         -2.6341e-01,  2.0864e-01,  2.7918e-01],\n",
            "        [ 1.9404e-02,  2.2809e-01, -1.1288e-01, -3.2519e-01,  2.7561e-01,\n",
            "         -3.4718e-01, -1.3460e-01, -2.9394e-01],\n",
            "        [-1.3288e-02, -9.5213e-02,  1.0359e-02, -2.7846e-01,  1.1129e-01,\n",
            "         -3.9852e-02, -1.5493e-01, -1.3188e-01],\n",
            "        [-1.3655e-01, -1.6840e-02, -2.2321e-01,  1.2610e-01, -1.5801e-01,\n",
            "          2.9381e-01,  3.2841e-01, -5.5420e-02],\n",
            "        [-2.8583e-01, -5.4386e-02, -1.8532e-01,  2.5301e-01, -1.9051e-01,\n",
            "          1.9542e-01, -1.3816e-01,  1.5359e-01],\n",
            "        [-6.6019e-02,  9.5294e-02, -1.0012e-01, -6.6112e-02, -6.5570e-02,\n",
            "          1.5730e-01, -1.5293e-01,  1.5480e-01],\n",
            "        [-1.2679e-01, -5.4688e-02,  2.3963e-01, -1.1260e-01, -5.7963e-02,\n",
            "          2.4673e-01, -1.3857e-01,  2.1245e-01],\n",
            "        [-6.2313e-02, -2.4841e-02, -2.8130e-02,  2.7120e-01, -8.0841e-02,\n",
            "          3.8039e-02,  5.8244e-02, -2.0851e-01],\n",
            "        [-2.8825e-03, -5.3405e-02,  3.1349e-01,  1.1990e-02,  1.2204e-01,\n",
            "         -5.0767e-02, -3.3876e-02,  3.0053e-01],\n",
            "        [ 9.5487e-02,  2.5548e-02, -2.3779e-01,  1.6954e-01, -8.6026e-02,\n",
            "         -2.9729e-01,  1.4010e-01, -2.9552e-01],\n",
            "        [ 2.6746e-02, -1.6260e-01,  1.2545e-01,  3.3337e-01, -3.4777e-01,\n",
            "         -3.7611e-03,  1.2616e-01,  1.8805e-01],\n",
            "        [ 6.4431e-02,  2.3175e-01,  1.2983e-01,  3.3329e-01,  2.7777e-01,\n",
            "          1.0933e-04, -1.9185e-04, -8.9170e-02],\n",
            "        [-3.3491e-01,  1.9707e-01, -5.4391e-02, -2.0452e-01,  2.0612e-01,\n",
            "          3.0640e-01, -1.5629e-01, -2.5118e-01],\n",
            "        [ 1.1213e-01, -6.7849e-02,  8.3772e-02, -1.9833e-01,  9.8492e-02,\n",
            "          2.0402e-01, -3.4293e-01, -1.1352e-01],\n",
            "        [ 8.8510e-02, -3.0561e-01, -2.2164e-01,  2.2746e-01, -2.4095e-03,\n",
            "          1.1713e-01,  1.6656e-01, -4.2860e-03],\n",
            "        [-8.5478e-02,  1.2604e-01, -2.6574e-01,  2.8037e-01,  3.1767e-02,\n",
            "          1.5607e-01, -3.4844e-02, -1.4701e-01],\n",
            "        [-2.3790e-02,  1.7786e-01, -2.6287e-01, -1.8282e-01, -1.0835e-01,\n",
            "          2.9293e-01, -2.2580e-01,  1.6148e-01],\n",
            "        [ 1.3713e-01, -1.1467e-01, -7.5965e-03, -4.0517e-02, -9.3728e-02,\n",
            "          2.3119e-02,  2.9103e-01,  2.7072e-01],\n",
            "        [-1.3901e-01, -8.2711e-02, -2.7074e-01, -1.0404e-01,  1.7976e-01,\n",
            "         -6.6159e-03,  1.8720e-01,  2.8947e-01],\n",
            "        [-2.4099e-01,  2.6889e-01,  2.0452e-01, -1.7289e-02,  2.6559e-01,\n",
            "         -2.2599e-01, -8.7307e-02, -3.1130e-01],\n",
            "        [ 2.7051e-01, -2.5156e-01, -3.3072e-01,  3.0664e-01, -2.2363e-01,\n",
            "         -1.5551e-01, -1.5784e-01, -7.6962e-02],\n",
            "        [ 2.5678e-02,  1.8747e-02,  2.1313e-01, -6.2761e-02,  2.4928e-01,\n",
            "          1.3376e-01, -1.3972e-01, -1.1012e-01],\n",
            "        [ 2.0279e-01, -2.2884e-01, -5.6231e-02,  3.2031e-01, -1.5250e-01,\n",
            "          3.9501e-02,  1.0282e-01,  1.6599e-01],\n",
            "        [ 1.1639e-01,  1.1319e-01, -1.6826e-01, -2.2818e-01,  1.7621e-02,\n",
            "         -8.3208e-02,  3.2842e-01,  9.8168e-02],\n",
            "        [ 7.1420e-02, -3.2623e-01, -2.5767e-01, -3.6390e-02,  1.3209e-01,\n",
            "          1.5804e-01,  2.2597e-01,  3.3372e-01],\n",
            "        [-3.1080e-03,  3.1370e-01,  2.7977e-01, -2.6882e-01,  6.1455e-02,\n",
            "          8.6320e-03, -3.3403e-01,  3.9072e-02],\n",
            "        [ 3.2519e-02, -3.3683e-01,  2.7513e-01,  1.7871e-01,  2.5284e-02,\n",
            "         -7.8332e-03, -1.4435e-01,  2.6268e-01],\n",
            "        [-1.7576e-01, -1.5654e-01,  5.3425e-02,  1.4033e-01, -1.9138e-01,\n",
            "         -2.3659e-01, -2.5030e-01,  3.3642e-01],\n",
            "        [-2.2333e-01,  4.0326e-02,  2.9652e-01,  1.2512e-02, -1.3704e-01,\n",
            "          6.9783e-02,  3.7780e-03,  1.7641e-01],\n",
            "        [-2.2158e-02, -1.2838e-01, -1.4536e-01, -2.4478e-01,  2.9311e-01,\n",
            "         -2.9916e-01,  7.8378e-02, -2.2665e-01],\n",
            "        [ 3.3980e-01, -2.7779e-02,  3.1675e-01, -3.2858e-01,  2.8137e-01,\n",
            "         -6.7032e-02,  3.3009e-01, -1.5554e-01],\n",
            "        [ 3.0611e-01, -3.4330e-01, -2.3856e-01,  2.6439e-01, -1.7307e-01,\n",
            "          2.3709e-01, -3.3454e-01, -3.0247e-01],\n",
            "        [-2.0896e-01, -2.8406e-01,  2.6076e-01, -6.1901e-02,  3.0450e-02,\n",
            "         -1.4117e-02, -2.9618e-01, -1.5854e-01],\n",
            "        [-8.0306e-02, -3.1268e-02,  2.2915e-01,  2.8673e-01,  3.0332e-01,\n",
            "         -1.2716e-01, -2.7798e-01,  2.2206e-01],\n",
            "        [ 1.9062e-02, -1.4281e-01, -1.4232e-01, -4.9796e-02, -5.5913e-02,\n",
            "         -8.3268e-02,  1.5239e-02, -1.1812e-02],\n",
            "        [ 3.9287e-02, -1.3171e-01,  1.3612e-01,  3.2280e-01, -5.5408e-03,\n",
            "          2.2034e-01,  1.0806e-01, -1.4233e-01],\n",
            "        [-2.0300e-01,  2.2378e-01, -7.7072e-02,  3.4535e-02, -2.4804e-01,\n",
            "          1.4068e-01,  2.8342e-01, -7.4558e-05],\n",
            "        [-3.0442e-01,  6.1682e-03,  7.1763e-02, -8.0413e-02,  1.6142e-01,\n",
            "          2.2131e-01, -3.4928e-01,  5.0658e-02],\n",
            "        [ 2.4904e-01, -1.2440e-01, -2.8973e-01,  1.4025e-01,  2.3241e-01,\n",
            "          1.2953e-01,  3.0508e-01, -1.8875e-01],\n",
            "        [ 2.8314e-01,  5.5902e-03, -1.7047e-01,  8.6045e-02, -1.6831e-01,\n",
            "         -3.3391e-01,  2.4129e-01, -1.4447e-01],\n",
            "        [-4.2283e-02, -2.5596e-01, -4.4729e-03,  3.2726e-01, -9.0082e-02,\n",
            "         -2.0556e-01,  3.0671e-01, -3.2467e-01],\n",
            "        [-1.5734e-01, -1.2560e-01, -6.1771e-02, -3.0311e-01,  2.8136e-01,\n",
            "         -1.8069e-01,  1.3727e-01, -1.1299e-01],\n",
            "        [ 2.2106e-01,  3.2628e-02,  3.4473e-01,  3.1143e-01, -3.5157e-02,\n",
            "         -6.9756e-02, -3.4431e-01,  1.4887e-01],\n",
            "        [-2.1727e-01,  2.7784e-01, -1.4780e-01,  1.5879e-01, -2.1219e-01,\n",
            "         -5.8326e-02,  2.6255e-01,  2.2433e-01],\n",
            "        [ 2.8687e-01,  8.3760e-02,  2.6145e-01,  4.1110e-02,  1.3152e-01,\n",
            "         -2.2809e-01, -1.9389e-01,  7.2481e-02],\n",
            "        [-1.5436e-01, -2.4877e-01, -2.8571e-01,  7.9681e-02,  2.5360e-01,\n",
            "          1.4712e-01,  2.9032e-01, -1.8002e-02],\n",
            "        [ 2.8701e-01, -2.2613e-01, -1.2158e-01,  2.1632e-01,  6.1863e-02,\n",
            "         -1.6087e-01, -2.0586e-01,  1.4056e-01],\n",
            "        [-1.8318e-01, -3.3598e-01, -3.4007e-01,  3.2658e-01, -1.4959e-01,\n",
            "          2.4467e-02, -3.4155e-01, -2.7417e-01],\n",
            "        [ 2.0480e-01, -2.2949e-01,  2.2887e-01,  2.6939e-01, -1.0731e-01,\n",
            "         -1.3517e-01,  9.8562e-02, -2.1377e-01],\n",
            "        [-1.6762e-01, -7.8915e-02,  1.5056e-01, -6.2506e-02, -1.7675e-01,\n",
            "         -1.5622e-01,  3.3095e-01,  2.9476e-01]], requires_grad=True))\n",
            "('clf.classifier.0.bias', Parameter containing:\n",
            "tensor([ 0.0705,  0.0240, -0.1222,  0.0962,  0.1031, -0.2339,  0.0176,  0.3216,\n",
            "        -0.0281,  0.1216, -0.0560,  0.2951, -0.1310,  0.3356,  0.1159, -0.2313,\n",
            "        -0.2999, -0.1904,  0.0356,  0.3315,  0.2791, -0.1023, -0.2417,  0.0182,\n",
            "        -0.1694,  0.0891,  0.1185,  0.2054, -0.2415,  0.2831,  0.1444,  0.3342,\n",
            "        -0.0719, -0.2316,  0.0616,  0.0041,  0.0367, -0.1962,  0.2441, -0.2419,\n",
            "        -0.1518, -0.0204,  0.1438,  0.0267,  0.0076,  0.0706, -0.0446,  0.3431,\n",
            "         0.3366, -0.2142, -0.0937,  0.2222, -0.0417, -0.1372,  0.3097, -0.0051,\n",
            "         0.0722, -0.3199,  0.2232,  0.1748, -0.2433, -0.0123,  0.1699,  0.0120],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.2.weight', Parameter containing:\n",
            "tensor([[-0.0179, -0.0871,  0.0547,  ..., -0.1119,  0.1071,  0.0295],\n",
            "        [ 0.0936,  0.1103, -0.0450,  ...,  0.0578,  0.0956,  0.1149],\n",
            "        [-0.0214, -0.0570,  0.0009,  ..., -0.1176,  0.1248, -0.0282],\n",
            "        ...,\n",
            "        [ 0.0299,  0.0906,  0.0537,  ...,  0.0994, -0.1208,  0.1205],\n",
            "        [ 0.0058,  0.1140, -0.0357,  ..., -0.0708, -0.1189,  0.1151],\n",
            "        [ 0.0338, -0.0587, -0.1054,  ...,  0.0315, -0.0717,  0.0839]],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.2.bias', Parameter containing:\n",
            "tensor([ 0.0795,  0.0273, -0.0808,  0.0568,  0.0104,  0.0113,  0.0518, -0.0870,\n",
            "         0.1060, -0.0065,  0.0701,  0.0304,  0.0575,  0.1241,  0.0561, -0.0087,\n",
            "        -0.0507, -0.1168, -0.0848, -0.0553,  0.0841,  0.0248,  0.0512, -0.0136,\n",
            "        -0.0909,  0.0573,  0.0391,  0.1049, -0.0750, -0.1187, -0.0374,  0.0319],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.4.weight', Parameter containing:\n",
            "tensor([[-0.0922, -0.1424, -0.0131,  0.0948, -0.0300, -0.0766, -0.1345, -0.0591,\n",
            "         -0.1096,  0.0387,  0.1487,  0.0471,  0.0639,  0.1668,  0.1562, -0.1706,\n",
            "          0.0376, -0.0231, -0.0708, -0.0324,  0.1704,  0.0627, -0.1398,  0.0581,\n",
            "         -0.0450,  0.1739,  0.1592,  0.0386,  0.1490,  0.0231,  0.0488, -0.0546],\n",
            "        [-0.1127, -0.0761, -0.0186, -0.1712,  0.1259, -0.0886,  0.0571,  0.1279,\n",
            "         -0.0310, -0.0192,  0.1203,  0.1666, -0.0759,  0.1434,  0.0604, -0.0685,\n",
            "          0.1618,  0.0779,  0.1531, -0.0458, -0.1303,  0.1048, -0.0238, -0.1113,\n",
            "          0.1114, -0.0673,  0.1444, -0.0938,  0.0381, -0.1232, -0.0297, -0.0686],\n",
            "        [-0.0615,  0.1428,  0.0287, -0.1274, -0.0452, -0.1087,  0.0839,  0.0191,\n",
            "         -0.0826,  0.0081,  0.0276,  0.0681,  0.0733, -0.0653,  0.1489,  0.0111,\n",
            "          0.1334,  0.1429, -0.0162, -0.0830,  0.0043, -0.0418, -0.0594,  0.0266,\n",
            "         -0.0329, -0.0731, -0.0498,  0.0419,  0.0694, -0.0345, -0.0652, -0.1216],\n",
            "        [-0.1456, -0.0384, -0.0223, -0.1480,  0.0472, -0.1122,  0.0665,  0.0097,\n",
            "         -0.1345, -0.0597, -0.1249,  0.0052,  0.1167, -0.0960,  0.1058, -0.0850,\n",
            "          0.0883, -0.0077, -0.1075,  0.0765,  0.0404, -0.0085, -0.0573, -0.0717,\n",
            "         -0.0223,  0.1465, -0.0686, -0.0440, -0.0878, -0.0866,  0.0102, -0.1111],\n",
            "        [ 0.0222,  0.0230, -0.1556,  0.0706, -0.1017,  0.0811, -0.0488, -0.0219,\n",
            "          0.0043,  0.1413, -0.1353, -0.0630,  0.1430, -0.0308,  0.1172, -0.0471,\n",
            "          0.1450,  0.1053,  0.0004, -0.1532,  0.1225,  0.0631, -0.0446,  0.0743,\n",
            "          0.1740,  0.1693,  0.0798, -0.0903,  0.0720,  0.0071, -0.0789,  0.0264],\n",
            "        [-0.0172,  0.1062,  0.0381, -0.0770,  0.1405,  0.1470,  0.0694, -0.1674,\n",
            "          0.0058, -0.0974, -0.1452, -0.1615,  0.0182,  0.0999,  0.1070,  0.0745,\n",
            "          0.0295,  0.1735, -0.1197, -0.1709,  0.1556, -0.1392,  0.1481, -0.0225,\n",
            "         -0.0342,  0.1560,  0.0786, -0.0998, -0.1716, -0.0972,  0.1512, -0.0384],\n",
            "        [ 0.1505,  0.1297, -0.0860,  0.0726,  0.0223,  0.1082,  0.1071, -0.1205,\n",
            "         -0.1478,  0.0462,  0.0856,  0.0665,  0.0782, -0.1579,  0.1389, -0.0950,\n",
            "          0.0943,  0.1023,  0.1637, -0.0945, -0.0732,  0.1682, -0.0931,  0.1184,\n",
            "         -0.0330, -0.0610,  0.0708,  0.1747, -0.0734, -0.1475,  0.0388, -0.1619],\n",
            "        [ 0.1348, -0.1124, -0.1600,  0.0820, -0.1355, -0.0745,  0.0783, -0.0327,\n",
            "          0.1308,  0.1746, -0.1373, -0.0668, -0.0834, -0.0712,  0.1674, -0.0271,\n",
            "         -0.0141, -0.0913,  0.0789,  0.1069, -0.0657,  0.1502, -0.1061, -0.0368,\n",
            "          0.1268, -0.1194, -0.0184,  0.0024,  0.0615,  0.0990, -0.1603,  0.0218],\n",
            "        [-0.1353,  0.0623,  0.0757,  0.1618,  0.1245, -0.0336, -0.0125,  0.0693,\n",
            "         -0.1045, -0.0525, -0.1511, -0.0914, -0.0821, -0.1523, -0.1614,  0.1335,\n",
            "         -0.1660,  0.1430, -0.1660, -0.1575,  0.0182, -0.1094,  0.0280,  0.1716,\n",
            "         -0.0258, -0.1692, -0.1461, -0.0064, -0.0111, -0.0293, -0.0234,  0.0584],\n",
            "        [ 0.0109, -0.0605, -0.0594,  0.0040,  0.1728,  0.0918,  0.0937,  0.0082,\n",
            "          0.0173, -0.1399, -0.0768,  0.0331,  0.0013, -0.0918,  0.0619, -0.0455,\n",
            "         -0.0954, -0.0883, -0.0612,  0.0849, -0.1343, -0.1226, -0.1265, -0.1319,\n",
            "         -0.0069, -0.1137, -0.1086, -0.1637,  0.1159, -0.1057, -0.0399,  0.0927]],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.4.bias', Parameter containing:\n",
            "tensor([ 0.0133, -0.0412, -0.1627,  0.1468,  0.0146, -0.0178,  0.0374,  0.1668,\n",
            "         0.0128,  0.1143], requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_i9jqSMeYO8"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model2.parameters(), lr=1e-3)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMnecCt9hugj"
      },
      "source": [
        "import os"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "Ulb2BRWDh6Ii",
        "outputId": "8535cb3e-8d1c-4ab7-e0a2-1d1ed34d7904"
      },
      "source": [
        "os.makedirs('Images3')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-40f5a9966f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Images3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'Images3'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "2frfZP7Vep2j",
        "outputId": "6465048a-8f38-4e52-fd25-5a7b9077790e"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "for epoch in range(N_EPOCHS):\n",
        "  train_loss = train_step_per_epoch(model2, train_loader, device, criterion, optimizer, epoch, 'Images2', plot_train=True)\n",
        "  val_loss = test_step_per_epoch(model2, valid_loader, device, criterion)\n",
        "  print('epoch [{}/{}], \\tTraining Loss:{:.4f} \\tValidation Loss:{:.4f}'.format(epoch + 1, 100, train_loss, val_loss))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAEHCAYAAABBbSdqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxcRZk38N8TEhJC2BMMN4QEsrEoDJAIAuIgoM4AAhlAR30BWQQdBBSUFxBZZpxBhpdNRkGHzcEBkWVERhAXUJEtQEg0ErYsZCGQhISQkIQQ6v2jT5/86uGeun1v+t7b3ef3/Xz4fKpT3afP6bPcop6nqiyEABEREZGy6NPbOyAiIiLSk9T4ERERkVJR40dERERKRY0fERERKRU1fkRERKRU1PgRERGRUlHjR6TkzOw8M/vPer+3hm0FMxtdUHe/mR1Xj+8REfFM8/yItA4zOx7AWQBGAVgG4B4A54YQlvbmfrXHzAKAMSGEl3p7X0SkXNTzI9IizOwsAN8F8A0AmwHYG8AIAL82sw0LPtO35/ZQRKQxqPEj0gLMbFMAFwP4agjhgRDCmhDCLADHABgJ4AvZ+y4yszvN7FYzWwbg+OzfbqVtHWtms81ssZldYGazzOwg+vytWXlkFro6zsxeMbNFZnY+befDZvaYmS01s1fN7NqiRlg7x/OwmZ2UlY83sz+Z2ZXZtmaY2T7Zv88xs9c5RGZmh5jZZDNbltVf5LadOr4+ZvZ/zezlrP4OM9syqxuQ/W6Ls/2YZGYf6OSpEpEGoMaPSGvYB8AAAHfzP4YQlgP4JYCD6Z8PB3AngM0B/ITfb2Y7A/g+gM8D2AaVHqRhHXz3fgDGATgQwLfNbKfs39cC+BqAwQA+ktV/pZPHVbUXgKkAtgLw3wBuBzABwGhUGnbXmtmg7L0rABybHd8hAL5sZkfUeHxfBXAEgI8BaAOwBMB/ZHXHZe8fnu3HqQBWdvF4RKQXqfEj0hoGA1gUQni3nbpXs/qqx0II/xNCeC+E4P94HwXgFyGER0II7wD4NoCOEgMvDiGsDCFMATAFwG4AEEJ4OoTweAjh3awX6npUGhVdMTOEcFMIYS2An6LSALkkhLA6hPAggHdQaQghhPBwCOHP2fFNBXAbfW9Hx3cqgPNDCHNDCKsBXATgqCw8uAaVRs/oEMLa7PiWdfF4RKQXKd4v0hoWARhsZn3baQBtk9VXzUlsp43rQwhvm9niDr57AZXfBjAIAMxsLIArAIwHMBCV583THWyryGtUXpntm/+36vfuBeBSAB8EsCGA/gB+lr2vo+MbAeAeM3uP/m0tgA8A+C9UGl23m9nmAG5FpaG0povHJCK9RD0/Iq3hMQCrAUzkf8xCQX8H4Lf0z6menFcBbEuf3wiV3o6u+AGA6aiM6NoUwHkArIvb6oz/BnAvgOEhhM0AXEff29HxzQHwdyGEzem/ASGEeVke1cUhhJ1RCTMeikp4TUSajBo/Ii0ghPAmKgnP3zOzT5lZPzMbCeAOAHNR6bWoxZ0ADssSijdEJezT1QbLJqgMt19uZjsC+HIXt9OV730jhLDKzD4M4HNU19HxXQfgO2Y2AgDMbIiZHZ6VDzCzD5nZBqgc1xoA3EMkIk1CjR+RFhFCuAyV3pXLUfnj/AQqPRkHZvkrtWxjGipJv7ej0kuyHMDrqPQqddbZqDQ83gLwI1RydXrCVwBcYmZvoZLTc0e1oobjuxqVXqMHs88/jkqyNQAMRaXxtAzAcwB+j9oblSLSQDTJoYgUysJmS1EJXc3s7f2pt1Y/PhFpn3p+RCRiZoeZ2UAz2xiVXqQ/A5jVu3tVP61+fCLSMTV+RMQ7HMD87L8xAD4bWquLuNWPT0Q6oLCXiIiIlIp6fkRERKRU1PgRERGRUunUDM9mphhZLwsh1GWSOJ3L3levcwnofDYC3ZutQ+eypSwKIQzx/6ieHxEREWlVs9v7RzV+REREpFTU+BEREZFSUeNHRERESkWNHxERESkVNX5ERESkVNT4ERERkVJR40dERERKpVOTHIo0gz594jb9IYccUvjeiRMn5uUBAwZEdffdd19e/slPflKnvRMRkd6mnh8REREpFTV+REREpFTU+BEREZFSsRBqX3et2RdpGz9+fPT68MMPz8t77rlnVPepT30qLz///PNR3de//vW8fP/999dzFzukBffad8MNN+TlY445JqobNGhQl7b55ptv5uUPf/jDUd0LL7zQpW0yLWy6zr333hu9Puyww/LyF77whaiuUfOvdG+2Dp3L9p122ml5+Zprronqzj333Lz83e9+t8f2qQZPhxDG+39Uz4+IiIiUiho/IiIiUiotGfbiIcvnn39+Xv7GN74RvW/DDTfMyzNnzozqOOSx2267RXXvvPNOXv7oRz8a1T311FNd2OPaqTu24rjjjote/+hHP8rL/fr1K/zc9ddfH72+7LLL8vLvfve7qG7EiBGF3/fjH/+49p0toLDXOj//+c+j14ceemheXrZsWVR31FFH5eXf/va33btjnaB7s3XoXFbst99+0Wu+3/r2jWfKWbNmTV4ePnx4VLdw4cJu2LuaKewlIiIiosaPiIiIlIoaPyIiIlIqLbG8hV+WgOOSe++9d16eP39+9L4TTjghL0+aNCmqe/vtt/PyGWecEdVdeumlefnCCy+M6o444oi8vHbt2g73XdI22mijvPzDH/4wL/vh7JznM3fu3KjuxBNPzMu/+c1vorqxY8fm5U033bRwP2bNmlXbDkvd+fOyxRZb9NKeNLZRo0bl5X333bfwfUceeWT0eocddsjL/rfmvLcUs3UpMp3JI01ZsWJFXr7zzjujuquuuiovT5kypS7fJ+/3mc98Jnrt83wY59Cec845Ud3ZZ59d3x2rA/X8iIiISKmo8SMiIiKl0hJhL57dF4hDXY888khe5hmdAWDp0qU1bf/KK6+MXu+44455+Ytf/GJUN2HChLz8+OOP17R9KXbLLbfk5aOPPrrwfU888URePv7446O66dOnF37u1FNPzcs+nMLXzuTJkzvcV5HexKGum2++uS7bnDZtWl5++OGH67LNWk2cODEv+6kmtttuu7x84IEH9tg+lUFbW1te9rOr1+qkk06KXn//+9/PyzNmzOjajtWZen5ERESkVNT4ERERkVJR40dERERKpSVyfj7xiU8U1vGSFrXm+Hjvvvtu9JqXQfA5P2+99VaXvkPad8ABB+RlHkL7xz/+MXrfpz/96bzMS5N4w4YNi14fcsghhe/l1cN1XqXR3X///Xn5m9/8ZlS3zz775OVddtmlcBs87B0Afvazn+XlSy65ZH138X369Fn3/988JQUAHHvssXnZL49wyimn1H1fpOLggw/Oy5tttlnh++bNmxe93muvvfLykiVLorqVK1fWae/qRz0/IiIiUipq/IiIiEiptETYi2cXbe91V2y88cZ5+eSTT47q/uEf/iEvT506Nap76aWX1vu7ZZ2DDjooL2+55ZZ5+aGHHurS9r70pS9Fr0ePHp2XH3vssaju9ttv79J3SG04/LLzzjv34p60Bg4NXX755V3aBk/jAcQz3deDD6PwNCJ+iorXX389L3P6AqDnbHfi2ZhTs3XzSgrA+1dQaHTq+REREZFSUeNHRERESkWNHxERESmVps354SHLvJos0LVVhffcc8/o9RVXXJGX99tvv8LPPfDAA9Hr1atXd/q7pVg9Vmw+7LDD8vJ5551X+D4eKgx0fWoEqQ2vQu6HWEvvSC0F01U8ncR1110X1fFzfPbs2VEdD7lWjk/3OvTQQ/My5+Kl/pauWrWqW/epu6nnR0REREpFjR8REREplaYNe/Hskj7UxMPUU4488si8zKvOAsDWW2+dl33444477sjLvPK3NIahQ4dGr3k4bd++8SV/11135WXfJS/d68wzz6zpfX649YoVK7pjd2Q98IryJ5xwQlTHK7IvWrQoqrvwwgvzMt+nALB8+fJ67qIk+LSPIjxz8/nnn99du9Mj1PMjIiIipaLGj4iIiJSKGj8iIiJSKk2b81MrXuqCp+0G4pWPt9pqq6iOp1b3K38/88wz9dxFqTOfv8VDqj2+JvzK0VJ/PHx5woQJNX3G59X5KQmkfjbYYIPoNZ+jz33uc1HdSSedlJd5upH33nsvet9Xv/rVvHzLLbdEdfVePkNq079//+g1TweSWh7qxhtvzMuLFy+u/471IPX8iIiISKmo8SMiIiKl0hJhL7/CN6+6fs011+Tl8ePHR+/j7r1JkyZFdaecckpefvbZZ+uyn9J9Tj755LzMoRUAWLlyZV7+/Oc/H9XNnTu3e3dMIvvvv39eHjhwYE2f8eFqWT9+KggO/0+cODGq22677Wra5ltvvZWXL7jggqjuySefzMs+3MLhMs2o3nO22GKL6PXuu++el3lWZz/D85133tm9O9aD1PMjIiIipaLGj4iIiJRKS4S97r777uj1UUcdlZdTI0p4ttETTzwxqvvLX/5Sp72T7tDW1ha9Pvfcc/PyoEGDojoelXLPPfd0745J3XFIRdbfl7/85eh1rTNt+5m133jjjXbfd9ZZZ0WveSbgIUOGRHU8MuzXv/51VMczPj/44IM17aPUZsCAAV36XLMvZsrU8yMiIiKlosaPiIiIlIoaPyIiIlIqLZHz42dn9sPzqp5//vno9THHHJOXlePT+EaPHp2XJ0+eHNVxns8Pf/jDqO6GG27o3h0TaSL+/vjFL35R0+f8iuyzZs2q6XObbrppXh47dmxUx0PrefV3APj5z3+el/2s3jy1RbPPNNwbOC82ZcaMGdHrmTNndsfu9Ar1/IiIiEipqPEjIiIipdK0YS8OgXzrW9+q6TNf//rXo9cKdfUOv3jinnvumZd5NlgAOOigg/Iyd4P72YG5e/YHP/hBXfZT1t+2224bvT7ttNNq+hyfz1YaXtsI5s2bl3xdb8uWLcvLTz31VFTHr6+++uqo7vLLL8/LfmZ2HjLPM/oD8aLUUhte7YDLy5cvj97XStNOqOdHRERESkWNHxERESkVNX5ERESkVJo25+d73/teXt56661r+szpp58evX7ggQfquk9l41cG5mUkjj766KjuQx/6UF7mmDIA9OvXLy+/8847hXWcK+Tj+nvttVde9kNypWfxSt3+nuNhz8xPT3HjjTfmZeVwlMNrr70Wvf6nf/qnvLzLLrtEdfvuu29evuiii6K6r3zlK/XfuRbj86SKpofx0yK0EvX8iIiISKmo8SMiIiKlYkXdXe2+2az2N9fZJZdcEr3m4e3+GB566KG8fMABBxRu0w+5bgYhBOv4XR3r6rnk7ueLL744qvNdqT1p6dKlefn666+P6i677LK8XLQSdUd8aHWTTTbJyy+//HKXtlmvcwn07r3p8czpt912W02f8SGPtra2uu5TT+jte7OV7bHHHtFrHiLvV4P/5Cc/ud7f14rnkmfX9jPk8yrvs2fPzsu77bZb9L4mHer+dAhhvP9H9fyIiIhIqajxIyIiIqWixo+IiIiUSkMPdefV2v0SFjxc+g9/+ENUd+yxx+bl3//+93l51KhR0ft4uOSf/vSn9dvZkjjiiCPyss/xWb16dV6+9NJLo7p77rknL/ucHB6m7j366KN5uX///nmZh84DwOabb56XzznnnKiOl8i48MILo7rHHnssL/t8IF6a4Ve/+lVUxzlGfB1J8bDZlAsuuKAb9kRahZ8Cg/H9DQCDBg3Ky355hjLbeeed8zLn+HgvvPBCXm7SHJ+aqOdHRERESkWNHxERESmVhg57jR+/bnRaqiv9s5/9bPR6wYIFeZln+91hhx2i940cOTIvK+xVm7PPPruwjkOTs2bNiupuvfXWvPzBD36wcBvXXntt9PprX/taXn733XfzMl8bQBzOOvTQQ6M6XjX+vvvui+rmzp2bl/3M0Dy83Q+9vuGGG9o/AHnfDN618EPdRWrlV6Vfs2ZNL+1JY+PwfOoe7cr924zU8yMiIiKlosaPiIiIlIoaPyIiIlIqDZ3zc9ZZZxXWce7GwoULozpeVTo1pE86j5d18P793/+9pm2sWrUqes1Ll/gh8kW5Xjy9PQBMnDgxL59//vlRHQ/JHzduXFTHw9m57E2dOjV6fdVVVxW+t+y6MtRdxOvXr19ePuWUUwrf9/TTT0evecoNWYfvy9Q9OmbMmLz8j//4j1EdTx0zf/78Ou5dz1PPj4iIiJSKGj8iIiJSKg0d9kp1q+200055mYdDA8CnP/3pvLzrrrvWf8dK7Mwzz8zL++yzT82f41DX1VdfHdVNmTJlvfeLh7dedNFFUR2/9qsUn3HGGXnZh0jvv//+vPzLX/4yqlu8eHFXd1UyDz/8cF72s7RLOfTps+7/v3ffffeo7oorrsjLH/3oR6M6nqLiO9/5TjftXWvx6QZFeAqYK6+8Mqr7+Mc/npcV9hIRERFpImr8iIiISKmo8SMiIiKlYp0ZlmpmPTqGlZdB8HkhPAV3rcfw0EMPRa959fdmiV+GEOoy93hPn0t5v3qdS6CxzucxxxyTl2+77bbC9x111FF5+Z577unWfeoJZb43Bw4cmJdTeZaHHHJI9Jpzefbff//Cz02bNi16ffrpp+dl/1yvh1Y8lzxNyV133RXVHXjggXmZ/xZ++9vfjt530003ddPedaunQwjj/T+q50dERERKRY0fERERKZWGDnvJ+7Vid2xZtWrYq6wa6d78xCc+Eb2++eab8/Kbb74Z1fHs5X5Iea369l03a8rgwYNr/tzatWvzMk8tAcShGR+mWb58eWd3sVMa6VzKelPYS0RERESNHxERESkVNX5ERESkVBp6eQsREek8HnoOAEOHDm23DADjxo2raZu8hAwA3Hfffe2+b8mSJdFrXgn8mWeeiepmzZqVl1esWFHTfojUg3p+REREpFTU+BEREZFS0VD3JqMhmK1DQ91bi+7N1qFz2VI01F1EREREjR8REREpFTV+REREpFTU+BEREZFSUeNHRERESkWNHxERESmVzs7wvAjA7O7YEanJiDpuS+eyd9XzXAI6n71N92br0LlsLe2ez07N8yMiIiLS7BT2EhERkVJR40dERERKRY0fERERKRU1fkRERKRU1PgRERGRUlHjR0REREpFjR8REREpFTV+REREpFTU+BEREZFSUeNHRERESkWNHxERESkVNX5ERESkVNT4ERERkVJR40dERERKRY0fERERKRU1fkRERKRU1PgRERGRUlHjR0REREpFjR8REREpFTV+REREpFTU+BGRlmBmD5vZSQV155nZf/b0PolIY1LjR6QXmdksM1tpZsvNbIGZ3Wxmg3p7v9pjZsHMRnfTtkdm2+/bHdsPIfxrCKHdhpGIlI8aPyK977AQwiAAfwNgdwDn9vL+dEl3NVxEROpNjR+RBhFCWADgV6g0ggAAZra3mT1qZkvNbIqZ/S3VbWlmN5nZfDNbYmb/Q3Unm9lLZvaGmd1rZm1UF8zsVDN7Mdvuf5iZZXWjzez3ZvammS0ys59m//6H7ONTsl6qz5jZ35rZXDM7x8wWALjJzI43s0f4uLjHyMw2MrP/Z2azs+94xMw2AlDd/tJs+x/J3n+CmT2XHd+vzGwEbfdgM5uebedaAFb025rZRWZ2a1au9jJ90czmZNs+1cwmmNnU7De5lj47ysx+Z2aLs9/kJ2a2OdXvYWaTzewtM/uZmf3UzP6F6g81s2ez7T5qZrtS3TlmNi/77PNmdmDRMYhI/ajxI9IgzGxbAH8H4KXs9TAA/wvgXwBsCeBsAHeZ2ZDsI/8FYCCAXQBsDeDK7HMfB/BvAI4BsA2A2QBud193KIAJAHbN3vfJ7N//GcCDALYAsC2A7wFACGH/rH63EMKgEMJPs9dDs30bAeBLNRzm5QD2BLBP9rlvAngPQHX7m2fbf8zMDgdwHoCJAIYA+COA27JjHAzgbgDfAjAYwMsA9q3h+9leAMYA+AyAqwCcD+AgVH7PY8zsY9n7DJXfsw3ATgCGA7go248NAdwD4ObseG4DcGT1C8xsdwA3AjgFwFYArgdwr5n1N7NxAE4DMCGEsAkq52BWJ49BRLpAjR+R3vc/ZvYWgDkAXgdwYfbvXwDwyxDCL0MI74UQfg3gKQB/b2bboNJQOjWEsCSEsCaE8Pvsc58HcGMI4ZkQwmpUwmgfMbOR9J2XhhCWhhBeAfAQ1vU2rUGlIdMWQlgVQoh6cdrxHoALQwirQwgrU280sz4ATgBwRghhXghhbQjh0Wwf23MqgH8LITwXQngXwL8C+Jus9+fvAUwLIdwZQliDSuNlQQf76v1zdowPAlgB4LYQwushhHmoNLR2B4AQwkshhF9nx7gQwBUAqg2jvQH0BXBNdg7uBvAkfceXAFwfQngiO95bAKzOPrcWQH8AO5tZvxDCrBDCy508BhHpAjV+RHrfEdn/+f8tgB1R6ckAKo2Qo7NwyVIzWwpgP1R6c4YDeCOEsKSd7bWh0tsDAAghLAewGMAweg83FN4GUE2y/iYqPR1Pmtk0Mzuhg31fGEJYVcMxIjuuAaj00tRiBICr6djfyPZtGCrHOKf6xhBC4Nc1eo3KK9t5PQgAzOwDZnZ7Fp5aBuBWrDtHbQDmZd9fxfsxAsBZ7hwOR6Vx+RKAM1HpRXo9+442iEi3U+NHpEFkPTc3oxIaAip/RP8rhLA5/bdxCOHSrG5Lzj0h81H5owsAMLONUQm5zKthHxaEEE4OIbShEqr5vqVHeAX3egUqobjqdw+lukUAVgEYVcN2gMoxnuKOf6MQwqMAXkWlEVH9HuPXdfav2f59KISwKSo9ctX8olcBDKvmTGV4P+YA+I47hoEhhNsAIITw3yGE/VA5XwHAd7vpGESEqPEj0liuAnCwme2GSg/DYWb2STPbwMwGZEnG24YQXgVwPyqNky3MrJ+ZVfNmbgPwRTP7GzPrj8of7ydCCLM6+nIzOzrLPQKAJaj8QX4ve/0agB062MQUALtk3z0AWW4MAIQQ3kMl/+UKM2vLjukj2T4uzL6Ht38dgHPNbJds3zYzs6Ozuv/NvmeiVUaZnY5K/lF32ATAcgBvZnlY36C6x1AJX51mZn2zPKUPU/2PAJxqZntZxcZmdoiZbWJm48zs49nxr0Klt+k9iEi3U+NHpIFkOSU/BvDtEMIcANWk34Wo9CJ8A+vu2/+DSo7OdFRyhc7MtvEbABcAuAuVnolRAD5b4y5MAPCEmS0HcC8q+TkzsrqLANyShW+OKdj/FwBcAuA3AF4E4HOGzgbwZwCTUAljfRdAnxDC2wC+A+BP2fb3DiHck9XfnoWb/oJKnhNCCIsAHA3gUlRCemMA/KnGY+ysiwHsAeBNVBpdd1crQgjvoJKQfSKApaj0Ct2HSl4PQghPATgZwLWoNCZfAnB89vH+2f4vQiUMuTWadJoDkWZjcahaRETWh5k9AeC6EMJNvb0vItI+9fyIiKwHM/uYmQ3Nwl7HoTJ9wAO9vV8iUkwzsoqIrJ9xAO4AsDGAGQCOynKyRKRBKewlIiIipaKwl4iIiJRKp8JeZqZuol4WQihcv6gzsrWNqtusxybBU52kthlPidK1709tox7bb287Rbq6/XqdS0D3ZiNo5HuzUdTr3uzubdbzXNZjO7JeFoUQhvh/VM5PSZkZBgwYAAB45513orpaGy7+odOnz7qOxDVr1hTWcdl/n//u995rf9qTfv36Fb6vb9/4sl69et3qCf67+XO+boMNNmi3DABr165tt9zRNqu/2bvvvguR9phZfn3766Sr9ya/9tdr6nOp7y7aF3+v8Pt8HT97Us+F1LMmdU/750ct96b/faTpzW7vH9X4KakQQt5A8Q8xfij4h++GG26Yl32jiRsdqf8bq/UhCrz/YVnlG1f83f7hxdvwD8NaG171aqwUNeZEqkII+TWcujdT17m/XrmuXr2mvC/8vtR3+30u2kZH3536vq42EHVvlotyfkRERKRU1PgRERGRUlHjR0REREpFOT8lVo2Vp5IjUwmKqc+lEic7k1fAuTyppObUSLNUTkOt+5XaZlFekt9nkVpVc2NS16tP2OXcl1pHKnb2vUXfz/eDvzdrzd1J5dyl7s3UPZZKok4lfkvrU8+PiIiIlIoaPyIiIlIqpQ571TopX6vzYRseRu67sHl+Hd9tXOsQU98VzcPnq3MPtfd9XOffx9tYtWpVVMfhgLfffjuqW7lyZeHnUl3rqeHzIvXi7xW+53xdarqHlFS4mreZehbw/eifJ/w+Pz0G35u+jl/74ex8z/nnTlcnW5VyUc+PiIiIlIoaPyIiIlIqavyIiIhIqTRtzk9qOHb//v3z8mabbZaXBw0aFL1v4MCBednHmzlmvnjx4qjurbfeyst+mYVmyv/wOQNVnD/TmdyB1FB0/q0333zzqI5fb7vttlHd0KFD8/I222yTlzfddNPoffzan4OlS5fmZX8u58yZk5fnzp0b1fHrN954I6rz+UGMr82iXKGyru3F1xxfI/4e5rpUvoeva5V1mYryUYqmfgDS+S383tTz0t9XG220UV5ua2uL6oYMWbdWJN+n/v7m5y7n2AHxs3TRokVR3ezZ65ZkWrBgQVTH9/Ty5cujOv9MrlX12izDvemvL74m+PnPZf+a10wE4mvM1/E5aZT8WvX8iIiISKmo8SMiIiKl0tBhL+6a82GULbfcMi9vtdVWUR13z3LZv893zzLujuUuViDujn3++eejuldffTUvd7X7tadUu3lT3ee+joet+u5zfs3nB4jPw7Bhw6K6HXfcMS/vsMMOUR2HLbkLfvjw4TXvM9f5UN/UqVPz8osvvhjVPfXUU3l53rx5UR2/9l35qakCfHi1FfEx8/UCxGGVLbbYIi9zWNS/9mEI/g1fe+21qI7v2xUrVkR1zRQSqz77/LWcGsZdFFL0dT78P3jw4Lzsn5E777xzXh4xYkRU94EPfCAv87253XbboYg/B3xufSh5ypQpeXn69OmFdcuWLYvqOHzmrx1+nZrioxX40BaHN/1UIXze+Xrw18omm2ySl/3vxaGu+fPnR3WcNuBTCHrrmaieHxERESkVNX5ERESkVNT4ERERkVJpqJwfH6PkuL/PIeFhlj5PZNy4cXl5l9SzXn4AABYGSURBVF12ycvbb7994fb9sgecL+Djl3/961/zso+JPv7443nZD93keHMjDPer7oOPfadWh+YcBI4hA3EOx9Zbbx3V8TkZOXJkVLfrrrvmZT6vft84V8gPiee8G59XwPkOPt7MOQ2pJTMmT54c1XGc+pVXXonq+DfzOQfV42mm/JP2pPJLOM+HrwkgPm+c/+OvCf59fU4V1/H0BwDw7LPPtruPAPDmm2/m5Ua4/2rh783UdcP3ph+izM86ztsA4uenPw9jxozJyz7PjrfJ59k/Zzknx+d38H5yvhYQP5N97hgf64wZM6I6vudef/31qC51bxblQDYTvhf984yf15yvBcTnjPN//N9Wvv7830w+t/5amTRpUrv7CMTTGHRmyaT1pZ4fERERKRU1fkRERKRUGirs5bvDeJizD4fstNNOeZmHSgNx1zp35/muPu4G9F2dHPbyXW9ct3DhwqiOu+H9zKP+dW8ys7yb1x8fv/ZhL+5+9mEvDmP435rPl+8S5RCZn36Au8U5xOhnEOV95mG3QHooZWqfuQvWh8u4q5anN/Df50MvRUOYm03RjLBAHKL24c+NN944L/OswP6358/535Bn3p42bVpUx2EbP3VBatboRguDVa+T1L2ZWtXdh8s4RMVDmYE4JO3vTf49+Xnsv59Daf5+KwqPAfEz0Q+d5mepHwbPIRf/OX4mp6aaaIV7M/V89s9Bvsf8eebnIE9L4u9fDon57+ZnIqeGAHH49M9//nNUx+E5H+LuzvQA9fyIiIhIqajxIyIiIqWixo+IiIiUSq/n/HDcMDV02k+tzsOe/XBXzgHifIQlS5ZE7+P4r/9uHnbpY9gcK/b5Dhy/TE0x39tDnUMI+T6kpslP5Rz4Y+e4/+jRo6M6fi/nfQBxnNr/Zpy7wPkBPqeBlznw+1y0QjYQH6vPA+F99vvFsW+/L7Wc50bLMemIz4/gc+aHTnOOh//d+Dflbfp8OM418MOvOf/DrzTO00v4febz1Ogrd1fzTlLXcmoZF/+78znx9yafSz91B/9m/vv4NZ8/v1QJD3X3dZy75+9TPh5/H/Fz1uf8cM6ZXw2ev6O3n8H14J89/Lv4/CrO2Uo9u4ueuUD87PbTjfB59jm6/HxOPeN7knp+REREpFTU+BEREZFSaaiwV2oFWT/MksMOfng0D5dLrc7OwyV5qB8Qd8WlVq/13dIcPutM+KU3pWaR9d2jfAyp4bT+XHJXtF85mt/rf2sensmztfJsvUDcPevPJXfP+33mLli/2jx/n/8dirYPvD/c0t57mz3sxb+b/21SdbziN9/fflhuapZePve+W97PBMx6q3t9ffh95mutM8eaujc5POJn0ufz54ebc3oBP1v9tBC8z37WYX6W+jAUHwNPiwDEs+77a4e/L/UMLvptm+neTIWVUzPW+zpOHeE6/zeLp3nhUBaQvi9T917q2dqd1PMjIiIipaLGj4iIiJSKGj8iIiJSKr2e85MaSsmxXD+clut8PJFjjxwb9nHI1PIWHCP32+e4p5+Om4f7+c81Ws5P0fIWHINN5bOkliNJxZRTU7L7feGlI+bNm5eX/ZBZzkfgcwDEOQ5+ygSeCt+fSz6G1JT3Ph+Gcxeaaar8FH9e+Nz7nAu+fvxwWx6KzufJ53TwvePPNb/3mWeeier4Hvc5JDxlRWpYdSMoujdTz0u+Dv01yfeAP3b+PVNTGvgpKniZEc758UuVcF6PfwbzufW5H4sXL2637PfTH0/qd+DfzP9+jfZ8LpKa7oB/Q3/f8N87n0Pr8+qqfH4m31N+ehjOvX3uueeiOs699Xmd/NxNna9636Pq+REREZFSUeNHRERESqWhwl6pVcL98GUOg/khmNy1zqESH4biWWR9NyB36/uZoXmIvJ8pll/7lccbLQRS7Ub03b2p2W+5W9IPtU1NTcC/he9K5e50f464O523n5qN2YdaeD/52gDiob0vv/xyVJcaTpsKI3D3bFG4qNFnGAbi4/LHyPeqD4ekwsk8DJq7v32Iimd19tcZr9buf0cOj6SGTvuu90ZTdG+mniF8fD4kzdervzd5mz5UkpqOgNMLuM4/9/i7/bnkkIcfIs/v9dvk54J/ZvD115nwZvXZ1ugzP6eG69eaKuKvI/49+e+pv0923333vOxTG2bNmpWX/aoIqfsyNSN+d4aj1fMjIiIipaLGj4iIiJSKGj8iIiJSKj2e85Maluhzfpifkp3jl35oc9Hq334ZjLFjx+Zlv0Itx5h9ngjzcWqObfphe420qjuw7lz4feFzlJoe3sd8U7k7nEvgc0Q4b8MvQcIxZ/5uPyydt+mHTXN82+dC8PellqXwQ3Q5Lu6v21SuTKMNqU7hfU8NQfV5AYMHD87L/ndjfN55qQQAmDBhQl72w5z5ukvdRz5PpOhaAhrvvFT3L5Xj4/eZX/trsmjVbiDOl/M5Ofw7pZ6DqeHXvC98bfht+nwjztf0uV18Ln1+CV8T/rpNDWdvtGugCB9TavkTfx44b9bfl3zs/Lntt98+et+uu+6al/19z+fSfzdvn6eKAeL71J+f1N+i9aWeHxERESkVNX5ERESkVBpqqLsPo6RCJfy51OyzY8aMabcMxKt4++1zV7vfLx7iyTNXAnGXZCN3o5pZ3qWYCgGkuo19KJK7z/3nUqEK/r7U0F7u+vbD5XnmZj8kl/kQKXeZ+ykNmA8H8DXmrx2eNToVNmx0vO+plZf9dZDqeud7+uCDD87L++23X/Q+DlH7ECf/9qmQRyvo6r3pn1nMn6/U6vCpsFvRs8BPS+JnVWd8PAsWLIjq+H73YRr+bn9tpv6m8Haa9d7k/fbHx9dE6r709wlvZ5999snL48ePj97Hs3f7FAUOb6bClKlwbU9Sz4+IiIiUiho/IiIiUiq9PtqLuyz9SBwOJ/jPcTea/9y4cePyMnfT8ayxQDzDs1/YjcNZvmudR/o062iCEELeNelHDHCXqO8e5a5TP1Mshyr84oY867Ifdccj5vwolaJFCv3spfw5P+M3d+n6rlo+ntRikP53SIUKUqOkmklqdCLfm76Lm0OSPizMoyp5RBeXgficzZw5M6rjsKK/93lffF2zhDWAdb+3vzeLRuV4PuTBo6x8Hd+rPmTFs9n7EAvvG2+Tn6tAHOrkc+dxOgEQX3P+u/nZwwusAunRlql7s1muD/7d/X3J58FfH/zc9WHEtra2vMyzOO+xxx7R+/hcPvLII1Edp4r435L/hvpnJx+Pf5ZohmcRERGROlHjR0REREpFjR8REREplR7P+fFxVo7/+XyP1DBkfq/fJueDcP6BjzVy3NPPOsmx6dSsw6khg42ec1C0cjTzw0j5+PyMrHwe/PBkPpc+7s+/k8/X4e/geLYfXs75Aj7WzXX+nHBOg8+F4FXdvVReFP8Ofl+qdY12LbQnNZyYfzc/kzLfS6nzOWTIkLzsczp4SgI/wzPfjz6niO9xnz+QOi+NlI/HUteJv5ZTQ7xT0w/wc9CfSz5ffM6B+NnK59LP4sz5lP45y/l+qdxDX8fb8X83+Brwx5qaibpR8/M6syoC/y4+r4df+/uSn6ep+5LvN/83mc+ln1KEnx9+Zmg+t/4c8H2pGZ5FRERE1oMaPyIiIlIqvT7UnbsefZcrh058dyl3v/lwFne/cVeZH7LO4TE/uyiHZvznUt1vqW661NDU3lDtYkx1DXvcfem7XLmLNDWcfcsttyzcpu8S5e9ILZLJIQDfPc/d5z4clxqWzfvlu905pOKvj5Tq8TVqmIWl7h2+53zYj+8dfx0w/r19aItDJbNnz47qeGhzZ2aSbdSwRntqWdjU43OSWrzUhzI4jOiHqfM2feiTQ2IcRvH3Kd+b/jnOr/29ycPu/VQk/N0+/MfXgH+epDTL7OCp+5L/hvprh+8xP00JHztfD34xW04h8FMMzJkzJy/7+5L3szP3pYa6i4iIiNSJGj8iIiJSKmr8iIiISKn0eM6Pj0VzfomPz/JwOT/1OccU/SreHOtM5ZNwHsqrr74a1XEs2seCOa6amsY7tXp5s/Dni+PwPp+D83P89ACcS5A6lz73ij/HsWGfN8Tb8LljvF/+HKTyiDgHwceleZinv654X4qm0Pcx8UaXiuH7XA1+rx/2zPc05wj4vD1e0oLfB8TXYGpKBX9vNttv3hF/bfFz0N+bfB/7Zx3nzKSm9fD5Jfx78jnx+SScg+fz8Tj/yN9HvC/+WPk68s8ovjd93gs/k4tyTRot9yeVg+mHrPPfO/9s4/Pllwcq+lvo8zq5zt+XPFze50+mloTqTF5WPannR0REREpFjR8REREplR4Pe3ncTefDV9wd67siufvU1/E2edjt0KFDo/dxN6DvOk2tEp6S6lpvtLBXdX9SQw19Vzevzu6PlX+z1BBn343LXdh+lmW+Bvj389/N4TLex/a2ybhr2HcTp6Za4Pf636iWGZ4b7VroiB9OzMflzwWfXz9UlrfDv5sPt3AYzF9L06dPz8v+nPFv76+zZvvNgXTIw//uqdmYGa/i7rfjvy+1qjv/1nxefSiSn8F+1Xh+dvv7iL/Pb5Nf+2Pl53VXZl9vNKnr1oel+Jj8sXN4icNcQPw3k39bH75i/ly+/PLLedk/L/nva2q6m57UmGdbREREpJuo8SMiIiKlosaPiIiIlEqP5PwUxYaBOM/HD1/mGLaPbXIM0ecK8TC+1Aq1zOf18HBJH/dMxURTQ64bNecglRuRis/64clF2wDi+LAf2sjn2a8UzLkgvA1/vrbddtvCfeHYt1+Jft68eXnZx575evHLL3CeUmqoZqOe8/b4c82vfU4cv06tqu2Huo8ZMyYvp4Y5z58/Py/7a4LvMb96NPM5D3w8jTac2ateN525N7nOP+v4fPlcIV7iJfV8Tk13wHU+D4tz8Px9mxoCzVNi+HuTnwWcawLEz+TO5GA26r2aWtXdP4NTyw+l8ui22267vMzPSH+f8PPY5/XwPexz+Pi39fc6H09nlgpaX+r5ERERkVJR40dERERKpUfCXqnuRO7S892ePETZh7a4W9eHPEaPHp2Xd9ppp3Y/A6RXlebQlu/G5RWGfdiLuwKbZUbZVPdvKuyVCvf4z3H4MTVsdeTIkVEdzxbL++WvFe7W913rvM++O5bf64d/zpgxIy+/8sorUV1qqgXmwwhVqSHMjSjV9e5DEvzetra2qI6717fZZpu87O8x7v72w+VTU1TwteTvv0YPdbHqb9jVe9MfO9f5z6XCXnwe/L3Jnyv6LiB+TqRCJf65wNeEvwaef/75vMwhUiA+9tQw6qJ7s7eGXneFP5dFxwTE98rw4cOjuh122CEv8z3qn6V8/fmZ+vlc+v3iv5Opleh7MvSonh8REREpFTV+REREpFTU+BEREZFS6fGcHx/v4xiwn6acY/Q+ts+5ID5+udtuu+Vljkv7IbMcR/Yr1L7wwgt5mXM/gDjWyVO3A3HcutFjx9Xf1MdZU9O8v/baa3nZx+H5t9h+++2jOs618bkCfC59zJrzvjhny78vtUyFXym+qG7WrFlRHef5+JWw+RpILe/gVd/biMNqU/klPr+Lf39/vfB58jlxfO55FWifU8U5eP4e4/Obmn7fn5dG/M2LFC2Dkro3+Xfx+Wv87BsxYkRUx8/gYcOGRXU8PDqVX8L3qX8ff7e/jvgZ4s8X32MvvfRSVMfXhM/XTOXj8b7537ZRn9d+P/mY/HQqfO/588BD2P154KWfeBoB/9vya/9c5We8/1vLx+Bzu7S8hYiIiEgPUONHRERESqXHV3X3XZvcjeZnneQZn1Mrdfsh7PwdM2fOzMs+dDFt2rS8/Nxzz0V1f/3rX/OyD4lxl2sqVNcsfAgpNWSRu6n9sHGeLfnFF1+M6njmUY/DH35fOCTG3fo83YDfvg+T8H757ljuTp8yZUphnf+cHwJapGgYeDOEYPha9uEWrvPd2Dytgb+nOWw6d+7cvOzvzcmTJxdun89Fauh0M/zGHfHh/tQK7DzbtZ/5moeD8z0FxOEQP2MwP3dTQ+v5nvPhcL5W/POSQyd8nwJxuoGfxZnf68PctU4x0izXh99PvsZ9GgnX+d+ap5bwK7JzmJTvRR/a4vvSP//5vannZaOEF9XzIyIiIqWixo+IiIiUiho/IiIiUio9nvPj430cC+Th5UAcz/RxT8758YpyAnwckoc2T58+ParjGLPPR+AchGaJG7enuu+pYcw+54Df++STT0Z1fC5TeRq85AgQL0/icw44bs25Xf5c8rXiryPOLfH5W5zn43MVOB8ttWSGx3X+96v+5o0S966Vv0ZS1z3n9fghynye+N70208NZeYh0D7noZnvR1Y9Dp9DyPemz8Hh93KuI5BedZ3zg/y9yUta+Fwh/u15BXG/7AHnhvhcQM5F8tMdTJ06tXCfU8slpK6B1L1ZrWv0a4j3z+f1pPadl4jyebL8fONt+uce51r5fKBmy4VVz4+IiIiUiho/IiIiUirWmS4+M+u1/kAfDhk1alRe9jOWcpdeKuzFw9v9TJncPdpI3aAhhLosB25modrtm1qV2w9xTnUbMx+W5Jl9fdf6jjvumJf9ytHcnc7nyHd1c/hq9uzZUR2fd38NcHjOh+r4O/xvxNdE6vfzuPu3Xucy+86GuUj5XvXXAV8z/Fv4sJcPczSDet6bRTM8s9S9mZoJ2oc8eKoJXtEbiJ+zY8eOjep4egm+N/1Q80mTJuVlHyrh57OftoDvP/98Tg1nTz27U/em+1zdzmU9ttPF745ec9iLp5EB4nAq34v+d+ch8U0Uun86hDDe/6N6fkRERKRU1PgRERGRUlHjR0REREqlaXJ+pKJeseg+ffqEapw3lbPi6zhnIxXzTeUceBxv5hyfjval6H2p1cn9Nji+3Zm8Hj6+1MrRXnfkFWTfqXuzl9UzT6Q7701/fab+BvC96Zee6cq9mfpuvw2+r1L3Zur7/L3J923qOdEKOT+SU86PiIiIiBo/IiIiUio9PsOzNIYQQk0zmnam252HOKdm9PRD5HkWUT+Eld/L350a6pqalToVkvL4+Pzn+LX/Pu5aLzqeRpzxVBpHURjJhWYK6/znOWTVmXB1arqHohBSavudWaW+Hvz31RISa6Ih3LIe1PMjIiIipaLGj4iIiJSKGj8iIiJSKsr5KbFqbDs1/DQ1hb7/HMfvUzkHfimDVB4Rx+V5Gz6Xhqfa9/gY/D7zvvhj7cSQ9cJ99ttQPoHUoujeZKlry1/LblmVqK5oyRH/Hf7aLfq+1L2fWm4i9TzpzNQZqRxGPj6/zUZaxki6n3p+REREpFTU+BEREZFS6WzYaxGA2R2+S7rLiI7fUrNFIYTZQNe7ezvzudTQ9Fq341dyZ3714a7ojuHniWOr57kEdG/2trrem8jOZU/cm7Ve952ZEoP5MHdXdEe4OLHNbjmX0mvaPZ+dWt5CREREpNkp7CUiIiKlosaPiIiIlIoaPyIiIlIqavyIiIhIqajxIyIiIqWixo+IiIiUiho/IiIiUipq/IiIiEipqPEjIiIipfL/AaWirkuKoPq5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x324 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/100], \tTraining Loss:21.5823 \tValidation Loss:15.4415\n",
            "epoch [2/100], \tTraining Loss:14.4696 \tValidation Loss:13.8313\n",
            "epoch [3/100], \tTraining Loss:12.8703 \tValidation Loss:12.1802\n",
            "epoch [4/100], \tTraining Loss:11.2557 \tValidation Loss:10.6405\n",
            "epoch [5/100], \tTraining Loss:10.2494 \tValidation Loss:9.9425\n",
            "epoch [6/100], \tTraining Loss:9.5701 \tValidation Loss:9.2676\n",
            "epoch [7/100], \tTraining Loss:9.0465 \tValidation Loss:8.9102\n",
            "epoch [8/100], \tTraining Loss:8.7271 \tValidation Loss:8.6099\n",
            "epoch [9/100], \tTraining Loss:8.4261 \tValidation Loss:8.2512\n",
            "epoch [10/100], \tTraining Loss:8.0585 \tValidation Loss:7.9137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY0yZ0J3SxTe",
        "outputId": "13c1b6b0-7a61-4b86-d496-8ebe9031b0b5"
      },
      "source": [
        "for param in model2.named_parameters():\n",
        "  print(param)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('encoder.encoder.0.weight', Parameter containing:\n",
            "tensor([[ 0.0142,  0.0087, -0.0357,  ..., -0.0263,  0.0060,  0.0039],\n",
            "        [ 0.0103,  0.0356,  0.0210,  ..., -0.0140,  0.0240,  0.0322],\n",
            "        [-0.0054,  0.0077,  0.0088,  ...,  0.0332,  0.0337, -0.0311],\n",
            "        ...,\n",
            "        [ 0.0203,  0.0126, -0.0319,  ...,  0.0258, -0.0238, -0.0239],\n",
            "        [ 0.0003,  0.0206, -0.0031,  ...,  0.0236,  0.0008, -0.0047],\n",
            "        [-0.0162, -0.0195,  0.0143,  ...,  0.0134,  0.0330,  0.0240]],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.0.bias', Parameter containing:\n",
            "tensor([-0.0626,  0.4047,  0.0165, -0.0318, -0.0063,  0.1092,  0.0466, -0.0346,\n",
            "         0.1345, -0.0389,  0.2244,  0.0056, -0.0250,  0.0489, -0.0942,  0.0906,\n",
            "         0.0500,  0.2363, -0.0111,  0.0572, -0.0281,  0.0026,  0.2367,  0.1138,\n",
            "        -0.0110,  0.1233, -0.0459, -0.0226, -0.0305, -0.0658,  0.2023,  0.0149,\n",
            "         0.1647,  0.0255,  0.0140,  0.1280,  0.0356,  0.0774,  0.0726, -0.0162,\n",
            "         0.2012,  0.0225,  0.2585,  0.0235, -0.0290,  0.0776,  0.3370,  0.0184,\n",
            "         0.0029,  0.0332, -0.1122, -0.0289, -0.0236,  0.0165,  0.0337,  0.1126,\n",
            "        -0.0285,  0.2247, -0.0028, -0.0049, -0.0242, -0.0992,  0.2677,  0.0261,\n",
            "        -0.0512,  0.0141, -0.0089, -0.0234, -0.0321, -0.0073, -0.0448,  0.0722,\n",
            "         0.4300,  0.1518,  0.0069,  0.2117,  0.0545,  0.0625, -0.0008,  0.1430,\n",
            "        -0.0370, -0.0695, -0.0347,  0.2060,  0.0915,  0.1544, -0.0849,  0.0862,\n",
            "        -0.0420,  0.0704,  0.1062,  0.0205,  0.0294,  0.1203, -0.0044, -0.0442,\n",
            "         0.0012,  0.1255, -0.1811,  0.0217,  0.0722,  0.1003,  0.0783, -0.0054,\n",
            "         0.1007, -0.0017,  0.1714,  0.0068, -0.0177,  0.1839,  0.0032, -0.0376,\n",
            "        -0.0404, -0.0693,  0.2505, -0.0318, -0.0359, -0.0252, -0.0014,  0.0483,\n",
            "         0.0914,  0.0811,  0.0040, -0.0103, -0.2205, -0.1490, -0.0176,  0.0166],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.2.weight', Parameter containing:\n",
            "tensor([[ 0.2117, -0.1107,  0.1381,  ...,  0.0325,  0.0056, -0.0389],\n",
            "        [-0.1259,  0.1978,  0.2775,  ...,  0.0781, -0.0710, -0.0795],\n",
            "        [ 0.2344, -0.1395, -0.1203,  ..., -0.1936,  0.0137,  0.0720],\n",
            "        ...,\n",
            "        [ 0.0284, -0.0465,  0.0678,  ...,  0.0258,  0.0718, -0.0779],\n",
            "        [ 0.2203,  0.2201,  0.0803,  ..., -0.0092, -0.0261, -0.0374],\n",
            "        [ 0.1288,  0.1170,  0.1399,  ..., -0.0591, -0.0313, -0.0775]],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.2.bias', Parameter containing:\n",
            "tensor([ 0.2726,  0.0898, -0.2900, -0.1164, -0.0350, -0.0947,  0.0122,  0.0378,\n",
            "        -0.0872, -0.0715,  0.0958, -0.0658,  0.1662, -0.0432,  0.1322, -0.0443,\n",
            "        -0.0943,  0.0068, -0.0454, -0.0089,  0.0611,  0.0053, -0.0732,  0.0303,\n",
            "         0.1324,  0.1463,  0.0034, -0.0803,  0.2128,  0.0336, -0.2104,  0.2655,\n",
            "         0.0793, -0.0255,  0.0743, -0.0455, -0.0517, -0.0933, -0.1074, -0.0907,\n",
            "        -0.1162, -0.1169,  0.0967, -0.0442, -0.1813, -0.0058,  0.0552, -0.0267,\n",
            "        -0.3801,  0.3299, -0.0525,  0.0005,  0.0698,  0.1724,  0.2540,  0.0570,\n",
            "         0.0470, -0.0378,  0.1156, -0.0999,  0.2794,  0.0097,  0.1406,  0.1286],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.4.weight', Parameter containing:\n",
            "tensor([[ 7.9640e-01, -1.2685e-02,  2.7699e-01,  ..., -1.1501e-01,\n",
            "          1.5955e-01,  7.3582e-02],\n",
            "        [ 9.6361e-01,  8.0053e-02, -1.7488e-01,  ..., -1.0039e-01,\n",
            "          1.0261e-01,  6.2273e-02],\n",
            "        [ 3.1232e-01,  1.7499e-01, -3.6936e-01,  ..., -2.3028e-03,\n",
            "          7.7024e-02,  1.6946e-01],\n",
            "        ...,\n",
            "        [ 1.1375e-01,  9.9298e-02,  2.0871e-02,  ..., -2.5805e-02,\n",
            "         -9.5036e-02,  5.6946e-04],\n",
            "        [ 1.5559e-01,  3.2634e-02,  4.1993e-01,  ..., -8.2020e-02,\n",
            "          1.4492e-01,  3.9023e-02],\n",
            "        [-1.8113e-01,  7.8606e-02, -5.2031e-01,  ..., -6.5206e-02,\n",
            "          1.6174e-01, -2.6329e-02]], requires_grad=True))\n",
            "('encoder.encoder.4.bias', Parameter containing:\n",
            "tensor([-0.1099,  0.1465,  0.1058, -0.0835,  0.0822,  0.0687,  0.0953,  0.1170,\n",
            "        -0.0538,  0.2530,  0.1948, -0.0806,  0.0674,  0.0415,  0.1556, -0.0616],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.6.weight', Parameter containing:\n",
            "tensor([[-1.8553e-01, -3.2433e-01, -2.4582e-01,  3.4264e-01, -5.1192e-02,\n",
            "          2.2765e-01, -5.4226e-02, -2.1979e-01,  2.4571e-01, -1.4466e-01,\n",
            "         -1.9776e-02,  9.8085e-03,  1.7044e-01,  9.6801e-02,  2.3912e-01,\n",
            "         -1.4510e-01],\n",
            "        [-3.1609e-01, -1.2312e-01,  1.4379e-01,  8.8199e-02, -2.1391e-01,\n",
            "          2.5733e-01,  4.5714e-02,  8.0462e-02,  1.0599e-01,  2.0858e-02,\n",
            "          1.8499e-01, -4.0419e-02, -1.2345e-01, -2.6550e-02, -8.0043e-02,\n",
            "          2.8968e-01],\n",
            "        [-2.2468e-01, -1.3736e-02, -1.8616e-01, -1.5807e-01, -9.0415e-03,\n",
            "         -1.0363e-01, -1.7054e-01, -2.1408e-01, -2.2803e-01,  7.7874e-01,\n",
            "         -4.2499e-02, -2.4992e-01, -2.8187e-02,  1.3355e-01, -2.9259e-01,\n",
            "         -2.0083e-01],\n",
            "        [-1.1178e-01, -1.1985e-01, -1.7988e-01, -2.9670e-02, -1.0457e-01,\n",
            "         -1.4234e-01, -3.7532e-02, -2.4290e-02,  8.5394e-02, -3.2119e-01,\n",
            "         -2.0776e-01, -2.0559e-01, -1.3491e-02, -2.1691e-01, -2.9507e-01,\n",
            "          2.0533e-01],\n",
            "        [ 2.4641e-02, -2.5665e-02, -1.5433e-01,  2.6112e-01,  2.2740e-01,\n",
            "         -7.4283e-02, -1.1162e-01,  4.4467e-02, -2.1881e-01,  4.0893e-02,\n",
            "         -3.4020e-01, -2.6172e-01,  4.4163e-02, -1.2304e-01, -3.9277e-01,\n",
            "          1.5207e-01],\n",
            "        [ 3.5172e-01,  9.3501e-02, -1.1936e-01, -3.1851e-01, -2.1758e-01,\n",
            "         -4.0699e-02, -1.1316e-01,  1.4713e-01, -2.1337e-01, -2.0488e-01,\n",
            "         -2.2978e-01,  1.1803e-01, -2.0988e-01, -1.3009e-01,  1.3001e-01,\n",
            "          1.8439e-01],\n",
            "        [-3.8932e-01, -7.4343e-02,  1.1381e-01, -2.7857e-01,  8.8430e-03,\n",
            "          6.2940e-02, -1.4170e-01,  1.2976e-01, -1.1444e-01, -1.4496e-01,\n",
            "          8.0509e-02, -2.2147e-01,  1.7855e-01, -2.4715e-02, -2.3312e-01,\n",
            "          2.9734e-02],\n",
            "        [-4.3188e-01,  2.0290e-01, -2.2559e-02,  3.0153e-01,  3.6834e-04,\n",
            "         -2.5321e-02, -1.9703e-01, -3.2923e-02, -1.0505e-01,  8.1740e-04,\n",
            "         -3.7848e-01, -6.0756e-02, -1.6329e-01,  1.1009e-01,  2.2463e-01,\n",
            "          3.6092e-02]], requires_grad=True))\n",
            "('encoder.encoder.6.bias', Parameter containing:\n",
            "tensor([-0.2137,  0.3108,  0.1323,  0.0542, -0.1174,  0.2055,  0.1963,  0.0270],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.0.weight', Parameter containing:\n",
            "tensor([[ 3.0565e-01,  3.5721e-01,  3.3465e-02, -1.0186e-01, -2.4452e-01,\n",
            "          1.9449e-01, -2.3141e-01,  5.2753e-01],\n",
            "        [-2.1914e-01,  2.2015e-01, -9.0414e-03, -5.0139e-02,  6.1864e-02,\n",
            "         -9.1593e-02,  2.7935e-01, -3.0155e-01],\n",
            "        [ 3.2542e-01, -1.9176e-02,  6.6199e-03, -2.3646e-01,  2.2202e-01,\n",
            "          3.3240e-01, -5.5803e-01, -1.9994e-02],\n",
            "        [-3.0255e-01,  8.0312e-02,  1.7529e-01, -1.3953e-01, -2.7499e-01,\n",
            "          7.7106e-02,  5.3746e-01, -1.8041e-01],\n",
            "        [-2.7050e-01, -1.3921e-01,  2.6177e-01, -2.0518e-01, -1.6211e-01,\n",
            "          1.5431e-01, -4.2107e-01,  3.1297e-01],\n",
            "        [ 1.9400e-01,  3.8719e-01, -3.0818e-01, -3.4997e-02,  1.5701e-01,\n",
            "         -1.8316e-01, -4.3012e-01, -2.3882e-01],\n",
            "        [-1.9403e-01, -2.5478e-01, -1.8670e-01,  1.6488e-01, -3.4463e-01,\n",
            "          5.4816e-02,  2.1729e-01, -5.2415e-02],\n",
            "        [-3.9280e-01,  3.6444e-01, -8.6027e-02, -3.2741e-01, -1.7054e-01,\n",
            "          2.9357e-01, -5.2342e-02,  1.0880e-01],\n",
            "        [ 1.9801e-02,  1.0860e-02, -2.4133e-01,  1.2050e-01, -3.5679e-01,\n",
            "          7.2012e-02,  3.1898e-01,  3.6831e-01],\n",
            "        [-4.1238e-02, -3.0628e-03, -1.4740e-01, -1.3069e-01, -3.2067e-01,\n",
            "          8.3649e-02, -2.2181e-01, -5.2337e-01],\n",
            "        [-2.0975e-01,  3.5841e-01,  9.2212e-02,  2.3849e-01,  3.8440e-01,\n",
            "         -4.5022e-04,  1.2979e-01,  2.9974e-01],\n",
            "        [-1.6009e-01, -2.8879e-01, -2.3496e-01, -1.3931e-01, -8.7085e-03,\n",
            "          3.1189e-01, -2.3913e-01, -3.3359e-02],\n",
            "        [ 3.2538e-01,  2.4486e-01,  2.8030e-01,  1.0714e-01,  2.0485e-01,\n",
            "          3.1483e-01,  1.0454e-01, -1.7680e-01],\n",
            "        [ 2.9262e-01,  2.6602e-01, -7.0354e-02, -3.7831e-01, -5.2074e-01,\n",
            "         -3.4369e-01,  5.2122e-02,  1.5497e-01],\n",
            "        [-2.3981e-01, -1.3574e-02,  3.9740e-01,  2.0856e-01, -2.4947e-01,\n",
            "          1.2462e-01, -3.0239e-02,  2.7657e-01],\n",
            "        [ 1.0383e-01,  3.3894e-02,  2.3233e-01,  2.5286e-01,  1.9544e-01,\n",
            "         -3.5448e-02, -2.5894e-01,  1.7020e-01]], requires_grad=True))\n",
            "('decoder.decoder.0.bias', Parameter containing:\n",
            "tensor([ 0.2170,  0.3484, -0.2474,  0.0147,  0.0564, -0.2137,  0.3550,  0.1400,\n",
            "         0.1023,  0.2474,  0.2625,  0.2510, -0.1487,  0.1202, -0.3179,  0.3179],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.2.weight', Parameter containing:\n",
            "tensor([[ 0.4550,  0.1257, -0.0141,  ...,  0.3910, -0.1508,  0.2660],\n",
            "        [-0.2731,  0.3027, -0.2048,  ...,  0.2403,  0.2220,  0.2212],\n",
            "        [ 0.4862, -0.1876, -0.4312,  ...,  0.1645, -0.0967, -0.1292],\n",
            "        ...,\n",
            "        [ 0.2871, -0.1755, -0.0958,  ...,  0.5081,  0.2129, -0.1014],\n",
            "        [-0.2815,  0.2534, -0.3380,  ...,  0.3879,  0.0988, -0.1653],\n",
            "        [ 0.1893, -0.0547, -0.0198,  ...,  0.3914,  0.1398,  0.0933]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.2.bias', Parameter containing:\n",
            "tensor([-0.0359,  0.0388,  0.1433,  0.1217, -0.1222,  0.3307,  0.4072, -0.0231,\n",
            "        -0.5803,  0.3112, -0.4010,  0.2443,  0.2613,  0.3874,  0.2083,  0.1698,\n",
            "        -0.2169,  0.0349, -0.2650, -0.0166, -0.0008, -0.2776, -0.1813, -0.5039,\n",
            "         0.2667, -0.1138,  0.1309,  0.0048, -0.0416,  0.2833,  0.0915, -0.2558,\n",
            "         0.2615,  0.2718,  0.3912,  0.0013,  0.0449,  0.1625,  0.1137, -0.2769,\n",
            "        -0.3051,  0.0803,  0.1880,  0.0239,  0.3748,  0.0118, -0.2429,  0.3186,\n",
            "         0.1913,  0.1397,  0.2275, -0.1913,  0.3709,  0.2632,  0.1784,  0.3184,\n",
            "         0.2778, -0.1962,  0.3217,  0.0623,  0.1910,  0.3508,  0.0399,  0.3589],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.4.weight', Parameter containing:\n",
            "tensor([[ 0.0565,  0.0171,  0.0188,  ...,  0.0987,  0.1173,  0.1536],\n",
            "        [ 0.1393, -0.1161,  0.0311,  ..., -0.3135,  0.1201,  0.0755],\n",
            "        [ 0.0218,  0.0205, -0.0096,  ..., -0.3853,  0.0061, -0.1554],\n",
            "        ...,\n",
            "        [-0.0556, -0.0433, -0.0670,  ...,  0.0939,  0.0120, -0.0244],\n",
            "        [-0.0826, -0.0812, -0.0731,  ..., -0.0274, -0.0613, -0.0296],\n",
            "        [ 0.0680,  0.0354,  0.0327,  ..., -0.0872,  0.0859, -0.0795]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.4.bias', Parameter containing:\n",
            "tensor([-0.0577,  0.0840, -0.2694,  0.1176,  0.1011, -0.0077, -0.0995,  0.0582,\n",
            "        -0.0130,  0.1264,  0.0361,  0.0533, -0.1020,  0.1151,  0.1838, -0.0885,\n",
            "        -0.1591, -0.0945, -0.0892, -0.1744,  0.1394,  0.1386, -0.0108,  0.0483,\n",
            "         0.1944,  0.1383, -0.0016,  0.1765,  0.1926, -0.0989,  0.0331,  0.1190,\n",
            "        -0.0496,  0.1823, -0.3049,  0.0020,  0.0929,  0.1499,  0.1837, -0.2040,\n",
            "         0.1446,  0.0011, -0.0970, -0.1000,  0.0466, -0.1412,  0.0251,  0.0311,\n",
            "         0.2119, -0.0325,  0.0412,  0.0849,  0.0813,  0.0525, -0.5420,  0.1892,\n",
            "         0.1956,  0.0805, -0.2842,  0.1108,  0.1216,  0.3776, -0.1346, -0.2134,\n",
            "         0.1484, -0.0738,  0.0759,  0.2084, -0.0549,  0.1548,  0.0522, -0.0853,\n",
            "         0.1148, -0.0072, -0.0399, -0.0170, -0.0550,  0.0884,  0.0009,  0.2917,\n",
            "        -0.1004,  0.1130,  0.0586,  0.0363,  0.1597,  0.0300,  0.1810, -0.1809,\n",
            "         0.0119,  0.0130,  0.0776,  0.1635, -0.1013,  0.2060, -0.1025,  0.0408,\n",
            "         0.1684,  0.1132, -0.1824, -0.0939, -0.0359,  0.1270, -0.0833,  0.3071,\n",
            "        -0.0510, -0.0603,  0.0665, -0.0651, -0.1218,  0.0723,  0.1892,  0.0952,\n",
            "        -0.0334,  0.0937, -0.0726, -0.1320,  0.1172, -0.3367,  0.2859, -0.0952,\n",
            "        -0.0475,  0.2839,  0.1079, -0.4679,  0.1891, -0.0564, -0.1234,  0.0180],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.6.weight', Parameter containing:\n",
            "tensor([[-0.0239, -0.0561, -0.1075,  ..., -0.0787, -0.0137, -0.0624],\n",
            "        [-0.0295, -0.1205, -0.1076,  ...,  0.0102,  0.0504, -0.0718],\n",
            "        [-0.0585,  0.0202, -0.1271,  ..., -0.0454,  0.0828,  0.0412],\n",
            "        ...,\n",
            "        [-0.1131, -0.0217, -0.2633,  ...,  0.0195,  0.0858,  0.0287],\n",
            "        [-0.0840,  0.0177, -0.2264,  ..., -0.0501, -0.0761,  0.0100],\n",
            "        [-0.0213, -0.0491, -0.2802,  ..., -0.0087,  0.0095, -0.0568]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.6.bias', Parameter containing:\n",
            "tensor([-6.9632e-03, -7.5988e-03, -1.8377e-02, -5.8131e-02, -8.6429e-02,\n",
            "        -3.0369e-02,  9.8303e-03, -1.0116e-01, -6.9382e-02, -4.0913e-02,\n",
            "         3.5446e-02, -3.7800e-02, -1.2170e-01,  3.8185e-02, -1.0552e-02,\n",
            "        -8.2669e-02,  4.6793e-02, -8.4020e-02, -9.2043e-02, -6.7359e-02,\n",
            "        -5.0620e-02,  4.7192e-02, -1.1226e-01, -1.7278e-02, -9.6671e-02,\n",
            "        -7.8187e-02, -1.0482e-01, -7.0238e-02, -4.9751e-02,  2.5636e-02,\n",
            "        -8.5288e-03, -7.4845e-02, -6.2106e-02, -7.6538e-02, -9.1218e-02,\n",
            "        -9.4719e-02, -3.6350e-02, -9.6428e-02,  1.1188e-03, -9.5117e-02,\n",
            "         2.8151e-02, -9.2526e-02, -3.5544e-02,  1.2453e-02, -2.7345e-02,\n",
            "        -3.7753e-02, -1.1526e-01, -3.8413e-02, -2.8747e-03,  4.7896e-02,\n",
            "        -4.3373e-02, -3.1863e-02, -1.9806e-02, -9.8044e-02, -9.1729e-02,\n",
            "        -7.8089e-02,  3.0608e-02, -1.1497e-01, -3.1458e-03, -5.7596e-02,\n",
            "        -5.4939e-03, -4.1890e-02, -7.1134e-02,  3.9516e-02, -1.0550e-02,\n",
            "        -8.3240e-02, -2.4748e-02, -2.0078e-03, -1.2237e-02, -5.1819e-02,\n",
            "        -6.5698e-03,  6.0974e-03, -4.2046e-02, -4.1796e-02, -1.0384e-01,\n",
            "        -6.9615e-02, -8.6339e-02, -1.1320e-01, -1.3849e-02, -2.5691e-02,\n",
            "        -9.4880e-02, -6.8378e-02, -7.8096e-02, -7.3586e-02,  4.0858e-02,\n",
            "        -5.4069e-03,  2.4708e-02, -6.5273e-02,  3.0467e-02,  4.5287e-02,\n",
            "        -2.8856e-02, -1.1221e-01, -6.6675e-02, -2.5789e-02, -5.6327e-02,\n",
            "        -8.2417e-02, -1.0794e-01, -1.3845e-02, -8.2654e-02, -1.2648e-01,\n",
            "        -1.0080e-02, -1.1082e-01, -7.5514e-02, -1.2492e-01,  3.3746e-02,\n",
            "        -9.0952e-02, -9.1264e-02,  4.7466e-02, -8.4201e-02, -1.0472e-01,\n",
            "        -1.5360e-02, -4.6367e-02, -6.6261e-03,  3.3488e-02, -3.1820e-02,\n",
            "        -3.1047e-03, -6.8077e-02, -6.9140e-02,  1.7370e-02, -4.5540e-02,\n",
            "        -5.8773e-03, -7.2723e-02, -1.0999e-01,  3.5634e-03,  8.8049e-03,\n",
            "        -1.0599e-01, -1.5312e-01, -7.2812e-02, -3.8527e-02, -1.7570e-01,\n",
            "        -2.9792e-02, -1.4427e-02, -1.2487e-01, -6.0113e-02, -3.3255e-02,\n",
            "        -8.3559e-02, -9.9632e-02, -8.5173e-02, -3.5391e-02, -3.5308e-02,\n",
            "        -9.0712e-02, -4.6992e-02, -4.5851e-03, -5.5877e-02,  3.3649e-02,\n",
            "         3.7456e-02, -6.3317e-02, -5.1189e-02, -6.9118e-02, -7.5411e-02,\n",
            "        -7.8309e-02, -5.2055e-03, -2.9977e-02, -1.0776e-01, -7.1009e-02,\n",
            "        -9.3146e-02, -1.2356e-01, -1.4534e-01, -1.3412e-01, -1.0602e-01,\n",
            "        -1.2360e-01, -1.0923e-01,  4.8802e-02,  4.2337e-02, -4.2140e-02,\n",
            "        -2.8659e-02, -1.0472e-01,  4.3835e-02, -2.3130e-03, -7.0302e-03,\n",
            "         2.5906e-03,  4.3839e-02, -4.9234e-02, -1.2479e-01,  2.4636e-02,\n",
            "        -9.7887e-02, -6.3047e-02, -5.8423e-02, -1.8658e-02, -4.7242e-02,\n",
            "        -4.6659e-02, -8.7381e-02, -3.2748e-02, -1.7313e-01, -1.6548e-01,\n",
            "        -1.7297e-01, -1.0226e-01, -1.7933e-01, -1.1437e-01, -5.7735e-03,\n",
            "        -8.3735e-02, -1.3555e-02, -1.0624e-01,  1.3490e-02,  2.1937e-02,\n",
            "        -1.4889e-04, -1.5384e-02,  4.3013e-02, -1.6597e-02, -9.6061e-02,\n",
            "        -5.3558e-02, -3.1608e-02, -4.0023e-02, -2.8701e-02,  4.2253e-02,\n",
            "         3.6320e-02,  1.5673e-02, -9.7391e-03, -8.2586e-02, -1.7121e-01,\n",
            "        -2.0843e-01, -1.9684e-01, -2.5406e-01, -2.3740e-01, -6.5683e-02,\n",
            "        -1.6845e-01, -8.8338e-02,  3.4444e-02, -2.9217e-02,  5.6008e-02,\n",
            "        -9.4136e-02, -9.1479e-02, -1.2371e-01,  3.8283e-02, -1.1517e-01,\n",
            "        -4.1678e-02,  3.7290e-02, -1.0944e-01, -9.4247e-02, -7.9420e-02,\n",
            "         1.9373e-02,  2.8693e-02, -6.4358e-02, -5.9099e-02, -2.2349e-02,\n",
            "        -1.3979e-01, -2.7222e-01, -1.5962e-01, -3.1206e-01, -1.7311e-01,\n",
            "        -3.0440e-01, -2.0770e-01, -1.5062e-01, -1.7225e-01, -7.3648e-02,\n",
            "        -2.4065e-02,  5.1135e-02, -1.8114e-02, -5.5632e-02, -1.0576e-01,\n",
            "        -9.8248e-02, -2.9822e-02, -7.1776e-03, -4.6194e-02,  2.1778e-02,\n",
            "         1.7146e-02,  1.3448e-02, -5.6942e-02, -3.6812e-02, -7.4721e-04,\n",
            "        -9.5283e-02, -1.4163e-01, -2.3098e-01, -3.0909e-01, -1.5992e-01,\n",
            "        -1.6840e-01, -2.7384e-01, -2.5981e-01, -1.7327e-01, -1.8738e-01,\n",
            "        -2.1467e-01, -1.3024e-01, -8.8999e-02,  1.1222e-01,  9.7110e-02,\n",
            "        -2.2405e-02, -1.5776e-02,  1.3818e-02, -3.8304e-02, -9.9011e-02,\n",
            "        -1.2503e-01,  3.0140e-02, -1.0758e-01, -1.0568e-01, -7.4772e-02,\n",
            "         9.4933e-03,  9.3439e-03, -2.6505e-02,  5.5819e-02, -1.3114e-01,\n",
            "        -1.4702e-01, -2.8738e-01, -2.2645e-01, -2.2907e-01, -2.2381e-01,\n",
            "        -2.4085e-01, -2.5700e-01, -2.4289e-01, -2.4370e-01, -1.0805e-01,\n",
            "        -9.0124e-02, -4.8465e-03, -8.6344e-02, -8.7064e-02, -1.4845e-02,\n",
            "        -2.8163e-02, -2.7064e-02, -7.6437e-02, -1.0879e-01, -9.8991e-02,\n",
            "        -3.2774e-02, -9.8995e-02, -7.4480e-02, -5.1757e-02,  5.0074e-02,\n",
            "        -1.0691e-01, -2.6159e-02, -1.9708e-01, -1.9125e-01, -2.9223e-01,\n",
            "        -5.1515e-02, -1.0233e-01, -1.3409e-01, -2.4806e-01, -2.2682e-01,\n",
            "        -1.8820e-01, -2.1857e-01, -3.3583e-02,  6.0315e-02, -5.1465e-02,\n",
            "         4.8555e-02, -6.8240e-03, -2.8807e-02, -9.1099e-03, -3.0156e-02,\n",
            "        -7.1605e-02, -8.5064e-02, -9.7038e-02, -1.0457e-01, -1.0003e-01,\n",
            "        -9.9169e-02, -9.9156e-02, -9.0142e-02, -7.7390e-02, -2.9257e-02,\n",
            "        -7.5641e-02, -1.9306e-01, -1.5066e-01, -1.7229e-01, -9.6692e-02,\n",
            "        -2.3493e-01, -2.6540e-01, -2.7722e-01, -2.3916e-01, -2.3055e-01,\n",
            "        -4.6171e-02,  6.6017e-02, -7.2339e-02, -9.7982e-02, -8.3986e-02,\n",
            "        -5.1642e-02, -9.9930e-03, -7.9017e-02, -1.1122e-01, -8.0664e-02,\n",
            "        -8.4184e-02, -4.0825e-02, -1.0320e-01, -3.8104e-02, -2.5083e-02,\n",
            "         4.9828e-02, -1.1043e-01, -3.6954e-02, -1.0222e-01, -5.3684e-02,\n",
            "        -4.3994e-02, -4.1162e-02, -8.1274e-02, -2.2953e-01, -2.5956e-01,\n",
            "        -3.0020e-01, -2.1937e-01, -1.9616e-01, -9.2053e-02,  5.1296e-02,\n",
            "        -4.8513e-03,  1.5290e-03, -2.4569e-03, -6.6828e-02,  1.7826e-02,\n",
            "        -9.5818e-02, -4.2823e-02, -5.4452e-02, -1.4781e-02,  2.4671e-02,\n",
            "        -4.7117e-02, -9.5182e-02,  4.1320e-02, -1.9578e-02,  4.1328e-02,\n",
            "        -1.0594e-01, -1.3070e-01, -7.0018e-02, -4.9537e-02,  1.7579e-02,\n",
            "        -8.0375e-02, -2.2922e-01, -2.3622e-01, -2.3527e-01, -1.3792e-01,\n",
            "        -1.1704e-01,  5.7432e-02,  1.1838e-02,  3.7072e-02, -3.0498e-02,\n",
            "        -2.0064e-02,  3.2064e-02,  1.3693e-02, -7.3208e-02,  3.7102e-03,\n",
            "        -4.2628e-02, -3.0583e-02, -5.9879e-02,  1.2138e-03, -6.8175e-02,\n",
            "         2.5636e-02, -7.6194e-02, -2.3387e-02, -6.1675e-02, -1.7850e-01,\n",
            "        -9.4709e-02, -6.5543e-02, -1.1498e-01, -1.8698e-01, -1.5429e-01,\n",
            "        -1.4869e-01, -2.1208e-01, -5.8256e-02, -2.6626e-02, -1.2234e-02,\n",
            "         5.4668e-02, -1.0396e-01, -6.2902e-02,  2.1947e-02, -3.9644e-02,\n",
            "        -9.5066e-02,  4.5419e-02,  3.7702e-03, -1.0780e-01,  3.4784e-02,\n",
            "        -1.1163e-01, -5.8842e-02, -7.2088e-03, -1.7463e-02, -3.9732e-02,\n",
            "         3.2380e-02, -1.3387e-01, -7.1571e-02, -1.7233e-01, -1.6886e-01,\n",
            "        -1.2077e-01, -9.0451e-02, -7.3861e-02, -1.2707e-01, -6.8902e-02,\n",
            "        -7.9184e-02, -1.4842e-02, -1.6535e-02, -3.0052e-03, -1.3882e-02,\n",
            "        -8.8538e-02,  1.3757e-03,  1.2926e-02, -9.7075e-02,  4.6489e-02,\n",
            "        -4.1657e-02,  2.6493e-02,  1.3849e-02,  4.1116e-02,  4.0473e-02,\n",
            "        -3.4892e-03,  2.5635e-02, -1.1263e-01, -2.7959e-02, -2.1253e-02,\n",
            "        -6.1138e-02, -4.5919e-02, -1.7940e-01, -1.6590e-02, -1.5093e-01,\n",
            "        -3.5043e-02, -5.7747e-02, -9.4128e-02, -6.1016e-02,  9.4822e-04,\n",
            "        -7.5599e-03, -2.4242e-02, -8.6876e-02,  3.8720e-02, -8.1069e-02,\n",
            "         4.6872e-02, -5.8484e-02,  5.8764e-03,  5.9920e-03, -4.6471e-02,\n",
            "        -1.1698e-01, -3.8058e-02,  4.0263e-02,  5.6745e-02,  4.4001e-03,\n",
            "        -9.8860e-03,  1.3693e-02,  6.1801e-03, -1.2803e-01, -6.9438e-02,\n",
            "        -7.6879e-03, -1.2766e-02, -1.3515e-01, -1.9967e-01, -1.5736e-01,\n",
            "        -8.5777e-02, -2.1500e-02, -5.4996e-02,  4.2692e-02,  3.6679e-02,\n",
            "        -2.6264e-02, -4.0443e-02, -2.8251e-02, -8.3470e-02, -1.1803e-01,\n",
            "        -1.8252e-02, -4.8156e-02,  4.7191e-02, -5.0014e-02, -3.5933e-02,\n",
            "        -7.6363e-02, -7.1818e-02, -3.9041e-02, -3.7984e-02,  5.2174e-02,\n",
            "         9.1823e-03,  2.7344e-02,  5.8210e-02,  6.0626e-03, -7.5270e-02,\n",
            "        -1.7398e-01, -9.8617e-02, -1.1754e-01, -1.9237e-01, -1.2396e-01,\n",
            "        -3.5439e-02,  6.0912e-02, -5.8854e-02,  2.5993e-02,  5.3244e-02,\n",
            "         3.1510e-02,  1.3606e-02,  2.8666e-03, -3.4437e-02, -7.7656e-02,\n",
            "        -4.6027e-02, -5.9431e-02, -1.1391e-01,  4.5633e-02,  3.4737e-02,\n",
            "         3.9627e-03,  1.5754e-02,  3.0758e-02,  8.8903e-02,  2.7429e-02,\n",
            "         3.8499e-02, -9.0349e-02, -7.9837e-02, -1.9031e-01, -3.2955e-01,\n",
            "        -2.4709e-01, -2.5330e-01, -1.9164e-01, -1.2313e-01,  5.9088e-02,\n",
            "         1.5793e-02, -6.9142e-02, -9.6766e-02, -3.8164e-02, -4.5193e-02,\n",
            "        -9.8787e-02, -9.2684e-03,  1.0101e-02, -1.0114e-01, -9.9241e-02,\n",
            "        -7.3725e-02,  4.4445e-02, -3.6198e-02, -5.9199e-02, -7.1190e-02,\n",
            "         2.3286e-02, -3.0562e-02,  1.8754e-02, -6.1994e-02, -1.2365e-01,\n",
            "        -1.7303e-01, -1.8196e-01, -3.1991e-01, -3.3307e-01, -2.5267e-01,\n",
            "        -8.8570e-02,  2.2673e-02, -9.1289e-02,  1.2568e-02, -9.5413e-02,\n",
            "         1.6562e-02,  4.4062e-04, -7.1369e-02,  2.7835e-02, -4.7012e-02,\n",
            "        -4.7972e-02,  4.3569e-02, -9.5820e-02,  3.0825e-02, -2.0660e-02,\n",
            "         4.5832e-02, -4.4403e-02,  3.3487e-02, -1.0478e-01, -8.5301e-02,\n",
            "        -1.0525e-01, -1.0704e-01, -2.2103e-01, -3.0774e-01, -3.5137e-01,\n",
            "        -2.2803e-01, -1.9546e-01, -9.5911e-02, -2.2260e-02,  5.0417e-02,\n",
            "         2.8164e-02,  3.6098e-02, -4.8357e-02,  5.5146e-02, -8.9249e-02,\n",
            "        -1.6858e-02, -4.6694e-02, -1.0828e-01, -9.8441e-02, -1.9383e-02,\n",
            "        -9.7700e-02, -9.2793e-02, -1.5788e-02,  4.5145e-02,  3.5957e-02,\n",
            "        -3.5227e-02,  1.0661e-02, -7.3187e-02, -8.8519e-02, -2.8745e-01,\n",
            "        -2.2752e-01, -3.7598e-01, -2.2033e-01, -1.6578e-01, -4.7133e-02,\n",
            "        -1.2089e-01, -8.6501e-02, -3.5355e-02, -8.3890e-03, -8.0988e-02,\n",
            "         5.2004e-02, -2.3241e-03, -6.1574e-02, -3.0668e-02, -1.9670e-02,\n",
            "        -1.1587e-01, -8.5075e-02,  9.9309e-03, -9.3189e-02, -9.9674e-02,\n",
            "         4.5744e-02, -2.5221e-02, -9.4752e-02, -8.4559e-02, -1.0687e-01,\n",
            "        -5.0293e-02, -1.4168e-02, -2.1957e-01, -1.7381e-01, -1.4877e-01,\n",
            "        -1.6509e-01, -1.7102e-01, -1.6392e-01, -9.4256e-02, -2.4663e-03,\n",
            "        -7.4062e-02, -1.1544e-02, -6.7664e-02, -9.1403e-02,  4.4695e-02,\n",
            "         3.7833e-02, -1.0888e-01, -3.2424e-03, -5.9108e-02, -7.0376e-02,\n",
            "        -8.9686e-02, -8.8550e-02,  4.0190e-02, -1.0951e-01, -8.0425e-02,\n",
            "        -6.8455e-03, -6.2740e-02, -1.0670e-01,  2.1353e-02, -1.2117e-02,\n",
            "         5.7133e-03, -1.5921e-02, -6.6526e-02, -1.2098e-01, -1.3819e-01,\n",
            "        -1.4207e-01, -1.0618e-01, -6.9065e-02, -1.3942e-02, -1.9524e-02,\n",
            "         5.8854e-03,  1.8032e-02,  4.4679e-02,  4.9506e-03, -7.9740e-02,\n",
            "        -1.0031e-01, -6.3982e-02, -1.0162e-01, -9.1782e-02, -1.1743e-01,\n",
            "        -7.0701e-02, -2.5590e-02, -4.9105e-02, -5.3680e-02, -4.5218e-02,\n",
            "        -3.5588e-02, -5.3723e-02, -4.8161e-02,  2.8750e-04,  1.7931e-02,\n",
            "        -1.0308e-02, -8.8663e-02,  8.6605e-03,  3.8348e-02, -1.3255e-01,\n",
            "        -4.6684e-02, -5.7762e-02, -1.0194e-01, -9.8854e-02, -6.4025e-02,\n",
            "        -6.4733e-02,  2.8362e-02, -1.1995e-02,  3.7476e-02, -3.9122e-02,\n",
            "         3.7852e-02, -1.1123e-01, -1.0819e-01, -1.6087e-02, -1.1068e-01,\n",
            "         4.9270e-02, -9.8071e-02, -7.1408e-02, -1.1354e-01, -1.0142e-01,\n",
            "         4.9972e-02, -8.6115e-02, -1.2671e-02, -1.1298e-01,  1.3219e-02,\n",
            "        -3.0310e-02,  2.6808e-02,  4.0055e-02, -1.2309e-01, -7.5854e-02,\n",
            "        -4.2667e-03,  1.8318e-02,  7.7380e-03, -4.8429e-02, -7.1461e-03,\n",
            "        -1.0206e-01, -4.9877e-02, -1.6687e-02,  1.6481e-02],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.0.weight', Parameter containing:\n",
            "tensor([[ 4.7013e-02,  3.3946e-01, -3.4599e-01, -1.7618e-01, -2.8881e-01,\n",
            "         -3.4877e-01, -1.0118e-01, -3.0927e-01],\n",
            "        [ 2.8559e-01, -1.7288e-01,  2.8011e-01,  1.4481e-01, -1.9936e-01,\n",
            "          2.8065e-01,  3.2695e-01,  3.3923e-01],\n",
            "        [ 4.3318e-02, -3.5171e-01, -2.1191e-01, -2.3646e-01, -2.2356e-01,\n",
            "         -4.4451e-03, -1.3715e-01,  2.4635e-01],\n",
            "        [ 2.5953e-01,  3.4152e-01, -2.2127e-01,  8.5971e-02, -1.3760e-01,\n",
            "         -2.9540e-01, -4.8023e-02,  2.8237e-01],\n",
            "        [-2.6619e-01,  2.1653e-01, -2.6232e-01, -2.7501e-01, -1.0314e-01,\n",
            "          3.1993e-01, -2.5691e-01,  1.3695e-01],\n",
            "        [ 3.2272e-01, -2.2238e-01, -1.8271e-01, -2.8956e-01,  5.0314e-02,\n",
            "         -3.3232e-01,  1.2323e-01,  3.0065e-01],\n",
            "        [-3.4074e-01,  3.3640e-01, -9.7145e-03,  4.1841e-02, -1.5750e-01,\n",
            "         -3.0758e-01,  3.2920e-01, -3.3360e-01],\n",
            "        [ 6.4003e-02, -4.6218e-02, -3.2688e-01, -2.7977e-02, -1.2449e-01,\n",
            "         -6.8677e-02, -2.2301e-01,  5.2083e-02],\n",
            "        [ 3.4978e-01, -3.9263e-02, -9.9840e-02, -2.6182e-02,  3.4211e-01,\n",
            "         -2.4499e-01, -2.2547e-02, -3.3091e-01],\n",
            "        [-1.2611e-01,  1.6385e-01, -1.3812e-01, -1.6059e-01,  1.4070e-01,\n",
            "         -8.1587e-02,  3.5547e-04, -1.9683e-01],\n",
            "        [-1.0835e-02,  1.0703e-01, -3.4715e-01,  2.3952e-01,  3.4513e-01,\n",
            "          2.4532e-01,  3.0525e-01, -1.3975e-01],\n",
            "        [ 3.4929e-01, -3.9428e-02, -3.0129e-01,  2.3211e-01, -5.2591e-02,\n",
            "          3.2536e-01, -2.9896e-02, -2.9106e-01],\n",
            "        [-2.6223e-01,  2.2580e-01,  6.9887e-02,  7.7045e-03, -7.6000e-02,\n",
            "          3.1145e-01, -6.0866e-02, -2.0827e-01],\n",
            "        [-1.1482e-01,  3.3827e-01,  1.6937e-01,  3.0829e-01,  2.3693e-01,\n",
            "          5.3876e-02, -1.1755e-01, -1.9362e-01],\n",
            "        [ 9.4581e-02,  6.4576e-02,  2.7254e-01,  2.0194e-01,  1.0994e-01,\n",
            "         -2.6341e-01,  2.0864e-01,  2.7918e-01],\n",
            "        [ 1.9404e-02,  2.2809e-01, -1.1288e-01, -3.2519e-01,  2.7561e-01,\n",
            "         -3.4718e-01, -1.3460e-01, -2.9394e-01],\n",
            "        [-1.3288e-02, -9.5213e-02,  1.0359e-02, -2.7846e-01,  1.1129e-01,\n",
            "         -3.9852e-02, -1.5493e-01, -1.3188e-01],\n",
            "        [-1.3655e-01, -1.6840e-02, -2.2321e-01,  1.2610e-01, -1.5801e-01,\n",
            "          2.9381e-01,  3.2841e-01, -5.5420e-02],\n",
            "        [-2.8583e-01, -5.4386e-02, -1.8532e-01,  2.5301e-01, -1.9051e-01,\n",
            "          1.9542e-01, -1.3816e-01,  1.5359e-01],\n",
            "        [-6.6019e-02,  9.5294e-02, -1.0012e-01, -6.6112e-02, -6.5570e-02,\n",
            "          1.5730e-01, -1.5293e-01,  1.5480e-01],\n",
            "        [-1.2679e-01, -5.4688e-02,  2.3963e-01, -1.1260e-01, -5.7963e-02,\n",
            "          2.4673e-01, -1.3857e-01,  2.1245e-01],\n",
            "        [-6.2313e-02, -2.4841e-02, -2.8130e-02,  2.7120e-01, -8.0841e-02,\n",
            "          3.8039e-02,  5.8244e-02, -2.0851e-01],\n",
            "        [-2.8825e-03, -5.3405e-02,  3.1349e-01,  1.1990e-02,  1.2204e-01,\n",
            "         -5.0767e-02, -3.3876e-02,  3.0053e-01],\n",
            "        [ 9.5487e-02,  2.5548e-02, -2.3779e-01,  1.6954e-01, -8.6026e-02,\n",
            "         -2.9729e-01,  1.4010e-01, -2.9552e-01],\n",
            "        [ 2.6746e-02, -1.6260e-01,  1.2545e-01,  3.3337e-01, -3.4777e-01,\n",
            "         -3.7611e-03,  1.2616e-01,  1.8805e-01],\n",
            "        [ 6.4431e-02,  2.3175e-01,  1.2983e-01,  3.3329e-01,  2.7777e-01,\n",
            "          1.0933e-04, -1.9185e-04, -8.9170e-02],\n",
            "        [-3.3491e-01,  1.9707e-01, -5.4391e-02, -2.0452e-01,  2.0612e-01,\n",
            "          3.0640e-01, -1.5629e-01, -2.5118e-01],\n",
            "        [ 1.1213e-01, -6.7849e-02,  8.3772e-02, -1.9833e-01,  9.8492e-02,\n",
            "          2.0402e-01, -3.4293e-01, -1.1352e-01],\n",
            "        [ 8.8510e-02, -3.0561e-01, -2.2164e-01,  2.2746e-01, -2.4095e-03,\n",
            "          1.1713e-01,  1.6656e-01, -4.2860e-03],\n",
            "        [-8.5478e-02,  1.2604e-01, -2.6574e-01,  2.8037e-01,  3.1767e-02,\n",
            "          1.5607e-01, -3.4844e-02, -1.4701e-01],\n",
            "        [-2.3790e-02,  1.7786e-01, -2.6287e-01, -1.8282e-01, -1.0835e-01,\n",
            "          2.9293e-01, -2.2580e-01,  1.6148e-01],\n",
            "        [ 1.3713e-01, -1.1467e-01, -7.5965e-03, -4.0517e-02, -9.3728e-02,\n",
            "          2.3119e-02,  2.9103e-01,  2.7072e-01],\n",
            "        [-1.3901e-01, -8.2711e-02, -2.7074e-01, -1.0404e-01,  1.7976e-01,\n",
            "         -6.6159e-03,  1.8720e-01,  2.8947e-01],\n",
            "        [-2.4099e-01,  2.6889e-01,  2.0452e-01, -1.7289e-02,  2.6559e-01,\n",
            "         -2.2599e-01, -8.7307e-02, -3.1130e-01],\n",
            "        [ 2.7051e-01, -2.5156e-01, -3.3072e-01,  3.0664e-01, -2.2363e-01,\n",
            "         -1.5551e-01, -1.5784e-01, -7.6962e-02],\n",
            "        [ 2.5678e-02,  1.8747e-02,  2.1313e-01, -6.2761e-02,  2.4928e-01,\n",
            "          1.3376e-01, -1.3972e-01, -1.1012e-01],\n",
            "        [ 2.0279e-01, -2.2884e-01, -5.6231e-02,  3.2031e-01, -1.5250e-01,\n",
            "          3.9501e-02,  1.0282e-01,  1.6599e-01],\n",
            "        [ 1.1639e-01,  1.1319e-01, -1.6826e-01, -2.2818e-01,  1.7621e-02,\n",
            "         -8.3208e-02,  3.2842e-01,  9.8168e-02],\n",
            "        [ 7.1420e-02, -3.2623e-01, -2.5767e-01, -3.6390e-02,  1.3209e-01,\n",
            "          1.5804e-01,  2.2597e-01,  3.3372e-01],\n",
            "        [-3.1080e-03,  3.1370e-01,  2.7977e-01, -2.6882e-01,  6.1455e-02,\n",
            "          8.6320e-03, -3.3403e-01,  3.9072e-02],\n",
            "        [ 3.2519e-02, -3.3683e-01,  2.7513e-01,  1.7871e-01,  2.5284e-02,\n",
            "         -7.8332e-03, -1.4435e-01,  2.6268e-01],\n",
            "        [-1.7576e-01, -1.5654e-01,  5.3425e-02,  1.4033e-01, -1.9138e-01,\n",
            "         -2.3659e-01, -2.5030e-01,  3.3642e-01],\n",
            "        [-2.2333e-01,  4.0326e-02,  2.9652e-01,  1.2512e-02, -1.3704e-01,\n",
            "          6.9783e-02,  3.7780e-03,  1.7641e-01],\n",
            "        [-2.2158e-02, -1.2838e-01, -1.4536e-01, -2.4478e-01,  2.9311e-01,\n",
            "         -2.9916e-01,  7.8378e-02, -2.2665e-01],\n",
            "        [ 3.3980e-01, -2.7779e-02,  3.1675e-01, -3.2858e-01,  2.8137e-01,\n",
            "         -6.7032e-02,  3.3009e-01, -1.5554e-01],\n",
            "        [ 3.0611e-01, -3.4330e-01, -2.3856e-01,  2.6439e-01, -1.7307e-01,\n",
            "          2.3709e-01, -3.3454e-01, -3.0247e-01],\n",
            "        [-2.0896e-01, -2.8406e-01,  2.6076e-01, -6.1901e-02,  3.0450e-02,\n",
            "         -1.4117e-02, -2.9618e-01, -1.5854e-01],\n",
            "        [-8.0306e-02, -3.1268e-02,  2.2915e-01,  2.8673e-01,  3.0332e-01,\n",
            "         -1.2716e-01, -2.7798e-01,  2.2206e-01],\n",
            "        [ 1.9062e-02, -1.4281e-01, -1.4232e-01, -4.9796e-02, -5.5913e-02,\n",
            "         -8.3268e-02,  1.5239e-02, -1.1812e-02],\n",
            "        [ 3.9287e-02, -1.3171e-01,  1.3612e-01,  3.2280e-01, -5.5408e-03,\n",
            "          2.2034e-01,  1.0806e-01, -1.4233e-01],\n",
            "        [-2.0300e-01,  2.2378e-01, -7.7072e-02,  3.4535e-02, -2.4804e-01,\n",
            "          1.4068e-01,  2.8342e-01, -7.4558e-05],\n",
            "        [-3.0442e-01,  6.1682e-03,  7.1763e-02, -8.0413e-02,  1.6142e-01,\n",
            "          2.2131e-01, -3.4928e-01,  5.0658e-02],\n",
            "        [ 2.4904e-01, -1.2440e-01, -2.8973e-01,  1.4025e-01,  2.3241e-01,\n",
            "          1.2953e-01,  3.0508e-01, -1.8875e-01],\n",
            "        [ 2.8314e-01,  5.5902e-03, -1.7047e-01,  8.6045e-02, -1.6831e-01,\n",
            "         -3.3391e-01,  2.4129e-01, -1.4447e-01],\n",
            "        [-4.2283e-02, -2.5596e-01, -4.4729e-03,  3.2726e-01, -9.0082e-02,\n",
            "         -2.0556e-01,  3.0671e-01, -3.2467e-01],\n",
            "        [-1.5734e-01, -1.2560e-01, -6.1771e-02, -3.0311e-01,  2.8136e-01,\n",
            "         -1.8069e-01,  1.3727e-01, -1.1299e-01],\n",
            "        [ 2.2106e-01,  3.2628e-02,  3.4473e-01,  3.1143e-01, -3.5157e-02,\n",
            "         -6.9756e-02, -3.4431e-01,  1.4887e-01],\n",
            "        [-2.1727e-01,  2.7784e-01, -1.4780e-01,  1.5879e-01, -2.1219e-01,\n",
            "         -5.8326e-02,  2.6255e-01,  2.2433e-01],\n",
            "        [ 2.8687e-01,  8.3760e-02,  2.6145e-01,  4.1110e-02,  1.3152e-01,\n",
            "         -2.2809e-01, -1.9389e-01,  7.2481e-02],\n",
            "        [-1.5436e-01, -2.4877e-01, -2.8571e-01,  7.9681e-02,  2.5360e-01,\n",
            "          1.4712e-01,  2.9032e-01, -1.8002e-02],\n",
            "        [ 2.8701e-01, -2.2613e-01, -1.2158e-01,  2.1632e-01,  6.1863e-02,\n",
            "         -1.6087e-01, -2.0586e-01,  1.4056e-01],\n",
            "        [-1.8318e-01, -3.3598e-01, -3.4007e-01,  3.2658e-01, -1.4959e-01,\n",
            "          2.4467e-02, -3.4155e-01, -2.7417e-01],\n",
            "        [ 2.0480e-01, -2.2949e-01,  2.2887e-01,  2.6939e-01, -1.0731e-01,\n",
            "         -1.3517e-01,  9.8562e-02, -2.1377e-01],\n",
            "        [-1.6762e-01, -7.8915e-02,  1.5056e-01, -6.2506e-02, -1.7675e-01,\n",
            "         -1.5622e-01,  3.3095e-01,  2.9476e-01]], requires_grad=True))\n",
            "('clf.classifier.0.bias', Parameter containing:\n",
            "tensor([ 0.0705,  0.0240, -0.1222,  0.0962,  0.1031, -0.2339,  0.0176,  0.3216,\n",
            "        -0.0281,  0.1216, -0.0560,  0.2951, -0.1310,  0.3356,  0.1159, -0.2313,\n",
            "        -0.2999, -0.1904,  0.0356,  0.3315,  0.2791, -0.1023, -0.2417,  0.0182,\n",
            "        -0.1694,  0.0891,  0.1185,  0.2054, -0.2415,  0.2831,  0.1444,  0.3342,\n",
            "        -0.0719, -0.2316,  0.0616,  0.0041,  0.0367, -0.1962,  0.2441, -0.2419,\n",
            "        -0.1518, -0.0204,  0.1438,  0.0267,  0.0076,  0.0706, -0.0446,  0.3431,\n",
            "         0.3366, -0.2142, -0.0937,  0.2222, -0.0417, -0.1372,  0.3097, -0.0051,\n",
            "         0.0722, -0.3199,  0.2232,  0.1748, -0.2433, -0.0123,  0.1699,  0.0120],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.2.weight', Parameter containing:\n",
            "tensor([[-0.0179, -0.0871,  0.0547,  ..., -0.1119,  0.1071,  0.0295],\n",
            "        [ 0.0936,  0.1103, -0.0450,  ...,  0.0578,  0.0956,  0.1149],\n",
            "        [-0.0214, -0.0570,  0.0009,  ..., -0.1176,  0.1248, -0.0282],\n",
            "        ...,\n",
            "        [ 0.0299,  0.0906,  0.0537,  ...,  0.0994, -0.1208,  0.1205],\n",
            "        [ 0.0058,  0.1140, -0.0357,  ..., -0.0708, -0.1189,  0.1151],\n",
            "        [ 0.0338, -0.0587, -0.1054,  ...,  0.0315, -0.0717,  0.0839]],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.2.bias', Parameter containing:\n",
            "tensor([ 0.0795,  0.0273, -0.0808,  0.0568,  0.0104,  0.0113,  0.0518, -0.0870,\n",
            "         0.1060, -0.0065,  0.0701,  0.0304,  0.0575,  0.1241,  0.0561, -0.0087,\n",
            "        -0.0507, -0.1168, -0.0848, -0.0553,  0.0841,  0.0248,  0.0512, -0.0136,\n",
            "        -0.0909,  0.0573,  0.0391,  0.1049, -0.0750, -0.1187, -0.0374,  0.0319],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.4.weight', Parameter containing:\n",
            "tensor([[-0.0922, -0.1424, -0.0131,  0.0948, -0.0300, -0.0766, -0.1345, -0.0591,\n",
            "         -0.1096,  0.0387,  0.1487,  0.0471,  0.0639,  0.1668,  0.1562, -0.1706,\n",
            "          0.0376, -0.0231, -0.0708, -0.0324,  0.1704,  0.0627, -0.1398,  0.0581,\n",
            "         -0.0450,  0.1739,  0.1592,  0.0386,  0.1490,  0.0231,  0.0488, -0.0546],\n",
            "        [-0.1127, -0.0761, -0.0186, -0.1712,  0.1259, -0.0886,  0.0571,  0.1279,\n",
            "         -0.0310, -0.0192,  0.1203,  0.1666, -0.0759,  0.1434,  0.0604, -0.0685,\n",
            "          0.1618,  0.0779,  0.1531, -0.0458, -0.1303,  0.1048, -0.0238, -0.1113,\n",
            "          0.1114, -0.0673,  0.1444, -0.0938,  0.0381, -0.1232, -0.0297, -0.0686],\n",
            "        [-0.0615,  0.1428,  0.0287, -0.1274, -0.0452, -0.1087,  0.0839,  0.0191,\n",
            "         -0.0826,  0.0081,  0.0276,  0.0681,  0.0733, -0.0653,  0.1489,  0.0111,\n",
            "          0.1334,  0.1429, -0.0162, -0.0830,  0.0043, -0.0418, -0.0594,  0.0266,\n",
            "         -0.0329, -0.0731, -0.0498,  0.0419,  0.0694, -0.0345, -0.0652, -0.1216],\n",
            "        [-0.1456, -0.0384, -0.0223, -0.1480,  0.0472, -0.1122,  0.0665,  0.0097,\n",
            "         -0.1345, -0.0597, -0.1249,  0.0052,  0.1167, -0.0960,  0.1058, -0.0850,\n",
            "          0.0883, -0.0077, -0.1075,  0.0765,  0.0404, -0.0085, -0.0573, -0.0717,\n",
            "         -0.0223,  0.1465, -0.0686, -0.0440, -0.0878, -0.0866,  0.0102, -0.1111],\n",
            "        [ 0.0222,  0.0230, -0.1556,  0.0706, -0.1017,  0.0811, -0.0488, -0.0219,\n",
            "          0.0043,  0.1413, -0.1353, -0.0630,  0.1430, -0.0308,  0.1172, -0.0471,\n",
            "          0.1450,  0.1053,  0.0004, -0.1532,  0.1225,  0.0631, -0.0446,  0.0743,\n",
            "          0.1740,  0.1693,  0.0798, -0.0903,  0.0720,  0.0071, -0.0789,  0.0264],\n",
            "        [-0.0172,  0.1062,  0.0381, -0.0770,  0.1405,  0.1470,  0.0694, -0.1674,\n",
            "          0.0058, -0.0974, -0.1452, -0.1615,  0.0182,  0.0999,  0.1070,  0.0745,\n",
            "          0.0295,  0.1735, -0.1197, -0.1709,  0.1556, -0.1392,  0.1481, -0.0225,\n",
            "         -0.0342,  0.1560,  0.0786, -0.0998, -0.1716, -0.0972,  0.1512, -0.0384],\n",
            "        [ 0.1505,  0.1297, -0.0860,  0.0726,  0.0223,  0.1082,  0.1071, -0.1205,\n",
            "         -0.1478,  0.0462,  0.0856,  0.0665,  0.0782, -0.1579,  0.1389, -0.0950,\n",
            "          0.0943,  0.1023,  0.1637, -0.0945, -0.0732,  0.1682, -0.0931,  0.1184,\n",
            "         -0.0330, -0.0610,  0.0708,  0.1747, -0.0734, -0.1475,  0.0388, -0.1619],\n",
            "        [ 0.1348, -0.1124, -0.1600,  0.0820, -0.1355, -0.0745,  0.0783, -0.0327,\n",
            "          0.1308,  0.1746, -0.1373, -0.0668, -0.0834, -0.0712,  0.1674, -0.0271,\n",
            "         -0.0141, -0.0913,  0.0789,  0.1069, -0.0657,  0.1502, -0.1061, -0.0368,\n",
            "          0.1268, -0.1194, -0.0184,  0.0024,  0.0615,  0.0990, -0.1603,  0.0218],\n",
            "        [-0.1353,  0.0623,  0.0757,  0.1618,  0.1245, -0.0336, -0.0125,  0.0693,\n",
            "         -0.1045, -0.0525, -0.1511, -0.0914, -0.0821, -0.1523, -0.1614,  0.1335,\n",
            "         -0.1660,  0.1430, -0.1660, -0.1575,  0.0182, -0.1094,  0.0280,  0.1716,\n",
            "         -0.0258, -0.1692, -0.1461, -0.0064, -0.0111, -0.0293, -0.0234,  0.0584],\n",
            "        [ 0.0109, -0.0605, -0.0594,  0.0040,  0.1728,  0.0918,  0.0937,  0.0082,\n",
            "          0.0173, -0.1399, -0.0768,  0.0331,  0.0013, -0.0918,  0.0619, -0.0455,\n",
            "         -0.0954, -0.0883, -0.0612,  0.0849, -0.1343, -0.1226, -0.1265, -0.1319,\n",
            "         -0.0069, -0.1137, -0.1086, -0.1637,  0.1159, -0.1057, -0.0399,  0.0927]],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.4.bias', Parameter containing:\n",
            "tensor([ 0.0133, -0.0412, -0.1627,  0.1468,  0.0146, -0.0178,  0.0374,  0.1668,\n",
            "         0.0128,  0.1143], requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzxMz6_UjuMm"
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV2ZeGr0-YQ0"
      },
      "source": [
        "model2.TurnOffEncoder()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcZMyWokOSMa"
      },
      "source": [
        "optimizer = optim.Adam(model2.parameters(), lr=1e-3)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGzOgR4iOJSL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "03076c90-5079-49f8-ead4-77ca7a3ddb45"
      },
      "source": [
        "\n",
        "train_loss_arr = []\n",
        "val_loss_arr=[]\n",
        "for epoch in range(50):\n",
        "    \n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "    \n",
        "    model2.train()\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        image = image.view(image.size(0), -1).to(device)\n",
        "        label = label.to(device)\n",
        "        #forward\n",
        "        out = model2.classify(image)\n",
        "        loss = criterion(out, label)\n",
        "        #backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()*image.size(0)\n",
        "        \n",
        "    model2.eval()\n",
        "    \n",
        "    for image, label in valid_loader:\n",
        "        image = image.view(image.size(0), -1).to(device)\n",
        "        label = label.to(device)\n",
        "        out = model2.classify(image)\n",
        "        loss = criterion(out, label)\n",
        "        \n",
        "        val_loss += loss.item()*image.size(0)\n",
        "    \n",
        "    val_loss = val_loss/len(valid_loader)    \n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    \n",
        "    val_loss_arr.append(val_loss)\n",
        "    train_loss_arr.append(train_loss)\n",
        "    \n",
        "    print('epoch [{}/{}], \\tTraining Loss:{:.4f} \\tValidation Loss:{:.4f}'.format(epoch + 1, 50, train_loss, val_loss))\n",
        "    \n",
        "    # if val_loss < val_loss_min:\n",
        "    #     print('Validation loss has decreased ({:.4f}-->{:.4f}). Model saved...'.format(val_loss_min, val_loss))\n",
        "    #     torch.save(model.state_dict(), 'autoencoder_V2.pt')\n",
        "    #     val_loss_min = val_loss"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/50], \tTraining Loss:164.4512 \tValidation Loss:150.4447\n",
            "epoch [2/50], \tTraining Loss:143.6207 \tValidation Loss:136.1451\n",
            "epoch [3/50], \tTraining Loss:132.9294 \tValidation Loss:129.6306\n",
            "epoch [4/50], \tTraining Loss:125.4032 \tValidation Loss:125.0170\n",
            "epoch [5/50], \tTraining Loss:121.8939 \tValidation Loss:121.5179\n",
            "epoch [6/50], \tTraining Loss:118.6382 \tValidation Loss:121.1622\n",
            "epoch [7/50], \tTraining Loss:116.7166 \tValidation Loss:117.5351\n",
            "epoch [8/50], \tTraining Loss:115.1873 \tValidation Loss:114.6048\n",
            "epoch [9/50], \tTraining Loss:113.4442 \tValidation Loss:112.7980\n",
            "epoch [10/50], \tTraining Loss:112.0933 \tValidation Loss:112.2728\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5210953c2e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egFvAxKxQTZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2276e230-2cf6-4ca3-e503-a86a176ffbd1"
      },
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model2.eval() # prep model for evaluation\n",
        "with torch.no_grad():\n",
        "    for image, target in test_loader:\n",
        "        image = image.view(image.size(0), -1).to(device)\n",
        "        target = target.to(device)\n",
        "        output = model2.classify(image)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        test_loss += loss.item()*image.size(0)\n",
        "\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(len(target)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.442192\n",
            "\n",
            "Test Accuracy of     0: 95% (937/980)\n",
            "Test Accuracy of     1: 97% (1112/1135)\n",
            "Test Accuracy of     2: 89% (928/1032)\n",
            "Test Accuracy of     3: 84% (856/1010)\n",
            "Test Accuracy of     4: 82% (807/982)\n",
            "Test Accuracy of     5: 74% (666/892)\n",
            "Test Accuracy of     6: 90% (865/958)\n",
            "Test Accuracy of     7: 87% (904/1028)\n",
            "Test Accuracy of     8: 82% (806/974)\n",
            "Test Accuracy of     9: 74% (754/1009)\n",
            "\n",
            "Test Accuracy (Overall): 86% (8635/10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6wdiDEiYK6P",
        "outputId": "130137ef-4258-4420-a4a1-a0b553f34aa7"
      },
      "source": [
        "for param in model2.named_parameters():\n",
        "  print(param)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('encoder.encoder.0.weight', Parameter containing:\n",
            "tensor([[ 0.0142,  0.0087, -0.0357,  ..., -0.0263,  0.0060,  0.0039],\n",
            "        [ 0.0103,  0.0356,  0.0210,  ..., -0.0140,  0.0240,  0.0322],\n",
            "        [-0.0054,  0.0077,  0.0088,  ...,  0.0332,  0.0337, -0.0311],\n",
            "        ...,\n",
            "        [ 0.0203,  0.0126, -0.0319,  ...,  0.0258, -0.0238, -0.0239],\n",
            "        [ 0.0003,  0.0206, -0.0031,  ...,  0.0236,  0.0008, -0.0047],\n",
            "        [-0.0162, -0.0195,  0.0143,  ...,  0.0134,  0.0330,  0.0240]]))\n",
            "('encoder.encoder.0.bias', Parameter containing:\n",
            "tensor([-0.0626,  0.4047,  0.0165, -0.0318, -0.0063,  0.1092,  0.0466, -0.0346,\n",
            "         0.1345, -0.0389,  0.2244,  0.0056, -0.0250,  0.0489, -0.0942,  0.0906,\n",
            "         0.0500,  0.2363, -0.0111,  0.0572, -0.0281,  0.0026,  0.2367,  0.1138,\n",
            "        -0.0110,  0.1233, -0.0459, -0.0226, -0.0305, -0.0658,  0.2023,  0.0149,\n",
            "         0.1647,  0.0255,  0.0140,  0.1280,  0.0356,  0.0774,  0.0726, -0.0162,\n",
            "         0.2012,  0.0225,  0.2585,  0.0235, -0.0290,  0.0776,  0.3370,  0.0184,\n",
            "         0.0029,  0.0332, -0.1122, -0.0289, -0.0236,  0.0165,  0.0337,  0.1126,\n",
            "        -0.0285,  0.2247, -0.0028, -0.0049, -0.0242, -0.0992,  0.2677,  0.0261,\n",
            "        -0.0512,  0.0141, -0.0089, -0.0234, -0.0321, -0.0073, -0.0448,  0.0722,\n",
            "         0.4300,  0.1518,  0.0069,  0.2117,  0.0545,  0.0625, -0.0008,  0.1430,\n",
            "        -0.0370, -0.0695, -0.0347,  0.2060,  0.0915,  0.1544, -0.0849,  0.0862,\n",
            "        -0.0420,  0.0704,  0.1062,  0.0205,  0.0294,  0.1203, -0.0044, -0.0442,\n",
            "         0.0012,  0.1255, -0.1811,  0.0217,  0.0722,  0.1003,  0.0783, -0.0054,\n",
            "         0.1007, -0.0017,  0.1714,  0.0068, -0.0177,  0.1839,  0.0032, -0.0376,\n",
            "        -0.0404, -0.0693,  0.2505, -0.0318, -0.0359, -0.0252, -0.0014,  0.0483,\n",
            "         0.0914,  0.0811,  0.0040, -0.0103, -0.2205, -0.1490, -0.0176,  0.0166]))\n",
            "('encoder.encoder.2.weight', Parameter containing:\n",
            "tensor([[ 0.2117, -0.1107,  0.1381,  ...,  0.0325,  0.0056, -0.0389],\n",
            "        [-0.1259,  0.1978,  0.2775,  ...,  0.0781, -0.0710, -0.0795],\n",
            "        [ 0.2344, -0.1395, -0.1203,  ..., -0.1936,  0.0137,  0.0720],\n",
            "        ...,\n",
            "        [ 0.0284, -0.0465,  0.0678,  ...,  0.0258,  0.0718, -0.0779],\n",
            "        [ 0.2203,  0.2201,  0.0803,  ..., -0.0092, -0.0261, -0.0374],\n",
            "        [ 0.1288,  0.1170,  0.1399,  ..., -0.0591, -0.0313, -0.0775]]))\n",
            "('encoder.encoder.2.bias', Parameter containing:\n",
            "tensor([ 0.2726,  0.0898, -0.2900, -0.1164, -0.0350, -0.0947,  0.0122,  0.0378,\n",
            "        -0.0872, -0.0715,  0.0958, -0.0658,  0.1662, -0.0432,  0.1322, -0.0443,\n",
            "        -0.0943,  0.0068, -0.0454, -0.0089,  0.0611,  0.0053, -0.0732,  0.0303,\n",
            "         0.1324,  0.1463,  0.0034, -0.0803,  0.2128,  0.0336, -0.2104,  0.2655,\n",
            "         0.0793, -0.0255,  0.0743, -0.0455, -0.0517, -0.0933, -0.1074, -0.0907,\n",
            "        -0.1162, -0.1169,  0.0967, -0.0442, -0.1813, -0.0058,  0.0552, -0.0267,\n",
            "        -0.3801,  0.3299, -0.0525,  0.0005,  0.0698,  0.1724,  0.2540,  0.0570,\n",
            "         0.0470, -0.0378,  0.1156, -0.0999,  0.2794,  0.0097,  0.1406,  0.1286]))\n",
            "('encoder.encoder.4.weight', Parameter containing:\n",
            "tensor([[ 7.9640e-01, -1.2685e-02,  2.7699e-01,  ..., -1.1501e-01,\n",
            "          1.5955e-01,  7.3582e-02],\n",
            "        [ 9.6361e-01,  8.0053e-02, -1.7488e-01,  ..., -1.0039e-01,\n",
            "          1.0261e-01,  6.2273e-02],\n",
            "        [ 3.1232e-01,  1.7499e-01, -3.6936e-01,  ..., -2.3028e-03,\n",
            "          7.7024e-02,  1.6946e-01],\n",
            "        ...,\n",
            "        [ 1.1375e-01,  9.9298e-02,  2.0871e-02,  ..., -2.5805e-02,\n",
            "         -9.5036e-02,  5.6946e-04],\n",
            "        [ 1.5559e-01,  3.2634e-02,  4.1993e-01,  ..., -8.2020e-02,\n",
            "          1.4492e-01,  3.9023e-02],\n",
            "        [-1.8113e-01,  7.8606e-02, -5.2031e-01,  ..., -6.5206e-02,\n",
            "          1.6174e-01, -2.6329e-02]]))\n",
            "('encoder.encoder.4.bias', Parameter containing:\n",
            "tensor([-0.1099,  0.1465,  0.1058, -0.0835,  0.0822,  0.0687,  0.0953,  0.1170,\n",
            "        -0.0538,  0.2530,  0.1948, -0.0806,  0.0674,  0.0415,  0.1556, -0.0616]))\n",
            "('encoder.encoder.6.weight', Parameter containing:\n",
            "tensor([[-1.8553e-01, -3.2433e-01, -2.4582e-01,  3.4264e-01, -5.1192e-02,\n",
            "          2.2765e-01, -5.4226e-02, -2.1979e-01,  2.4571e-01, -1.4466e-01,\n",
            "         -1.9776e-02,  9.8085e-03,  1.7044e-01,  9.6801e-02,  2.3912e-01,\n",
            "         -1.4510e-01],\n",
            "        [-3.1609e-01, -1.2312e-01,  1.4379e-01,  8.8199e-02, -2.1391e-01,\n",
            "          2.5733e-01,  4.5714e-02,  8.0462e-02,  1.0599e-01,  2.0858e-02,\n",
            "          1.8499e-01, -4.0419e-02, -1.2345e-01, -2.6550e-02, -8.0043e-02,\n",
            "          2.8968e-01],\n",
            "        [-2.2468e-01, -1.3736e-02, -1.8616e-01, -1.5807e-01, -9.0415e-03,\n",
            "         -1.0363e-01, -1.7054e-01, -2.1408e-01, -2.2803e-01,  7.7874e-01,\n",
            "         -4.2499e-02, -2.4992e-01, -2.8187e-02,  1.3355e-01, -2.9259e-01,\n",
            "         -2.0083e-01],\n",
            "        [-1.1178e-01, -1.1985e-01, -1.7988e-01, -2.9670e-02, -1.0457e-01,\n",
            "         -1.4234e-01, -3.7532e-02, -2.4290e-02,  8.5394e-02, -3.2119e-01,\n",
            "         -2.0776e-01, -2.0559e-01, -1.3491e-02, -2.1691e-01, -2.9507e-01,\n",
            "          2.0533e-01],\n",
            "        [ 2.4641e-02, -2.5665e-02, -1.5433e-01,  2.6112e-01,  2.2740e-01,\n",
            "         -7.4283e-02, -1.1162e-01,  4.4467e-02, -2.1881e-01,  4.0893e-02,\n",
            "         -3.4020e-01, -2.6172e-01,  4.4163e-02, -1.2304e-01, -3.9277e-01,\n",
            "          1.5207e-01],\n",
            "        [ 3.5172e-01,  9.3501e-02, -1.1936e-01, -3.1851e-01, -2.1758e-01,\n",
            "         -4.0699e-02, -1.1316e-01,  1.4713e-01, -2.1337e-01, -2.0488e-01,\n",
            "         -2.2978e-01,  1.1803e-01, -2.0988e-01, -1.3009e-01,  1.3001e-01,\n",
            "          1.8439e-01],\n",
            "        [-3.8932e-01, -7.4343e-02,  1.1381e-01, -2.7857e-01,  8.8430e-03,\n",
            "          6.2940e-02, -1.4170e-01,  1.2976e-01, -1.1444e-01, -1.4496e-01,\n",
            "          8.0509e-02, -2.2147e-01,  1.7855e-01, -2.4715e-02, -2.3312e-01,\n",
            "          2.9734e-02],\n",
            "        [-4.3188e-01,  2.0290e-01, -2.2559e-02,  3.0153e-01,  3.6834e-04,\n",
            "         -2.5321e-02, -1.9703e-01, -3.2923e-02, -1.0505e-01,  8.1740e-04,\n",
            "         -3.7848e-01, -6.0756e-02, -1.6329e-01,  1.1009e-01,  2.2463e-01,\n",
            "          3.6092e-02]]))\n",
            "('encoder.encoder.6.bias', Parameter containing:\n",
            "tensor([-0.2137,  0.3108,  0.1323,  0.0542, -0.1174,  0.2055,  0.1963,  0.0270]))\n",
            "('decoder.decoder.0.weight', Parameter containing:\n",
            "tensor([[ 3.0565e-01,  3.5721e-01,  3.3465e-02, -1.0186e-01, -2.4452e-01,\n",
            "          1.9449e-01, -2.3141e-01,  5.2753e-01],\n",
            "        [-2.1914e-01,  2.2015e-01, -9.0414e-03, -5.0139e-02,  6.1864e-02,\n",
            "         -9.1593e-02,  2.7935e-01, -3.0155e-01],\n",
            "        [ 3.2542e-01, -1.9176e-02,  6.6199e-03, -2.3646e-01,  2.2202e-01,\n",
            "          3.3240e-01, -5.5803e-01, -1.9994e-02],\n",
            "        [-3.0255e-01,  8.0312e-02,  1.7529e-01, -1.3953e-01, -2.7499e-01,\n",
            "          7.7106e-02,  5.3746e-01, -1.8041e-01],\n",
            "        [-2.7050e-01, -1.3921e-01,  2.6177e-01, -2.0518e-01, -1.6211e-01,\n",
            "          1.5431e-01, -4.2107e-01,  3.1297e-01],\n",
            "        [ 1.9400e-01,  3.8719e-01, -3.0818e-01, -3.4997e-02,  1.5701e-01,\n",
            "         -1.8316e-01, -4.3012e-01, -2.3882e-01],\n",
            "        [-1.9403e-01, -2.5478e-01, -1.8670e-01,  1.6488e-01, -3.4463e-01,\n",
            "          5.4816e-02,  2.1729e-01, -5.2415e-02],\n",
            "        [-3.9280e-01,  3.6444e-01, -8.6027e-02, -3.2741e-01, -1.7054e-01,\n",
            "          2.9357e-01, -5.2342e-02,  1.0880e-01],\n",
            "        [ 1.9801e-02,  1.0860e-02, -2.4133e-01,  1.2050e-01, -3.5679e-01,\n",
            "          7.2012e-02,  3.1898e-01,  3.6831e-01],\n",
            "        [-4.1238e-02, -3.0628e-03, -1.4740e-01, -1.3069e-01, -3.2067e-01,\n",
            "          8.3649e-02, -2.2181e-01, -5.2337e-01],\n",
            "        [-2.0975e-01,  3.5841e-01,  9.2212e-02,  2.3849e-01,  3.8440e-01,\n",
            "         -4.5022e-04,  1.2979e-01,  2.9974e-01],\n",
            "        [-1.6009e-01, -2.8879e-01, -2.3496e-01, -1.3931e-01, -8.7085e-03,\n",
            "          3.1189e-01, -2.3913e-01, -3.3359e-02],\n",
            "        [ 3.2538e-01,  2.4486e-01,  2.8030e-01,  1.0714e-01,  2.0485e-01,\n",
            "          3.1483e-01,  1.0454e-01, -1.7680e-01],\n",
            "        [ 2.9262e-01,  2.6602e-01, -7.0354e-02, -3.7831e-01, -5.2074e-01,\n",
            "         -3.4369e-01,  5.2122e-02,  1.5497e-01],\n",
            "        [-2.3981e-01, -1.3574e-02,  3.9740e-01,  2.0856e-01, -2.4947e-01,\n",
            "          1.2462e-01, -3.0239e-02,  2.7657e-01],\n",
            "        [ 1.0383e-01,  3.3894e-02,  2.3233e-01,  2.5286e-01,  1.9544e-01,\n",
            "         -3.5448e-02, -2.5894e-01,  1.7020e-01]], requires_grad=True))\n",
            "('decoder.decoder.0.bias', Parameter containing:\n",
            "tensor([ 0.2170,  0.3484, -0.2474,  0.0147,  0.0564, -0.2137,  0.3550,  0.1400,\n",
            "         0.1023,  0.2474,  0.2625,  0.2510, -0.1487,  0.1202, -0.3179,  0.3179],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.2.weight', Parameter containing:\n",
            "tensor([[ 0.4550,  0.1257, -0.0141,  ...,  0.3910, -0.1508,  0.2660],\n",
            "        [-0.2731,  0.3027, -0.2048,  ...,  0.2403,  0.2220,  0.2212],\n",
            "        [ 0.4862, -0.1876, -0.4312,  ...,  0.1645, -0.0967, -0.1292],\n",
            "        ...,\n",
            "        [ 0.2871, -0.1755, -0.0958,  ...,  0.5081,  0.2129, -0.1014],\n",
            "        [-0.2815,  0.2534, -0.3380,  ...,  0.3879,  0.0988, -0.1653],\n",
            "        [ 0.1893, -0.0547, -0.0198,  ...,  0.3914,  0.1398,  0.0933]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.2.bias', Parameter containing:\n",
            "tensor([-0.0359,  0.0388,  0.1433,  0.1217, -0.1222,  0.3307,  0.4072, -0.0231,\n",
            "        -0.5803,  0.3112, -0.4010,  0.2443,  0.2613,  0.3874,  0.2083,  0.1698,\n",
            "        -0.2169,  0.0349, -0.2650, -0.0166, -0.0008, -0.2776, -0.1813, -0.5039,\n",
            "         0.2667, -0.1138,  0.1309,  0.0048, -0.0416,  0.2833,  0.0915, -0.2558,\n",
            "         0.2615,  0.2718,  0.3912,  0.0013,  0.0449,  0.1625,  0.1137, -0.2769,\n",
            "        -0.3051,  0.0803,  0.1880,  0.0239,  0.3748,  0.0118, -0.2429,  0.3186,\n",
            "         0.1913,  0.1397,  0.2275, -0.1913,  0.3709,  0.2632,  0.1784,  0.3184,\n",
            "         0.2778, -0.1962,  0.3217,  0.0623,  0.1910,  0.3508,  0.0399,  0.3589],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.4.weight', Parameter containing:\n",
            "tensor([[ 0.0565,  0.0171,  0.0188,  ...,  0.0987,  0.1173,  0.1536],\n",
            "        [ 0.1393, -0.1161,  0.0311,  ..., -0.3135,  0.1201,  0.0755],\n",
            "        [ 0.0218,  0.0205, -0.0096,  ..., -0.3853,  0.0061, -0.1554],\n",
            "        ...,\n",
            "        [-0.0556, -0.0433, -0.0670,  ...,  0.0939,  0.0120, -0.0244],\n",
            "        [-0.0826, -0.0812, -0.0731,  ..., -0.0274, -0.0613, -0.0296],\n",
            "        [ 0.0680,  0.0354,  0.0327,  ..., -0.0872,  0.0859, -0.0795]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.4.bias', Parameter containing:\n",
            "tensor([-0.0577,  0.0840, -0.2694,  0.1176,  0.1011, -0.0077, -0.0995,  0.0582,\n",
            "        -0.0130,  0.1264,  0.0361,  0.0533, -0.1020,  0.1151,  0.1838, -0.0885,\n",
            "        -0.1591, -0.0945, -0.0892, -0.1744,  0.1394,  0.1386, -0.0108,  0.0483,\n",
            "         0.1944,  0.1383, -0.0016,  0.1765,  0.1926, -0.0989,  0.0331,  0.1190,\n",
            "        -0.0496,  0.1823, -0.3049,  0.0020,  0.0929,  0.1499,  0.1837, -0.2040,\n",
            "         0.1446,  0.0011, -0.0970, -0.1000,  0.0466, -0.1412,  0.0251,  0.0311,\n",
            "         0.2119, -0.0325,  0.0412,  0.0849,  0.0813,  0.0525, -0.5420,  0.1892,\n",
            "         0.1956,  0.0805, -0.2842,  0.1108,  0.1216,  0.3776, -0.1346, -0.2134,\n",
            "         0.1484, -0.0738,  0.0759,  0.2084, -0.0549,  0.1548,  0.0522, -0.0853,\n",
            "         0.1148, -0.0072, -0.0399, -0.0170, -0.0550,  0.0884,  0.0009,  0.2917,\n",
            "        -0.1004,  0.1130,  0.0586,  0.0363,  0.1597,  0.0300,  0.1810, -0.1809,\n",
            "         0.0119,  0.0130,  0.0776,  0.1635, -0.1013,  0.2060, -0.1025,  0.0408,\n",
            "         0.1684,  0.1132, -0.1824, -0.0939, -0.0359,  0.1270, -0.0833,  0.3071,\n",
            "        -0.0510, -0.0603,  0.0665, -0.0651, -0.1218,  0.0723,  0.1892,  0.0952,\n",
            "        -0.0334,  0.0937, -0.0726, -0.1320,  0.1172, -0.3367,  0.2859, -0.0952,\n",
            "        -0.0475,  0.2839,  0.1079, -0.4679,  0.1891, -0.0564, -0.1234,  0.0180],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.6.weight', Parameter containing:\n",
            "tensor([[-0.0239, -0.0561, -0.1075,  ..., -0.0787, -0.0137, -0.0624],\n",
            "        [-0.0295, -0.1205, -0.1076,  ...,  0.0102,  0.0504, -0.0718],\n",
            "        [-0.0585,  0.0202, -0.1271,  ..., -0.0454,  0.0828,  0.0412],\n",
            "        ...,\n",
            "        [-0.1131, -0.0217, -0.2633,  ...,  0.0195,  0.0858,  0.0287],\n",
            "        [-0.0840,  0.0177, -0.2264,  ..., -0.0501, -0.0761,  0.0100],\n",
            "        [-0.0213, -0.0491, -0.2802,  ..., -0.0087,  0.0095, -0.0568]],\n",
            "       requires_grad=True))\n",
            "('decoder.decoder.6.bias', Parameter containing:\n",
            "tensor([-6.9632e-03, -7.5988e-03, -1.8377e-02, -5.8131e-02, -8.6429e-02,\n",
            "        -3.0369e-02,  9.8303e-03, -1.0116e-01, -6.9382e-02, -4.0913e-02,\n",
            "         3.5446e-02, -3.7800e-02, -1.2170e-01,  3.8185e-02, -1.0552e-02,\n",
            "        -8.2669e-02,  4.6793e-02, -8.4020e-02, -9.2043e-02, -6.7359e-02,\n",
            "        -5.0620e-02,  4.7192e-02, -1.1226e-01, -1.7278e-02, -9.6671e-02,\n",
            "        -7.8187e-02, -1.0482e-01, -7.0238e-02, -4.9751e-02,  2.5636e-02,\n",
            "        -8.5288e-03, -7.4845e-02, -6.2106e-02, -7.6538e-02, -9.1218e-02,\n",
            "        -9.4719e-02, -3.6350e-02, -9.6428e-02,  1.1188e-03, -9.5117e-02,\n",
            "         2.8151e-02, -9.2526e-02, -3.5544e-02,  1.2453e-02, -2.7345e-02,\n",
            "        -3.7753e-02, -1.1526e-01, -3.8413e-02, -2.8747e-03,  4.7896e-02,\n",
            "        -4.3373e-02, -3.1863e-02, -1.9806e-02, -9.8044e-02, -9.1729e-02,\n",
            "        -7.8089e-02,  3.0608e-02, -1.1497e-01, -3.1458e-03, -5.7596e-02,\n",
            "        -5.4939e-03, -4.1890e-02, -7.1134e-02,  3.9516e-02, -1.0550e-02,\n",
            "        -8.3240e-02, -2.4748e-02, -2.0078e-03, -1.2237e-02, -5.1819e-02,\n",
            "        -6.5698e-03,  6.0974e-03, -4.2046e-02, -4.1796e-02, -1.0384e-01,\n",
            "        -6.9615e-02, -8.6339e-02, -1.1320e-01, -1.3849e-02, -2.5691e-02,\n",
            "        -9.4880e-02, -6.8378e-02, -7.8096e-02, -7.3586e-02,  4.0858e-02,\n",
            "        -5.4069e-03,  2.4708e-02, -6.5273e-02,  3.0467e-02,  4.5287e-02,\n",
            "        -2.8856e-02, -1.1221e-01, -6.6675e-02, -2.5789e-02, -5.6327e-02,\n",
            "        -8.2417e-02, -1.0794e-01, -1.3845e-02, -8.2654e-02, -1.2648e-01,\n",
            "        -1.0080e-02, -1.1082e-01, -7.5514e-02, -1.2492e-01,  3.3746e-02,\n",
            "        -9.0952e-02, -9.1264e-02,  4.7466e-02, -8.4201e-02, -1.0472e-01,\n",
            "        -1.5360e-02, -4.6367e-02, -6.6261e-03,  3.3488e-02, -3.1820e-02,\n",
            "        -3.1047e-03, -6.8077e-02, -6.9140e-02,  1.7370e-02, -4.5540e-02,\n",
            "        -5.8773e-03, -7.2723e-02, -1.0999e-01,  3.5634e-03,  8.8049e-03,\n",
            "        -1.0599e-01, -1.5312e-01, -7.2812e-02, -3.8527e-02, -1.7570e-01,\n",
            "        -2.9792e-02, -1.4427e-02, -1.2487e-01, -6.0113e-02, -3.3255e-02,\n",
            "        -8.3559e-02, -9.9632e-02, -8.5173e-02, -3.5391e-02, -3.5308e-02,\n",
            "        -9.0712e-02, -4.6992e-02, -4.5851e-03, -5.5877e-02,  3.3649e-02,\n",
            "         3.7456e-02, -6.3317e-02, -5.1189e-02, -6.9118e-02, -7.5411e-02,\n",
            "        -7.8309e-02, -5.2055e-03, -2.9977e-02, -1.0776e-01, -7.1009e-02,\n",
            "        -9.3146e-02, -1.2356e-01, -1.4534e-01, -1.3412e-01, -1.0602e-01,\n",
            "        -1.2360e-01, -1.0923e-01,  4.8802e-02,  4.2337e-02, -4.2140e-02,\n",
            "        -2.8659e-02, -1.0472e-01,  4.3835e-02, -2.3130e-03, -7.0302e-03,\n",
            "         2.5906e-03,  4.3839e-02, -4.9234e-02, -1.2479e-01,  2.4636e-02,\n",
            "        -9.7887e-02, -6.3047e-02, -5.8423e-02, -1.8658e-02, -4.7242e-02,\n",
            "        -4.6659e-02, -8.7381e-02, -3.2748e-02, -1.7313e-01, -1.6548e-01,\n",
            "        -1.7297e-01, -1.0226e-01, -1.7933e-01, -1.1437e-01, -5.7735e-03,\n",
            "        -8.3735e-02, -1.3555e-02, -1.0624e-01,  1.3490e-02,  2.1937e-02,\n",
            "        -1.4889e-04, -1.5384e-02,  4.3013e-02, -1.6597e-02, -9.6061e-02,\n",
            "        -5.3558e-02, -3.1608e-02, -4.0023e-02, -2.8701e-02,  4.2253e-02,\n",
            "         3.6320e-02,  1.5673e-02, -9.7391e-03, -8.2586e-02, -1.7121e-01,\n",
            "        -2.0843e-01, -1.9684e-01, -2.5406e-01, -2.3740e-01, -6.5683e-02,\n",
            "        -1.6845e-01, -8.8338e-02,  3.4444e-02, -2.9217e-02,  5.6008e-02,\n",
            "        -9.4136e-02, -9.1479e-02, -1.2371e-01,  3.8283e-02, -1.1517e-01,\n",
            "        -4.1678e-02,  3.7290e-02, -1.0944e-01, -9.4247e-02, -7.9420e-02,\n",
            "         1.9373e-02,  2.8693e-02, -6.4358e-02, -5.9099e-02, -2.2349e-02,\n",
            "        -1.3979e-01, -2.7222e-01, -1.5962e-01, -3.1206e-01, -1.7311e-01,\n",
            "        -3.0440e-01, -2.0770e-01, -1.5062e-01, -1.7225e-01, -7.3648e-02,\n",
            "        -2.4065e-02,  5.1135e-02, -1.8114e-02, -5.5632e-02, -1.0576e-01,\n",
            "        -9.8248e-02, -2.9822e-02, -7.1776e-03, -4.6194e-02,  2.1778e-02,\n",
            "         1.7146e-02,  1.3448e-02, -5.6942e-02, -3.6812e-02, -7.4721e-04,\n",
            "        -9.5283e-02, -1.4163e-01, -2.3098e-01, -3.0909e-01, -1.5992e-01,\n",
            "        -1.6840e-01, -2.7384e-01, -2.5981e-01, -1.7327e-01, -1.8738e-01,\n",
            "        -2.1467e-01, -1.3024e-01, -8.8999e-02,  1.1222e-01,  9.7110e-02,\n",
            "        -2.2405e-02, -1.5776e-02,  1.3818e-02, -3.8304e-02, -9.9011e-02,\n",
            "        -1.2503e-01,  3.0140e-02, -1.0758e-01, -1.0568e-01, -7.4772e-02,\n",
            "         9.4933e-03,  9.3439e-03, -2.6505e-02,  5.5819e-02, -1.3114e-01,\n",
            "        -1.4702e-01, -2.8738e-01, -2.2645e-01, -2.2907e-01, -2.2381e-01,\n",
            "        -2.4085e-01, -2.5700e-01, -2.4289e-01, -2.4370e-01, -1.0805e-01,\n",
            "        -9.0124e-02, -4.8465e-03, -8.6344e-02, -8.7064e-02, -1.4845e-02,\n",
            "        -2.8163e-02, -2.7064e-02, -7.6437e-02, -1.0879e-01, -9.8991e-02,\n",
            "        -3.2774e-02, -9.8995e-02, -7.4480e-02, -5.1757e-02,  5.0074e-02,\n",
            "        -1.0691e-01, -2.6159e-02, -1.9708e-01, -1.9125e-01, -2.9223e-01,\n",
            "        -5.1515e-02, -1.0233e-01, -1.3409e-01, -2.4806e-01, -2.2682e-01,\n",
            "        -1.8820e-01, -2.1857e-01, -3.3583e-02,  6.0315e-02, -5.1465e-02,\n",
            "         4.8555e-02, -6.8240e-03, -2.8807e-02, -9.1099e-03, -3.0156e-02,\n",
            "        -7.1605e-02, -8.5064e-02, -9.7038e-02, -1.0457e-01, -1.0003e-01,\n",
            "        -9.9169e-02, -9.9156e-02, -9.0142e-02, -7.7390e-02, -2.9257e-02,\n",
            "        -7.5641e-02, -1.9306e-01, -1.5066e-01, -1.7229e-01, -9.6692e-02,\n",
            "        -2.3493e-01, -2.6540e-01, -2.7722e-01, -2.3916e-01, -2.3055e-01,\n",
            "        -4.6171e-02,  6.6017e-02, -7.2339e-02, -9.7982e-02, -8.3986e-02,\n",
            "        -5.1642e-02, -9.9930e-03, -7.9017e-02, -1.1122e-01, -8.0664e-02,\n",
            "        -8.4184e-02, -4.0825e-02, -1.0320e-01, -3.8104e-02, -2.5083e-02,\n",
            "         4.9828e-02, -1.1043e-01, -3.6954e-02, -1.0222e-01, -5.3684e-02,\n",
            "        -4.3994e-02, -4.1162e-02, -8.1274e-02, -2.2953e-01, -2.5956e-01,\n",
            "        -3.0020e-01, -2.1937e-01, -1.9616e-01, -9.2053e-02,  5.1296e-02,\n",
            "        -4.8513e-03,  1.5290e-03, -2.4569e-03, -6.6828e-02,  1.7826e-02,\n",
            "        -9.5818e-02, -4.2823e-02, -5.4452e-02, -1.4781e-02,  2.4671e-02,\n",
            "        -4.7117e-02, -9.5182e-02,  4.1320e-02, -1.9578e-02,  4.1328e-02,\n",
            "        -1.0594e-01, -1.3070e-01, -7.0018e-02, -4.9537e-02,  1.7579e-02,\n",
            "        -8.0375e-02, -2.2922e-01, -2.3622e-01, -2.3527e-01, -1.3792e-01,\n",
            "        -1.1704e-01,  5.7432e-02,  1.1838e-02,  3.7072e-02, -3.0498e-02,\n",
            "        -2.0064e-02,  3.2064e-02,  1.3693e-02, -7.3208e-02,  3.7102e-03,\n",
            "        -4.2628e-02, -3.0583e-02, -5.9879e-02,  1.2138e-03, -6.8175e-02,\n",
            "         2.5636e-02, -7.6194e-02, -2.3387e-02, -6.1675e-02, -1.7850e-01,\n",
            "        -9.4709e-02, -6.5543e-02, -1.1498e-01, -1.8698e-01, -1.5429e-01,\n",
            "        -1.4869e-01, -2.1208e-01, -5.8256e-02, -2.6626e-02, -1.2234e-02,\n",
            "         5.4668e-02, -1.0396e-01, -6.2902e-02,  2.1947e-02, -3.9644e-02,\n",
            "        -9.5066e-02,  4.5419e-02,  3.7702e-03, -1.0780e-01,  3.4784e-02,\n",
            "        -1.1163e-01, -5.8842e-02, -7.2088e-03, -1.7463e-02, -3.9732e-02,\n",
            "         3.2380e-02, -1.3387e-01, -7.1571e-02, -1.7233e-01, -1.6886e-01,\n",
            "        -1.2077e-01, -9.0451e-02, -7.3861e-02, -1.2707e-01, -6.8902e-02,\n",
            "        -7.9184e-02, -1.4842e-02, -1.6535e-02, -3.0052e-03, -1.3882e-02,\n",
            "        -8.8538e-02,  1.3757e-03,  1.2926e-02, -9.7075e-02,  4.6489e-02,\n",
            "        -4.1657e-02,  2.6493e-02,  1.3849e-02,  4.1116e-02,  4.0473e-02,\n",
            "        -3.4892e-03,  2.5635e-02, -1.1263e-01, -2.7959e-02, -2.1253e-02,\n",
            "        -6.1138e-02, -4.5919e-02, -1.7940e-01, -1.6590e-02, -1.5093e-01,\n",
            "        -3.5043e-02, -5.7747e-02, -9.4128e-02, -6.1016e-02,  9.4822e-04,\n",
            "        -7.5599e-03, -2.4242e-02, -8.6876e-02,  3.8720e-02, -8.1069e-02,\n",
            "         4.6872e-02, -5.8484e-02,  5.8764e-03,  5.9920e-03, -4.6471e-02,\n",
            "        -1.1698e-01, -3.8058e-02,  4.0263e-02,  5.6745e-02,  4.4001e-03,\n",
            "        -9.8860e-03,  1.3693e-02,  6.1801e-03, -1.2803e-01, -6.9438e-02,\n",
            "        -7.6879e-03, -1.2766e-02, -1.3515e-01, -1.9967e-01, -1.5736e-01,\n",
            "        -8.5777e-02, -2.1500e-02, -5.4996e-02,  4.2692e-02,  3.6679e-02,\n",
            "        -2.6264e-02, -4.0443e-02, -2.8251e-02, -8.3470e-02, -1.1803e-01,\n",
            "        -1.8252e-02, -4.8156e-02,  4.7191e-02, -5.0014e-02, -3.5933e-02,\n",
            "        -7.6363e-02, -7.1818e-02, -3.9041e-02, -3.7984e-02,  5.2174e-02,\n",
            "         9.1823e-03,  2.7344e-02,  5.8210e-02,  6.0626e-03, -7.5270e-02,\n",
            "        -1.7398e-01, -9.8617e-02, -1.1754e-01, -1.9237e-01, -1.2396e-01,\n",
            "        -3.5439e-02,  6.0912e-02, -5.8854e-02,  2.5993e-02,  5.3244e-02,\n",
            "         3.1510e-02,  1.3606e-02,  2.8666e-03, -3.4437e-02, -7.7656e-02,\n",
            "        -4.6027e-02, -5.9431e-02, -1.1391e-01,  4.5633e-02,  3.4737e-02,\n",
            "         3.9627e-03,  1.5754e-02,  3.0758e-02,  8.8903e-02,  2.7429e-02,\n",
            "         3.8499e-02, -9.0349e-02, -7.9837e-02, -1.9031e-01, -3.2955e-01,\n",
            "        -2.4709e-01, -2.5330e-01, -1.9164e-01, -1.2313e-01,  5.9088e-02,\n",
            "         1.5793e-02, -6.9142e-02, -9.6766e-02, -3.8164e-02, -4.5193e-02,\n",
            "        -9.8787e-02, -9.2684e-03,  1.0101e-02, -1.0114e-01, -9.9241e-02,\n",
            "        -7.3725e-02,  4.4445e-02, -3.6198e-02, -5.9199e-02, -7.1190e-02,\n",
            "         2.3286e-02, -3.0562e-02,  1.8754e-02, -6.1994e-02, -1.2365e-01,\n",
            "        -1.7303e-01, -1.8196e-01, -3.1991e-01, -3.3307e-01, -2.5267e-01,\n",
            "        -8.8570e-02,  2.2673e-02, -9.1289e-02,  1.2568e-02, -9.5413e-02,\n",
            "         1.6562e-02,  4.4062e-04, -7.1369e-02,  2.7835e-02, -4.7012e-02,\n",
            "        -4.7972e-02,  4.3569e-02, -9.5820e-02,  3.0825e-02, -2.0660e-02,\n",
            "         4.5832e-02, -4.4403e-02,  3.3487e-02, -1.0478e-01, -8.5301e-02,\n",
            "        -1.0525e-01, -1.0704e-01, -2.2103e-01, -3.0774e-01, -3.5137e-01,\n",
            "        -2.2803e-01, -1.9546e-01, -9.5911e-02, -2.2260e-02,  5.0417e-02,\n",
            "         2.8164e-02,  3.6098e-02, -4.8357e-02,  5.5146e-02, -8.9249e-02,\n",
            "        -1.6858e-02, -4.6694e-02, -1.0828e-01, -9.8441e-02, -1.9383e-02,\n",
            "        -9.7700e-02, -9.2793e-02, -1.5788e-02,  4.5145e-02,  3.5957e-02,\n",
            "        -3.5227e-02,  1.0661e-02, -7.3187e-02, -8.8519e-02, -2.8745e-01,\n",
            "        -2.2752e-01, -3.7598e-01, -2.2033e-01, -1.6578e-01, -4.7133e-02,\n",
            "        -1.2089e-01, -8.6501e-02, -3.5355e-02, -8.3890e-03, -8.0988e-02,\n",
            "         5.2004e-02, -2.3241e-03, -6.1574e-02, -3.0668e-02, -1.9670e-02,\n",
            "        -1.1587e-01, -8.5075e-02,  9.9309e-03, -9.3189e-02, -9.9674e-02,\n",
            "         4.5744e-02, -2.5221e-02, -9.4752e-02, -8.4559e-02, -1.0687e-01,\n",
            "        -5.0293e-02, -1.4168e-02, -2.1957e-01, -1.7381e-01, -1.4877e-01,\n",
            "        -1.6509e-01, -1.7102e-01, -1.6392e-01, -9.4256e-02, -2.4663e-03,\n",
            "        -7.4062e-02, -1.1544e-02, -6.7664e-02, -9.1403e-02,  4.4695e-02,\n",
            "         3.7833e-02, -1.0888e-01, -3.2424e-03, -5.9108e-02, -7.0376e-02,\n",
            "        -8.9686e-02, -8.8550e-02,  4.0190e-02, -1.0951e-01, -8.0425e-02,\n",
            "        -6.8455e-03, -6.2740e-02, -1.0670e-01,  2.1353e-02, -1.2117e-02,\n",
            "         5.7133e-03, -1.5921e-02, -6.6526e-02, -1.2098e-01, -1.3819e-01,\n",
            "        -1.4207e-01, -1.0618e-01, -6.9065e-02, -1.3942e-02, -1.9524e-02,\n",
            "         5.8854e-03,  1.8032e-02,  4.4679e-02,  4.9506e-03, -7.9740e-02,\n",
            "        -1.0031e-01, -6.3982e-02, -1.0162e-01, -9.1782e-02, -1.1743e-01,\n",
            "        -7.0701e-02, -2.5590e-02, -4.9105e-02, -5.3680e-02, -4.5218e-02,\n",
            "        -3.5588e-02, -5.3723e-02, -4.8161e-02,  2.8750e-04,  1.7931e-02,\n",
            "        -1.0308e-02, -8.8663e-02,  8.6605e-03,  3.8348e-02, -1.3255e-01,\n",
            "        -4.6684e-02, -5.7762e-02, -1.0194e-01, -9.8854e-02, -6.4025e-02,\n",
            "        -6.4733e-02,  2.8362e-02, -1.1995e-02,  3.7476e-02, -3.9122e-02,\n",
            "         3.7852e-02, -1.1123e-01, -1.0819e-01, -1.6087e-02, -1.1068e-01,\n",
            "         4.9270e-02, -9.8071e-02, -7.1408e-02, -1.1354e-01, -1.0142e-01,\n",
            "         4.9972e-02, -8.6115e-02, -1.2671e-02, -1.1298e-01,  1.3219e-02,\n",
            "        -3.0310e-02,  2.6808e-02,  4.0055e-02, -1.2309e-01, -7.5854e-02,\n",
            "        -4.2667e-03,  1.8318e-02,  7.7380e-03, -4.8429e-02, -7.1461e-03,\n",
            "        -1.0206e-01, -4.9877e-02, -1.6687e-02,  1.6481e-02],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.0.weight', Parameter containing:\n",
            "tensor([[ 9.5494e-02,  3.5508e-01, -3.3884e-01, -1.1777e-01, -2.8851e-01,\n",
            "         -4.7537e-01, -1.0550e-02, -3.9944e-01],\n",
            "        [ 2.8559e-01, -1.7288e-01,  2.8011e-01,  1.4481e-01, -1.9936e-01,\n",
            "          2.8065e-01,  3.2695e-01,  3.3923e-01],\n",
            "        [ 3.2871e-03, -4.2012e-01, -1.4746e-01, -2.5295e-01, -1.6939e-01,\n",
            "         -3.2442e-02, -1.6147e-01,  2.0827e-01],\n",
            "        [ 3.8289e-01,  4.4829e-01, -3.2955e-01,  2.0690e-02, -1.8972e-01,\n",
            "         -4.7096e-01, -1.4986e-01,  4.5460e-01],\n",
            "        [-3.4380e-01,  2.4382e-01, -2.7677e-01, -3.9413e-01, -4.9503e-02,\n",
            "          3.0056e-01, -4.3457e-01,  3.2942e-01],\n",
            "        [ 2.4036e-01, -1.9136e-01, -2.9565e-01, -4.5265e-01, -2.1375e-01,\n",
            "         -4.3775e-01,  2.2542e-02,  1.4369e-01],\n",
            "        [-4.3766e-01,  3.8637e-01,  9.6519e-03,  2.2580e-02, -4.2377e-01,\n",
            "         -3.7783e-01,  5.3214e-01, -3.9151e-01],\n",
            "        [ 1.8097e-01, -8.9886e-03, -3.9191e-01,  8.7145e-02,  2.9430e-02,\n",
            "         -3.7821e-02, -2.3260e-01,  2.0807e-01],\n",
            "        [ 3.3587e-01, -9.3768e-02, -4.4383e-02,  3.2347e-02,  3.6322e-01,\n",
            "         -1.8912e-01,  4.7996e-02, -3.4518e-01],\n",
            "        [-1.6028e-01,  1.1081e-01, -7.2055e-02, -1.9996e-01,  6.0197e-02,\n",
            "         -1.4207e-01,  1.6955e-02, -3.1897e-01],\n",
            "        [ 6.6579e-02,  2.0629e-01, -4.4513e-01,  2.3420e-01,  3.4094e-01,\n",
            "          2.3406e-01,  1.5038e-01,  1.2510e-01],\n",
            "        [ 2.6717e-01,  1.6714e-02, -3.8106e-01,  2.6465e-01,  3.3783e-02,\n",
            "          4.7264e-01, -2.2751e-04, -4.2532e-01],\n",
            "        [-3.8680e-01,  1.5373e-01,  1.4452e-01,  6.9791e-02, -1.4411e-01,\n",
            "          4.3283e-01,  1.7477e-01, -2.7645e-01],\n",
            "        [-2.5191e-01,  4.5794e-01,  9.5318e-02,  4.0674e-01,  1.9769e-01,\n",
            "          2.1687e-01,  1.5720e-01, -4.1265e-01],\n",
            "        [ 1.9145e-01,  3.0839e-01,  2.8552e-02,  5.0987e-01,  6.1734e-01,\n",
            "         -4.4459e-01, -1.0822e-01,  5.4765e-01],\n",
            "        [ 2.3190e-02,  3.4865e-01, -1.5269e-01, -3.2995e-01,  3.8463e-01,\n",
            "         -5.4396e-01, -1.7452e-01, -3.2111e-01],\n",
            "        [ 3.8328e-02, -2.0682e-01,  6.8264e-02, -3.8447e-01,  3.7682e-02,\n",
            "         -1.5886e-01, -3.4674e-01, -2.5598e-01],\n",
            "        [-2.6725e-01,  9.3275e-02, -2.1905e-01,  1.3153e-01, -1.0736e-01,\n",
            "          3.2940e-01,  4.3197e-01,  2.0790e-01],\n",
            "        [-3.9354e-01, -9.7597e-02, -1.4190e-01,  3.0265e-01, -3.7421e-02,\n",
            "          3.2323e-01, -9.8072e-02,  1.8534e-01],\n",
            "        [ 4.4169e-02, -1.9692e-02, -6.3146e-02, -2.0031e-02, -7.1983e-03,\n",
            "          1.5815e-01, -2.6603e-01,  1.3645e-01],\n",
            "        [-2.3383e-01, -3.7164e-02,  2.0203e-01, -1.7034e-01, -4.5299e-02,\n",
            "          3.8937e-01, -2.0469e-01,  3.1293e-01],\n",
            "        [-1.7705e-01,  5.7578e-02, -1.0469e-01,  2.6413e-01, -3.1571e-01,\n",
            "          1.6048e-01,  2.4130e-01, -2.8815e-01],\n",
            "        [-2.5666e-02,  1.8736e-02,  2.4432e-01, -1.6520e-01,  1.3210e-01,\n",
            "         -8.5460e-02, -2.4999e-01,  6.1783e-01],\n",
            "        [ 2.7724e-01,  8.5455e-02, -2.7790e-01,  2.5277e-01,  2.0498e-01,\n",
            "         -5.7088e-01, -5.2284e-02, -1.2923e-01],\n",
            "        [ 2.6746e-02, -1.6260e-01,  1.2545e-01,  3.3337e-01, -3.4777e-01,\n",
            "         -3.7611e-03,  1.2616e-01,  1.8805e-01],\n",
            "        [-3.8211e-02,  4.0329e-01, -2.9476e-02,  1.9101e-01,  2.7169e-01,\n",
            "          1.1009e-01, -1.8747e-01,  8.5990e-02],\n",
            "        [-3.6921e-01,  1.0082e-01, -4.6646e-02, -2.1051e-01,  2.7035e-01,\n",
            "          3.9050e-01, -2.0426e-01, -3.0276e-01],\n",
            "        [ 1.2190e-01, -3.0982e-02,  1.8096e-02, -2.8396e-01, -8.5095e-03,\n",
            "          1.2827e-01, -4.8154e-01, -1.2260e-01],\n",
            "        [-7.1455e-02, -3.6738e-01, -3.1142e-01,  1.4706e-01, -8.3676e-02,\n",
            "          7.3257e-01,  4.5321e-02,  2.1069e-01],\n",
            "        [-9.8238e-02,  1.4356e-01, -2.7279e-01,  3.2389e-01,  9.3899e-02,\n",
            "          1.5843e-01, -1.2210e-02, -2.2108e-01],\n",
            "        [ 1.3315e-01,  2.3874e-01, -2.7850e-01, -1.1772e-01, -5.3378e-02,\n",
            "          1.0034e-01, -2.1373e-01,  3.7371e-01],\n",
            "        [ 1.6579e-01, -7.3957e-02, -6.4003e-02, -2.1307e-01, -4.9381e-01,\n",
            "         -1.7555e-01,  2.6050e-01,  3.3823e-01],\n",
            "        [-9.7581e-02, -1.6873e-01, -2.6236e-01, -7.1893e-02,  1.6467e-01,\n",
            "          7.4641e-02,  2.3468e-01,  5.1188e-01],\n",
            "        [-1.3028e-01,  3.7708e-01,  2.0940e-01,  3.9549e-02,  3.5129e-01,\n",
            "         -8.0491e-01, -5.7634e-04, -3.8711e-01],\n",
            "        [ 2.9063e-01, -2.2068e-01, -4.1537e-01,  2.5795e-01, -2.7271e-01,\n",
            "         -1.7912e-01, -2.9535e-01, -6.9790e-02],\n",
            "        [-1.3143e-01,  5.9530e-02,  1.0440e-01, -1.3248e-01,  4.3124e-01,\n",
            "          4.7245e-01, -3.5318e-01, -2.3349e-01],\n",
            "        [ 2.0279e-01, -2.2884e-01, -5.6231e-02,  3.2031e-01, -1.5250e-01,\n",
            "          3.9501e-02,  1.0282e-01,  1.6599e-01],\n",
            "        [ 1.0871e-01,  3.4823e-02, -1.4937e-01, -2.7156e-01, -2.0384e-01,\n",
            "         -1.7575e-02,  4.6136e-01,  1.0955e-01],\n",
            "        [ 5.7298e-02, -2.7645e-01, -3.3690e-01, -9.1650e-02,  2.9229e-01,\n",
            "          2.9436e-01,  1.9043e-02,  5.4392e-01],\n",
            "        [ 9.6490e-02,  3.5313e-01,  2.4312e-01, -3.4901e-01,  7.2332e-02,\n",
            "         -5.6136e-02, -4.8423e-01,  2.1631e-02],\n",
            "        [ 3.2519e-02, -3.3683e-01,  2.7513e-01,  1.7871e-01,  2.5284e-02,\n",
            "         -7.8332e-03, -1.4435e-01,  2.6268e-01],\n",
            "        [-1.7816e-01, -1.6238e-01,  4.7479e-02,  7.5966e-02, -1.4624e-02,\n",
            "         -1.8930e-01, -4.8909e-01,  5.3579e-01],\n",
            "        [-3.0209e-01, -3.8148e-03,  2.6963e-01, -1.2284e-01, -3.0508e-01,\n",
            "          1.9285e-01, -1.5807e-01,  1.7740e-01],\n",
            "        [-6.6247e-02, -1.7648e-01, -1.4118e-01, -3.6274e-01,  7.4357e-02,\n",
            "         -3.0596e-01,  3.7093e-02, -3.6668e-01],\n",
            "        [ 3.3980e-01, -2.7779e-02,  3.1675e-01, -3.2858e-01,  2.8137e-01,\n",
            "         -6.7032e-02,  3.3009e-01, -1.5554e-01],\n",
            "        [ 2.5642e-01, -3.5326e-01, -2.9653e-01,  1.1676e-01, -3.3588e-01,\n",
            "          1.9462e-01, -5.2701e-01, -7.1370e-01],\n",
            "        [-3.7815e-01, -2.7366e-01,  1.7358e-01, -2.3619e-01, -4.6024e-02,\n",
            "          3.0342e-01, -5.7103e-01, -3.4755e-01],\n",
            "        [-1.3483e-01,  1.1758e-01,  5.9241e-02,  2.0827e-01,  5.9112e-01,\n",
            "          8.2158e-02, -5.3436e-01,  4.9699e-01],\n",
            "        [-3.6259e-02, -1.9416e-01, -1.2936e-01, -1.5179e-01, -3.6473e-01,\n",
            "         -1.0790e-01,  1.4993e-01, -1.0072e-02],\n",
            "        [ 3.9287e-02, -1.3171e-01,  1.3612e-01,  3.2280e-01, -5.5408e-03,\n",
            "          2.2034e-01,  1.0806e-01, -1.4233e-01],\n",
            "        [-3.3458e-01,  1.4227e-01,  1.8429e-02,  1.2801e-01, -2.7049e-01,\n",
            "          1.8985e-01,  5.3184e-01, -1.6202e-01],\n",
            "        [-2.8174e-01, -1.0741e-01,  1.1057e-01, -1.6630e-01,  9.5695e-02,\n",
            "          2.4962e-01, -4.5655e-01,  9.0213e-02],\n",
            "        [ 3.3351e-01, -7.1024e-02, -4.0917e-01,  2.2420e-01,  4.2140e-01,\n",
            "          2.1876e-01,  3.9734e-02,  1.0559e-01],\n",
            "        [ 5.4886e-01,  1.0433e-01, -2.7861e-01,  1.0367e-01, -2.6599e-01,\n",
            "         -5.7050e-01,  1.7943e-01,  1.8914e-01],\n",
            "        [-4.2283e-02, -2.5596e-01, -4.4729e-03,  3.2726e-01, -9.0082e-02,\n",
            "         -2.0556e-01,  3.0671e-01, -3.2467e-01],\n",
            "        [-8.6097e-02,  1.4192e-02, -1.2251e-01, -2.8247e-01,  4.8757e-01,\n",
            "         -3.8607e-01, -4.8152e-02, -1.3798e-01],\n",
            "        [ 4.4655e-01,  9.4769e-02,  1.7079e-01,  1.0573e-01, -1.1400e-01,\n",
            "         -8.3428e-02, -7.0833e-01,  3.1257e-01],\n",
            "        [-1.5956e-01,  3.5011e-01, -1.6142e-01,  2.0824e-01, -1.4775e-01,\n",
            "         -1.4816e-01,  2.9750e-01,  5.9499e-01],\n",
            "        [ 1.9889e-01,  2.7645e-01,  8.8895e-02, -1.4427e-01, -6.9378e-02,\n",
            "         -5.4577e-01, -3.7105e-01,  2.1487e-01],\n",
            "        [-1.4307e-01, -2.3349e-01, -3.2474e-01,  2.4446e-01,  3.9647e-01,\n",
            "          2.3641e-01,  4.5248e-01,  1.3989e-01],\n",
            "        [ 4.1292e-01, -3.3453e-01, -1.6848e-01, -4.2631e-02, -3.0214e-01,\n",
            "         -1.0978e-01, -4.7615e-01,  3.7596e-01],\n",
            "        [-2.5198e-01, -3.8868e-01, -3.3244e-01,  3.9799e-01, -3.9195e-02,\n",
            "          1.7465e-01, -2.6144e-01, -4.5940e-01],\n",
            "        [ 2.0480e-01, -2.2949e-01,  2.2887e-01,  2.6939e-01, -1.0731e-01,\n",
            "         -1.3517e-01,  9.8562e-02, -2.1377e-01],\n",
            "        [-3.8529e-01, -3.2685e-02,  1.0314e-01, -2.0828e-01, -4.9868e-01,\n",
            "         -6.8675e-03,  5.3575e-01,  2.2881e-01]], requires_grad=True))\n",
            "('clf.classifier.0.bias', Parameter containing:\n",
            "tensor([ 0.2047,  0.0240, -0.0614,  0.1438,  0.1267, -0.1531,  0.0115,  0.3980,\n",
            "        -0.1123, -0.1087,  0.2399,  0.5735, -0.3791,  0.6524,  0.5017, -0.4608,\n",
            "        -0.4046, -0.1378,  0.2419,  0.5188,  0.6814,  0.0279, -0.1517,  0.1489,\n",
            "        -0.1694,  0.4339,  0.2844,  0.5084, -0.3651,  0.2447,  0.4979,  0.6583,\n",
            "        -0.3273, -0.2617,  0.4798,  0.1160,  0.0367, -0.3562,  0.2509, -0.0672,\n",
            "        -0.1518,  0.0617,  0.4814, -0.4505,  0.0076,  0.1645,  0.0232,  0.5785,\n",
            "         0.1393, -0.2142, -0.1699,  0.4253,  0.1801,  0.2820,  0.3097, -0.2037,\n",
            "         0.4032, -0.5769,  0.1312,  0.3865, -0.0533,  0.0174,  0.1699,  0.0439],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.2.weight', Parameter containing:\n",
            "tensor([[-0.0635, -0.0871, -0.0347,  ..., -0.2480,  0.1071, -0.0779],\n",
            "        [ 0.0362,  0.1103,  0.1193,  ..., -0.0201,  0.0956,  0.3965],\n",
            "        [-0.0447, -0.0570,  0.1237,  ...,  0.0804,  0.1248, -0.8408],\n",
            "        ...,\n",
            "        [ 0.0589,  0.0906, -0.0194,  ...,  0.1115, -0.1208,  0.1307],\n",
            "        [ 0.0706,  0.1140,  0.0401,  ..., -0.1434, -0.1189,  0.2384],\n",
            "        [ 0.0356, -0.0587, -0.0856,  ...,  0.0381, -0.0717,  0.2050]],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.2.bias', Parameter containing:\n",
            "tensor([ 0.1637,  0.1635, -0.1112,  0.0601,  0.0621, -0.0016,  0.2996, -0.2136,\n",
            "         0.4744, -0.1175, -0.0240,  0.0248,  0.0575, -0.1003,  0.0561,  0.1396,\n",
            "        -0.0662, -0.1168, -0.0841, -0.4303,  0.4575,  0.1389,  0.6867, -0.0351,\n",
            "         0.1271,  0.0620,  0.0331,  0.1513, -0.3660,  0.0281,  0.1059, -0.0785],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.4.weight', Parameter containing:\n",
            "tensor([[-2.8324e-01, -1.7873e-01, -5.9105e-01,  2.5561e-01, -8.2886e-02,\n",
            "         -8.8431e-02, -3.7720e-01, -7.1863e-01, -3.3410e-01, -1.7022e-01,\n",
            "          1.2827e-01,  3.3345e-02,  6.3935e-02,  2.0991e-01,  1.5623e-01,\n",
            "         -9.9616e-01,  2.3219e-02, -2.3116e-02, -1.5153e-03,  1.2292e-01,\n",
            "          3.0903e-01, -6.8347e-02, -2.3349e-01,  7.0216e-02, -1.8206e-01,\n",
            "         -1.6303e-01,  1.5321e-01,  3.3814e-02,  1.1284e-01, -1.7390e-01,\n",
            "          1.2971e-01, -7.3000e-02],\n",
            "        [-3.6176e-01,  7.5587e-02,  1.6562e-01, -3.2387e-01,  5.4468e-02,\n",
            "         -9.9615e-02,  9.4356e-02,  4.8721e-01, -2.0647e-01,  2.2193e-03,\n",
            "          2.1321e-01,  1.5337e-01, -7.5871e-02,  1.6138e-01,  6.0440e-02,\n",
            "          1.6794e-01,  1.4634e-01,  7.7850e-02,  5.1111e-01, -2.0503e-01,\n",
            "         -3.5872e-01,  1.9019e-01, -9.3566e-02, -1.5609e-01,  1.4398e-01,\n",
            "         -5.5580e-01,  1.3838e-01,  7.1862e-02,  2.9169e-02, -6.3278e-02,\n",
            "         -7.4019e-02, -2.4952e-02],\n",
            "        [ 1.3396e-02,  4.6130e-01,  3.5389e-01, -1.5231e-01, -3.2996e-02,\n",
            "         -1.2123e-01,  1.6668e-01, -5.5947e-01,  7.9997e-02,  3.0359e-01,\n",
            "          2.0675e-01,  5.4435e-02,  7.3302e-02, -7.6206e-01,  1.4892e-01,\n",
            "          6.0267e-02,  1.1933e-01,  1.4293e-01, -4.1270e-01, -3.3192e-01,\n",
            "          2.4570e-02,  1.1195e-01, -9.8146e-03,  2.7900e-02,  1.7358e-01,\n",
            "         -1.2652e-01, -5.5804e-02,  2.4644e-01,  1.3800e-01,  1.1523e-01,\n",
            "         -2.3033e-01, -2.1987e-01],\n",
            "        [-4.4296e-02,  1.1635e-01,  2.1341e-01, -3.0092e-01,  1.7349e-01,\n",
            "         -9.9349e-02,  1.9016e-01, -2.3476e-01, -1.6552e-02, -4.9029e-02,\n",
            "         -7.2052e-02,  1.3296e-02,  1.1674e-01, -3.4719e-01,  1.0576e-01,\n",
            "          3.2713e-01,  7.3039e-02, -7.7042e-03, -3.3003e-01,  8.1012e-03,\n",
            "          1.4060e-01, -7.2546e-02, -3.2066e-03, -6.3799e-02,  1.1613e-01,\n",
            "          3.0417e-01, -6.2549e-02, -3.1732e-04, -9.6338e-02,  2.4135e-01,\n",
            "          3.3814e-02, -1.6099e-01],\n",
            "        [ 1.8371e-01,  3.2797e-01, -4.4882e-01,  1.3086e-01, -1.3054e-01,\n",
            "          7.2005e-02, -2.0214e-02,  3.0075e-02, -1.6834e-02, -3.9159e-01,\n",
            "         -5.1744e-02, -7.6134e-02,  1.4302e-01, -4.6924e-01,  1.1717e-01,\n",
            "         -1.0913e-01,  1.3003e-01,  1.0527e-01, -7.9163e-02, -4.5358e-01,\n",
            "         -3.0919e-02,  2.2405e-01,  3.9956e-02,  2.9958e-02,  1.6689e-01,\n",
            "         -4.3430e-01,  7.3813e-02, -1.4561e-01,  1.2731e-01,  6.1565e-02,\n",
            "         -1.0268e-01,  8.1110e-02],\n",
            "        [ 3.6977e-02, -7.0521e-01, -3.0829e-01, -8.3001e-02,  9.9202e-02,\n",
            "          1.3425e-01,  1.5409e-01, -6.1471e-02,  1.8652e-01, -5.9215e-01,\n",
            "         -3.0386e-01, -1.7548e-01,  1.8200e-02,  2.7096e-01,  1.0696e-01,\n",
            "          9.2212e-02,  1.4116e-02,  1.7350e-01,  3.2734e-02, -8.5248e-02,\n",
            "          1.9100e-01, -9.2483e-02,  2.2242e-01, -1.1221e-02, -1.5722e-01,\n",
            "         -1.2319e-02,  7.2598e-02, -2.2279e-01, -3.7269e-01, -2.0227e-01,\n",
            "          2.2581e-01, -7.5917e-02],\n",
            "        [ 2.5704e-01,  4.9058e-01, -8.1906e-01,  6.7779e-02,  7.4130e-02,\n",
            "          9.6585e-02, -8.6546e-02, -7.7955e-02, -4.2264e-01, -2.3223e-01,\n",
            "          1.1376e-01,  5.3097e-02,  7.8210e-02,  3.0094e-01,  1.3889e-01,\n",
            "         -4.5161e-01,  8.1029e-02,  1.0226e-01,  2.3092e-01, -1.8860e-01,\n",
            "         -7.7360e-02,  1.9063e-01, -1.6809e-01,  1.0316e-01, -3.1865e-01,\n",
            "         -7.2015e-01,  6.4848e-02,  2.8302e-01, -1.1521e-01, -5.4408e-01,\n",
            "          1.1062e-01, -2.2497e-01],\n",
            "        [ 5.0495e-03, -4.1519e-01,  2.5327e-01,  3.9537e-02, -4.0013e-01,\n",
            "         -7.8213e-02,  4.0338e-02,  1.2895e-01,  2.3030e-01,  6.7493e-01,\n",
            "         -2.7838e-01, -7.9465e-02, -8.3378e-02,  2.3655e-02,  1.6743e-01,\n",
            "          3.1663e-02, -2.9574e-02, -9.1291e-02,  2.8486e-01,  3.8403e-01,\n",
            "         -1.1341e-01,  1.0170e-01, -1.9676e-01, -1.1714e-02,  1.6115e-01,\n",
            "         -4.5832e-01, -2.4431e-02,  1.1973e-01,  3.0872e-02,  1.7150e-01,\n",
            "         -2.8787e-01, -8.7462e-03],\n",
            "        [-4.5291e-01,  1.4942e-02,  5.7510e-02,  2.6822e-01,  2.1253e-01,\n",
            "         -4.6236e-02,  5.1697e-02, -4.0329e-01, -1.2290e-01, -1.7139e-01,\n",
            "         -3.4056e-01, -8.3783e-02, -8.2132e-02, -1.0501e-01, -1.6138e-01,\n",
            "          1.0749e-01, -1.8127e-01,  1.4299e-01, -4.4780e-01, -2.0610e-01,\n",
            "          1.1152e-02, -1.8146e-01,  8.1776e-02,  1.6359e-01,  9.0747e-02,\n",
            "         -1.6877e-01, -1.5208e-01, -7.4799e-02,  4.4823e-02, -2.0114e-01,\n",
            "         -2.7683e-03,  1.2189e-01],\n",
            "        [ 1.3999e-01, -4.7520e-02,  1.5781e-01,  8.0241e-02,  1.3357e-01,\n",
            "          8.2823e-02,  5.1732e-02,  1.7784e-01, -3.3355e-02, -2.1017e-01,\n",
            "         -4.7227e-02,  2.0028e-02,  1.3009e-03, -1.9998e-03,  6.1884e-02,\n",
            "         -2.4281e-02, -7.9935e-02, -8.8277e-02,  6.1182e-03,  1.7265e-01,\n",
            "         -3.1498e-01, -2.3242e-01, -1.4522e-01, -1.5324e-01, -1.1808e-01,\n",
            "         -1.7656e-02, -1.1460e-01, -5.6771e-01,  1.9358e-01, -3.7900e-02,\n",
            "         -2.0478e-02,  1.7377e-01]], requires_grad=True))\n",
            "('clf.classifier.4.bias', Parameter containing:\n",
            "tensor([-0.2615, -0.2243,  0.1138,  0.0218,  0.2131,  0.4413, -0.0877,  0.0649,\n",
            "         0.0802, -0.2082], requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUAz78O3KLhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e11cc1-3742-474e-d000-082c75ff30a1"
      },
      "source": [
        "for param in model3.named_parameters():\n",
        "  print(param)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('encoder.encoder.0.weight', Parameter containing:\n",
            "tensor([[ 3.2411e-02, -3.2762e-02,  2.6795e-02,  ...,  2.7951e-02,\n",
            "          7.7435e-05,  2.1013e-02],\n",
            "        [ 2.6341e-02,  2.0946e-02, -4.3794e-03,  ..., -2.7978e-02,\n",
            "         -3.0247e-02, -2.8799e-02],\n",
            "        [ 3.6207e-03, -1.1272e-02, -1.6410e-02,  ...,  3.1289e-02,\n",
            "         -1.5675e-02, -2.7952e-02],\n",
            "        ...,\n",
            "        [ 1.3151e-02,  1.7483e-02, -2.0752e-02,  ...,  7.6169e-03,\n",
            "         -9.5549e-03,  1.3336e-02],\n",
            "        [ 6.5785e-03, -1.6895e-02, -2.6035e-02,  ...,  1.5044e-02,\n",
            "         -1.9176e-02, -3.3738e-02],\n",
            "        [-2.8310e-02,  6.3773e-03, -3.0421e-04,  ..., -2.5119e-02,\n",
            "         -6.2974e-04, -2.0374e-02]], requires_grad=True))\n",
            "('encoder.encoder.0.bias', Parameter containing:\n",
            "tensor([-0.0262,  0.0281,  0.0184,  0.0139,  0.0242, -0.0137, -0.0067, -0.0322,\n",
            "        -0.0218,  0.0079,  0.0260,  0.0105,  0.0320, -0.0328, -0.0320,  0.0268,\n",
            "         0.0121, -0.0013, -0.0222,  0.0302, -0.0154, -0.0069, -0.0263,  0.0254,\n",
            "        -0.0011, -0.0350, -0.0061, -0.0127, -0.0304, -0.0283, -0.0231,  0.0342,\n",
            "        -0.0128, -0.0160, -0.0057,  0.0264, -0.0014,  0.0302,  0.0216,  0.0079,\n",
            "        -0.0070, -0.0081, -0.0251,  0.0147, -0.0126,  0.0346, -0.0128,  0.0124,\n",
            "         0.0335, -0.0217,  0.0355, -0.0094, -0.0081,  0.0316, -0.0100,  0.0248,\n",
            "         0.0211,  0.0195, -0.0239,  0.0270,  0.0091, -0.0065, -0.0275,  0.0032,\n",
            "         0.0353,  0.0050, -0.0335, -0.0011, -0.0181,  0.0106,  0.0203, -0.0203,\n",
            "         0.0022,  0.0209,  0.0163,  0.0092, -0.0014, -0.0199, -0.0071,  0.0325,\n",
            "        -0.0084, -0.0219, -0.0225,  0.0027, -0.0093,  0.0324, -0.0123,  0.0324,\n",
            "        -0.0250,  0.0345, -0.0339, -0.0253,  0.0103, -0.0049,  0.0191,  0.0044,\n",
            "         0.0250, -0.0063, -0.0147,  0.0169, -0.0299, -0.0131, -0.0021,  0.0128,\n",
            "        -0.0016,  0.0176,  0.0159,  0.0167,  0.0086, -0.0224, -0.0152, -0.0146,\n",
            "         0.0293, -0.0054, -0.0116,  0.0140,  0.0238, -0.0217,  0.0120,  0.0065,\n",
            "         0.0154, -0.0251, -0.0055,  0.0138,  0.0183, -0.0175,  0.0143, -0.0315],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.2.weight', Parameter containing:\n",
            "tensor([[-0.0270, -0.0720,  0.0577,  ..., -0.0673,  0.0664,  0.0361],\n",
            "        [ 0.0694,  0.0765, -0.0355,  ..., -0.0428,  0.0273, -0.0709],\n",
            "        [ 0.0473,  0.0192,  0.0251,  ...,  0.0095, -0.0233, -0.0807],\n",
            "        ...,\n",
            "        [ 0.0279, -0.0269,  0.0067,  ..., -0.0544,  0.0216, -0.0515],\n",
            "        [ 0.0732, -0.0795, -0.0019,  ..., -0.0107, -0.0523, -0.0365],\n",
            "        [-0.0786, -0.0238, -0.0788,  ...,  0.0332, -0.0242, -0.0470]],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.2.bias', Parameter containing:\n",
            "tensor([-0.0643, -0.0848, -0.0247, -0.0050,  0.0421, -0.0798,  0.0653,  0.0817,\n",
            "         0.0609,  0.0818,  0.0846,  0.0761, -0.0080, -0.0406, -0.0332, -0.0267,\n",
            "         0.0714, -0.0670,  0.0062,  0.0522, -0.0032,  0.0441,  0.0317, -0.0012,\n",
            "         0.0285, -0.0377,  0.0754,  0.0728, -0.0199,  0.0061, -0.0650,  0.0417,\n",
            "         0.0342, -0.0543,  0.0459,  0.0411, -0.0395, -0.0237, -0.0338, -0.0746,\n",
            "        -0.0697,  0.0623, -0.0119,  0.0521,  0.0039,  0.0760,  0.0246,  0.0721,\n",
            "        -0.0051,  0.0290,  0.0781,  0.0084, -0.0240,  0.0175,  0.0340,  0.0518,\n",
            "         0.0318, -0.0167, -0.0822, -0.0613, -0.0032, -0.0589, -0.0381, -0.0664],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.4.weight', Parameter containing:\n",
            "tensor([[ 0.0773,  0.0266, -0.0019,  ..., -0.0008,  0.1074, -0.0488],\n",
            "        [ 0.0225, -0.1235,  0.0113,  ...,  0.1168,  0.0634,  0.0063],\n",
            "        [ 0.0795,  0.0210, -0.1163,  ..., -0.0646,  0.0982,  0.1189],\n",
            "        ...,\n",
            "        [-0.0729, -0.0424,  0.0138,  ...,  0.0906, -0.0575, -0.0190],\n",
            "        [ 0.0407,  0.0766, -0.1144,  ...,  0.1121,  0.0213,  0.0889],\n",
            "        [-0.0913,  0.0319, -0.0947,  ...,  0.0553, -0.0511, -0.0220]],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.4.bias', Parameter containing:\n",
            "tensor([ 0.0699,  0.1092, -0.0347, -0.0365, -0.0465, -0.0210, -0.0346,  0.0671,\n",
            "         0.0268, -0.0722, -0.0454,  0.0153,  0.0738, -0.1127, -0.0383,  0.0738],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.6.weight', Parameter containing:\n",
            "tensor([[ 0.1846, -0.1640,  0.0316,  0.2139, -0.0912, -0.1281,  0.2145,  0.0058,\n",
            "          0.0156, -0.1693,  0.1104, -0.0610, -0.0849,  0.0546,  0.1146,  0.1225],\n",
            "        [-0.1991,  0.0109, -0.1019,  0.1443,  0.1602,  0.1935,  0.0864,  0.1151,\n",
            "         -0.0014, -0.1267, -0.2489,  0.0742,  0.0683, -0.0831, -0.0046,  0.1868],\n",
            "        [ 0.1719,  0.0183,  0.0079,  0.1067, -0.1201, -0.0707, -0.1930,  0.0014,\n",
            "          0.0425,  0.2463, -0.0616, -0.1337, -0.0889, -0.1849,  0.0453, -0.0107],\n",
            "        [-0.2072, -0.1623,  0.2437, -0.1036,  0.0843,  0.0197,  0.2192,  0.0226,\n",
            "         -0.0784, -0.0584,  0.1230, -0.0277,  0.1151,  0.2233, -0.0190,  0.0860],\n",
            "        [-0.0620, -0.1981,  0.2426, -0.0677,  0.1520, -0.1395, -0.1532, -0.0859,\n",
            "         -0.1532, -0.0349,  0.0572, -0.0796, -0.1324, -0.2031, -0.1710,  0.1221],\n",
            "        [ 0.1293,  0.1037, -0.1337, -0.0920,  0.0150,  0.1877, -0.2175,  0.0525,\n",
            "          0.2287,  0.0682,  0.1430, -0.2243, -0.1757,  0.1898, -0.1967,  0.0913],\n",
            "        [-0.2081, -0.0023, -0.1077, -0.1744, -0.0322, -0.1875,  0.0196, -0.0611,\n",
            "          0.1185,  0.0980, -0.0508, -0.0231, -0.2009,  0.0084, -0.0549, -0.0647],\n",
            "        [-0.1468, -0.0169, -0.1066, -0.0540,  0.0310, -0.0974,  0.2256, -0.0800,\n",
            "         -0.2322, -0.0776, -0.1866,  0.1261,  0.2092, -0.0947, -0.1636,  0.1385]],\n",
            "       requires_grad=True))\n",
            "('encoder.encoder.6.bias', Parameter containing:\n",
            "tensor([-0.0068, -0.1970,  0.0877, -0.0626,  0.0547, -0.2299, -0.0401, -0.1905],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.0.weight', Parameter containing:\n",
            "tensor([[ 3.1830e-01,  2.8991e-01,  3.0021e-01, -1.1534e-01,  1.6069e-02,\n",
            "         -1.7974e-01, -9.1215e-03, -3.1097e-01],\n",
            "        [ 2.4035e-01,  1.5866e-01, -1.8113e-01, -2.8889e-02, -1.8389e-01,\n",
            "         -3.0275e-01,  1.2645e-01,  2.5938e-01],\n",
            "        [ 3.1172e-01, -2.2684e-02, -1.4949e-01,  2.0782e-01, -1.6584e-01,\n",
            "          1.6988e-01, -4.4617e-02,  3.3408e-01],\n",
            "        [ 4.7821e-02,  2.4349e-01,  2.7101e-02, -3.1925e-01,  3.1347e-01,\n",
            "         -4.7301e-02, -1.4643e-01,  9.6862e-02],\n",
            "        [-3.0706e-01,  2.3759e-01,  9.6529e-02,  1.5761e-01,  9.6702e-02,\n",
            "          2.7747e-01,  3.3367e-01, -2.3305e-01],\n",
            "        [ 2.1321e-01, -3.0098e-01,  9.7698e-02, -1.4870e-01,  2.3599e-01,\n",
            "         -1.6699e-01, -2.7114e-01, -2.1696e-01],\n",
            "        [ 2.9188e-01,  2.4003e-01,  1.0225e-01, -1.6349e-02,  2.5028e-01,\n",
            "         -7.1145e-02,  1.0620e-01, -7.6666e-02],\n",
            "        [-2.8395e-01, -2.8633e-01, -2.3362e-02, -2.7411e-01, -3.0247e-01,\n",
            "         -7.1638e-02,  2.4725e-01,  3.1917e-01],\n",
            "        [ 2.4574e-01,  2.2858e-01,  1.4110e-01,  1.0816e-01,  3.0159e-01,\n",
            "          1.4601e-01, -7.1594e-02,  2.9091e-01],\n",
            "        [ 2.6672e-01, -1.0567e-01, -2.0884e-01, -2.1968e-01,  3.2151e-01,\n",
            "         -1.0623e-01,  1.8015e-01, -4.8628e-02],\n",
            "        [ 3.0546e-01,  8.2465e-02,  2.1653e-01,  1.9795e-01, -3.2201e-01,\n",
            "         -2.6598e-01, -2.9498e-01, -1.8083e-02],\n",
            "        [ 7.3822e-02, -1.0965e-01,  8.7952e-02,  2.2088e-01,  1.6442e-01,\n",
            "         -3.4937e-01, -6.9331e-02, -2.2546e-01],\n",
            "        [ 2.8925e-01, -3.8343e-02, -7.1636e-02,  2.8074e-01,  2.9673e-02,\n",
            "          2.8186e-01, -3.2141e-01,  1.3215e-01],\n",
            "        [-2.1816e-01,  1.1700e-01, -1.7484e-01,  1.4522e-01,  2.0100e-01,\n",
            "         -7.7958e-02,  7.1406e-03,  2.8807e-01],\n",
            "        [ 2.3962e-01, -2.9025e-02, -2.1134e-01,  9.8070e-02, -1.5031e-01,\n",
            "          2.1071e-01, -1.9174e-01,  2.5852e-01],\n",
            "        [ 3.2829e-01, -1.5716e-01,  3.1636e-01,  7.1108e-02,  2.6209e-01,\n",
            "         -3.0395e-01,  5.5046e-02,  1.0414e-01],\n",
            "        [-2.8491e-01,  2.4249e-01, -3.0796e-01,  1.6389e-01, -1.3327e-01,\n",
            "          2.9043e-02,  7.3633e-02, -2.9342e-01],\n",
            "        [-3.3870e-01, -2.9686e-01,  1.6663e-01,  2.0385e-01,  2.2308e-01,\n",
            "         -7.2210e-02, -8.6672e-02, -3.0264e-01],\n",
            "        [ 3.3695e-01,  3.5340e-01, -8.2371e-02,  2.1707e-02, -8.3965e-02,\n",
            "         -1.1274e-01, -1.2619e-02,  2.0609e-01],\n",
            "        [ 7.2594e-02,  4.5698e-02, -1.0520e-01,  2.3469e-01,  6.5853e-02,\n",
            "          2.0197e-01,  1.8232e-01,  2.2270e-01],\n",
            "        [-1.4048e-01, -2.0995e-01,  2.5691e-01, -3.0160e-01, -3.4220e-01,\n",
            "          2.5053e-02,  1.4218e-02,  3.9203e-02],\n",
            "        [-1.8110e-01,  9.6097e-02, -4.8783e-02,  4.4498e-02,  3.1577e-01,\n",
            "         -2.0273e-01,  2.6307e-01, -3.4398e-01],\n",
            "        [ 7.5404e-02, -2.2157e-01, -4.0056e-02, -8.4497e-02,  2.0312e-01,\n",
            "          2.0009e-01, -1.6628e-01,  1.6400e-01],\n",
            "        [-3.3123e-01,  3.4002e-01,  3.2952e-01,  3.4448e-01,  2.7821e-01,\n",
            "         -3.8466e-02,  2.1608e-01, -1.7977e-01],\n",
            "        [ 2.6505e-01,  3.1227e-01,  1.7007e-02,  2.1312e-01, -1.0191e-01,\n",
            "         -6.5847e-02,  1.4135e-01, -3.1466e-01],\n",
            "        [ 3.9348e-02, -3.2757e-01, -1.7510e-01,  1.2293e-01, -5.3410e-02,\n",
            "          1.9315e-01, -4.7873e-02,  4.7216e-02],\n",
            "        [-2.1090e-01,  3.1483e-01,  2.3067e-01, -1.4529e-01,  2.3484e-01,\n",
            "          1.6026e-01, -2.3848e-01,  1.8547e-01],\n",
            "        [-2.6713e-01, -3.3777e-01,  2.0780e-01,  1.2676e-01, -2.6863e-02,\n",
            "         -8.1756e-02, -2.4744e-01, -3.0583e-02],\n",
            "        [-1.9140e-01,  1.7813e-01, -1.6730e-01,  2.8966e-01,  2.3973e-01,\n",
            "         -3.3440e-01,  3.4864e-01, -9.1523e-02],\n",
            "        [ 1.5784e-01,  1.1571e-01,  2.2489e-01, -1.1647e-01, -2.7661e-01,\n",
            "         -1.7318e-01, -1.2689e-01,  3.0358e-01],\n",
            "        [ 1.3433e-01, -2.3652e-01,  7.6723e-02,  1.7323e-01,  2.6786e-02,\n",
            "         -2.5338e-02,  2.1882e-01, -2.4851e-01],\n",
            "        [ 5.1629e-02, -2.1697e-01, -1.6358e-01, -2.8939e-01, -2.4904e-01,\n",
            "          4.1455e-03, -3.2850e-01,  2.9004e-01],\n",
            "        [ 2.4862e-01, -2.5017e-02, -3.2456e-01,  2.9661e-01,  1.0771e-01,\n",
            "          1.4182e-01,  2.6752e-01, -1.6909e-01],\n",
            "        [ 2.9759e-01, -2.4681e-01,  1.2899e-01,  1.3119e-01, -2.2432e-01,\n",
            "          1.7786e-01,  3.0358e-01,  4.3139e-02],\n",
            "        [-1.7385e-01,  1.5385e-01, -1.9838e-01, -1.8557e-01,  2.6023e-01,\n",
            "         -3.5015e-01,  3.3454e-03,  2.2125e-01],\n",
            "        [ 1.5151e-01, -3.2744e-01,  1.1958e-02,  1.5577e-01,  2.4501e-01,\n",
            "         -1.1818e-01, -1.5600e-01,  9.7608e-02],\n",
            "        [ 2.1846e-01,  6.3389e-02, -9.5354e-02, -3.3015e-01,  1.4782e-01,\n",
            "         -1.8445e-01, -1.7265e-01, -8.4859e-02],\n",
            "        [ 1.4881e-01, -1.5623e-01,  3.0269e-01,  2.8562e-01,  1.0443e-01,\n",
            "         -4.4350e-02,  2.8126e-02, -1.1049e-01],\n",
            "        [-1.9836e-01,  9.5609e-02, -2.9599e-01,  2.2475e-01,  7.6585e-02,\n",
            "          1.5829e-01,  1.7652e-01,  1.3418e-01],\n",
            "        [ 9.3959e-02, -2.1443e-01, -2.8477e-01,  2.0006e-01, -3.0604e-01,\n",
            "          2.5221e-01, -8.8913e-02, -1.8628e-01],\n",
            "        [ 2.3076e-01,  3.0825e-02,  2.6367e-01,  3.1137e-01, -2.8029e-01,\n",
            "          9.4367e-02, -2.2578e-01, -2.5711e-01],\n",
            "        [ 1.5681e-01, -1.1684e-01, -2.3237e-01, -8.4147e-02, -2.7953e-01,\n",
            "         -2.6627e-01,  2.8395e-01,  1.0315e-02],\n",
            "        [-1.4985e-01, -1.7040e-01,  2.8238e-04, -1.6290e-01, -1.0144e-02,\n",
            "          1.0813e-01,  2.0771e-01,  1.8523e-01],\n",
            "        [-1.8567e-02, -2.9213e-01, -1.2184e-01, -5.6427e-02,  2.6022e-01,\n",
            "         -1.5267e-01,  2.0600e-01,  2.5785e-01],\n",
            "        [ 2.0454e-01,  6.6945e-02, -7.1581e-02, -1.9927e-01,  1.0849e-01,\n",
            "          2.2279e-01, -1.7317e-01, -2.6516e-01],\n",
            "        [ 2.8074e-01,  2.2929e-01, -7.5863e-02,  1.0769e-01,  2.5462e-01,\n",
            "          6.6055e-02, -6.0269e-02, -1.5054e-01],\n",
            "        [ 1.4087e-01,  2.0708e-03,  4.2213e-02, -1.6587e-01, -2.0257e-01,\n",
            "          1.1897e-01, -9.6707e-02,  6.4563e-02],\n",
            "        [ 3.3687e-01, -1.0036e-01, -1.4607e-01,  1.8272e-01,  5.6975e-02,\n",
            "         -2.3193e-01,  1.7019e-01, -2.8375e-01],\n",
            "        [ 3.1850e-01, -2.4154e-01, -2.2006e-02, -2.1003e-01,  3.6923e-02,\n",
            "         -1.0582e-01,  6.8674e-02,  7.5434e-02],\n",
            "        [ 3.1838e-01, -1.7650e-01,  3.4994e-01, -1.6512e-01, -3.4435e-01,\n",
            "         -3.1727e-01, -9.2672e-02,  2.2799e-01],\n",
            "        [ 2.9751e-02, -2.0267e-01,  2.5526e-01,  3.4799e-01,  3.5267e-02,\n",
            "         -2.8892e-01,  8.3137e-02,  7.6205e-02],\n",
            "        [ 2.6159e-01,  5.7226e-02, -3.2717e-02, -8.0238e-02, -1.0281e-01,\n",
            "          1.5710e-01, -2.9203e-01,  2.3012e-01],\n",
            "        [-1.9112e-01, -2.7805e-01, -1.1762e-01,  3.4347e-02,  2.2232e-01,\n",
            "          2.9453e-01, -2.0084e-01,  2.8816e-01],\n",
            "        [-8.5081e-02,  2.8040e-02,  3.2902e-01, -1.6733e-01,  1.7073e-01,\n",
            "         -3.1137e-01, -7.7327e-02, -2.2437e-01],\n",
            "        [-8.0047e-02,  2.2035e-01, -3.0629e-01, -8.8741e-02, -1.5570e-01,\n",
            "         -3.5097e-01, -1.0531e-01, -2.6269e-01],\n",
            "        [ 2.2530e-01,  1.4838e-01, -2.2057e-01, -2.8509e-01, -1.1519e-01,\n",
            "          3.5521e-03,  1.7814e-01,  3.3986e-01],\n",
            "        [-2.5215e-02, -1.8327e-01,  3.6031e-02,  2.6418e-01,  6.6018e-02,\n",
            "          2.0929e-01, -2.4148e-01, -1.8940e-01],\n",
            "        [ 3.4802e-01,  6.9092e-02,  7.9455e-02, -1.5453e-01,  2.5118e-01,\n",
            "          2.5874e-01,  2.9017e-01,  9.3104e-02],\n",
            "        [ 4.5208e-02, -1.6257e-01,  1.3984e-01,  5.2422e-02,  2.8833e-01,\n",
            "         -7.8469e-04, -1.1697e-01,  1.7210e-01],\n",
            "        [ 2.2087e-01, -2.2227e-01, -1.5415e-01, -3.4038e-01,  1.7859e-01,\n",
            "          4.4755e-02,  2.7669e-01, -3.2278e-01],\n",
            "        [-1.2093e-02, -3.2637e-02,  1.0281e-01,  2.2605e-01,  2.2776e-01,\n",
            "          3.8029e-02, -1.9131e-01, -1.4259e-01],\n",
            "        [-1.1678e-01,  2.3294e-01,  1.9760e-01, -1.3504e-01, -2.0682e-01,\n",
            "          2.4412e-01, -1.7884e-01,  2.8776e-01],\n",
            "        [-2.9910e-01, -2.1482e-01,  3.4747e-01,  2.9484e-01, -3.4042e-01,\n",
            "          6.0074e-02,  8.9609e-02, -1.9401e-01],\n",
            "        [-2.9563e-01, -7.2984e-02, -6.9098e-02,  3.4923e-01,  2.1460e-01,\n",
            "         -1.3671e-01,  3.3026e-01, -2.0934e-01]], requires_grad=True))\n",
            "('clf.classifier.0.bias', Parameter containing:\n",
            "tensor([ 0.0074,  0.1870, -0.2587, -0.1204, -0.1225, -0.2733, -0.2478, -0.1417,\n",
            "         0.3355, -0.1675,  0.2610,  0.0381, -0.2461, -0.1002, -0.1918,  0.1648,\n",
            "         0.2887, -0.0021,  0.1046,  0.0663,  0.0881,  0.3297,  0.1739, -0.2125,\n",
            "         0.0344,  0.2610,  0.2841,  0.2122,  0.3471,  0.0506, -0.0464, -0.2025,\n",
            "        -0.2675,  0.0953,  0.2792, -0.2984, -0.2249, -0.2780,  0.2686,  0.3182,\n",
            "         0.1331,  0.2870, -0.2279,  0.2864,  0.3496,  0.0013, -0.1494,  0.0947,\n",
            "        -0.2157, -0.0719, -0.3194,  0.2167, -0.2710,  0.2415,  0.0256, -0.0280,\n",
            "         0.2683, -0.2525, -0.1877,  0.2011, -0.3350, -0.2991,  0.2582, -0.0554],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.2.weight', Parameter containing:\n",
            "tensor([[-0.0212,  0.0701, -0.0431,  ..., -0.0348, -0.1196, -0.0959],\n",
            "        [ 0.0047,  0.0673,  0.0688,  ..., -0.1237,  0.0421,  0.0626],\n",
            "        [-0.0969,  0.1134,  0.0755,  ..., -0.0157,  0.0602, -0.0672],\n",
            "        ...,\n",
            "        [-0.0744, -0.0398, -0.0905,  ...,  0.1060, -0.0871,  0.0604],\n",
            "        [-0.0555,  0.0266, -0.0917,  ...,  0.1021,  0.0828,  0.0085],\n",
            "        [-0.0570, -0.0133, -0.0255,  ..., -0.0159, -0.0585, -0.1216]],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.2.bias', Parameter containing:\n",
            "tensor([-2.3688e-03,  3.4431e-02, -5.7096e-02, -4.2269e-02, -6.3928e-02,\n",
            "         1.0553e-01, -3.5105e-02,  8.9648e-02,  2.7173e-02, -1.0763e-01,\n",
            "        -3.9793e-02,  7.8206e-02, -1.5374e-04,  3.0301e-02,  6.6848e-02,\n",
            "         1.3905e-02,  7.6456e-02, -4.8894e-02,  1.1290e-01,  2.7344e-05,\n",
            "         1.3682e-02,  7.4568e-02, -9.7389e-02, -3.0083e-02,  1.1224e-01,\n",
            "        -5.2071e-03,  4.0007e-03,  9.1141e-02,  8.1912e-02, -3.2884e-02,\n",
            "        -1.1527e-01,  9.0644e-02], requires_grad=True))\n",
            "('clf.classifier.4.weight', Parameter containing:\n",
            "tensor([[-0.0299, -0.1432,  0.0212, -0.0384,  0.0662,  0.0624,  0.0540, -0.0642,\n",
            "          0.1118, -0.1042,  0.0848,  0.1603, -0.0040,  0.0146,  0.0028,  0.0746,\n",
            "          0.1094,  0.1219,  0.1028,  0.1293, -0.0090,  0.1711,  0.1111, -0.0768,\n",
            "         -0.1556, -0.0846,  0.0657,  0.0950, -0.1170,  0.1111,  0.0873,  0.0759],\n",
            "        [ 0.1150, -0.1406, -0.0857, -0.0716, -0.0713, -0.1667, -0.0899,  0.0192,\n",
            "         -0.1340,  0.1650,  0.1594,  0.0748,  0.0710,  0.0772,  0.1268,  0.0587,\n",
            "         -0.1083, -0.0497,  0.0397, -0.1423,  0.1657, -0.0074,  0.0869,  0.0023,\n",
            "         -0.0942,  0.1592, -0.0964,  0.1543,  0.1596,  0.0769, -0.1632, -0.1392],\n",
            "        [ 0.1525,  0.0691, -0.1529, -0.1464, -0.1100,  0.0867, -0.0389, -0.1105,\n",
            "         -0.1236,  0.1135,  0.0466,  0.0664, -0.0591,  0.1053, -0.1098, -0.0680,\n",
            "          0.1396,  0.1326, -0.0241, -0.0630,  0.1087,  0.0814, -0.1501,  0.0069,\n",
            "         -0.0080, -0.1290,  0.1739,  0.0296, -0.1678, -0.0188, -0.0065,  0.1381],\n",
            "        [ 0.1715, -0.0481,  0.0010, -0.0723, -0.0408,  0.1167, -0.0398, -0.1416,\n",
            "          0.0684, -0.0783,  0.1619,  0.1657, -0.1310,  0.0712, -0.1684, -0.0612,\n",
            "          0.0451, -0.1699,  0.0988, -0.0808,  0.0337,  0.1634,  0.1017, -0.1268,\n",
            "         -0.1124,  0.0216, -0.1552, -0.1310, -0.1103, -0.0779, -0.1001,  0.0331],\n",
            "        [ 0.1445,  0.0024, -0.0357,  0.0813, -0.0372, -0.1559,  0.1296, -0.0942,\n",
            "          0.1281, -0.0563,  0.0895, -0.0424,  0.0552, -0.0356,  0.0702, -0.0781,\n",
            "          0.1373, -0.0555, -0.1072,  0.0264,  0.0936, -0.0784, -0.0656,  0.0836,\n",
            "         -0.0071,  0.1477, -0.0051, -0.0039, -0.1132,  0.0360, -0.0927,  0.0328],\n",
            "        [ 0.1187,  0.0569, -0.0928,  0.1714,  0.0445, -0.0445,  0.0695, -0.0978,\n",
            "          0.0374, -0.1405,  0.0575, -0.1055, -0.0038, -0.0378, -0.0041, -0.0565,\n",
            "         -0.1311, -0.1696, -0.0976, -0.1163,  0.1690, -0.1250, -0.1417,  0.1186,\n",
            "          0.0276,  0.0091, -0.0768,  0.0671,  0.0445,  0.1286,  0.0854,  0.0344],\n",
            "        [ 0.0635,  0.0824, -0.0191, -0.0534,  0.1634,  0.0730,  0.1642, -0.0726,\n",
            "         -0.1161, -0.0365, -0.0011,  0.0234,  0.1738,  0.0164,  0.1507, -0.0295,\n",
            "          0.1359,  0.1607,  0.1209, -0.0473, -0.0879,  0.0151, -0.1171, -0.0701,\n",
            "          0.1049,  0.0768,  0.1329,  0.0673,  0.1058,  0.1128, -0.0907, -0.0978],\n",
            "        [-0.1591, -0.1390,  0.1471, -0.0571, -0.0615, -0.0741, -0.0797,  0.0012,\n",
            "         -0.1347,  0.0294, -0.1287, -0.0401,  0.1000,  0.0371, -0.1564, -0.1409,\n",
            "          0.0525, -0.0214,  0.0214,  0.0290,  0.1141,  0.0759,  0.0539, -0.1393,\n",
            "         -0.1645, -0.0239,  0.0399,  0.0254,  0.1447, -0.1534, -0.0563,  0.0824],\n",
            "        [ 0.1260, -0.0458,  0.0670,  0.0620, -0.1186,  0.0459, -0.0875, -0.1006,\n",
            "         -0.0919, -0.1198,  0.0554, -0.0237,  0.1216,  0.1334, -0.1765,  0.0632,\n",
            "         -0.0807,  0.1574,  0.0519,  0.0662, -0.1684,  0.0687,  0.0928, -0.0916,\n",
            "          0.0694, -0.1366, -0.0765, -0.0231,  0.1443, -0.0631,  0.1543, -0.0705],\n",
            "        [ 0.1200,  0.1402,  0.1184,  0.0933, -0.0745,  0.0807, -0.0624, -0.0261,\n",
            "         -0.1510,  0.0591, -0.1171, -0.1416,  0.0730,  0.1577,  0.1150,  0.1384,\n",
            "         -0.1675, -0.0037, -0.1185, -0.0690, -0.1738,  0.0578,  0.0943,  0.0314,\n",
            "          0.0224, -0.1095, -0.0150,  0.1026, -0.0349,  0.0568,  0.1722, -0.1689]],\n",
            "       requires_grad=True))\n",
            "('clf.classifier.4.bias', Parameter containing:\n",
            "tensor([-0.1096, -0.1097,  0.0579, -0.1669, -0.0374, -0.0926,  0.0973,  0.0276,\n",
            "         0.0987, -0.1097], requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU4XmkDMIHkC",
        "outputId": "c8ac146e-2362-43b9-b8ec-5baaab1e3965"
      },
      "source": [
        "model3.state_dict()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('encoder.encoder.0.weight',\n",
              "              tensor([[ 3.2411e-02, -3.2762e-02,  2.6795e-02,  ...,  2.7951e-02,\n",
              "                        7.7435e-05,  2.1013e-02],\n",
              "                      [ 2.6341e-02,  2.0946e-02, -4.3794e-03,  ..., -2.7978e-02,\n",
              "                       -3.0247e-02, -2.8799e-02],\n",
              "                      [ 3.6207e-03, -1.1272e-02, -1.6410e-02,  ...,  3.1289e-02,\n",
              "                       -1.5675e-02, -2.7952e-02],\n",
              "                      ...,\n",
              "                      [ 1.3151e-02,  1.7483e-02, -2.0752e-02,  ...,  7.6169e-03,\n",
              "                       -9.5549e-03,  1.3336e-02],\n",
              "                      [ 6.5785e-03, -1.6895e-02, -2.6035e-02,  ...,  1.5044e-02,\n",
              "                       -1.9176e-02, -3.3738e-02],\n",
              "                      [-2.8310e-02,  6.3773e-03, -3.0421e-04,  ..., -2.5119e-02,\n",
              "                       -6.2974e-04, -2.0374e-02]])),\n",
              "             ('encoder.encoder.0.bias',\n",
              "              tensor([-0.0262,  0.0281,  0.0184,  0.0139,  0.0242, -0.0137, -0.0067, -0.0322,\n",
              "                      -0.0218,  0.0079,  0.0260,  0.0105,  0.0320, -0.0328, -0.0320,  0.0268,\n",
              "                       0.0121, -0.0013, -0.0222,  0.0302, -0.0154, -0.0069, -0.0263,  0.0254,\n",
              "                      -0.0011, -0.0350, -0.0061, -0.0127, -0.0304, -0.0283, -0.0231,  0.0342,\n",
              "                      -0.0128, -0.0160, -0.0057,  0.0264, -0.0014,  0.0302,  0.0216,  0.0079,\n",
              "                      -0.0070, -0.0081, -0.0251,  0.0147, -0.0126,  0.0346, -0.0128,  0.0124,\n",
              "                       0.0335, -0.0217,  0.0355, -0.0094, -0.0081,  0.0316, -0.0100,  0.0248,\n",
              "                       0.0211,  0.0195, -0.0239,  0.0270,  0.0091, -0.0065, -0.0275,  0.0032,\n",
              "                       0.0353,  0.0050, -0.0335, -0.0011, -0.0181,  0.0106,  0.0203, -0.0203,\n",
              "                       0.0022,  0.0209,  0.0163,  0.0092, -0.0014, -0.0199, -0.0071,  0.0325,\n",
              "                      -0.0084, -0.0219, -0.0225,  0.0027, -0.0093,  0.0324, -0.0123,  0.0324,\n",
              "                      -0.0250,  0.0345, -0.0339, -0.0253,  0.0103, -0.0049,  0.0191,  0.0044,\n",
              "                       0.0250, -0.0063, -0.0147,  0.0169, -0.0299, -0.0131, -0.0021,  0.0128,\n",
              "                      -0.0016,  0.0176,  0.0159,  0.0167,  0.0086, -0.0224, -0.0152, -0.0146,\n",
              "                       0.0293, -0.0054, -0.0116,  0.0140,  0.0238, -0.0217,  0.0120,  0.0065,\n",
              "                       0.0154, -0.0251, -0.0055,  0.0138,  0.0183, -0.0175,  0.0143, -0.0315])),\n",
              "             ('encoder.encoder.2.weight',\n",
              "              tensor([[-0.0270, -0.0720,  0.0577,  ..., -0.0673,  0.0664,  0.0361],\n",
              "                      [ 0.0694,  0.0765, -0.0355,  ..., -0.0428,  0.0273, -0.0709],\n",
              "                      [ 0.0473,  0.0192,  0.0251,  ...,  0.0095, -0.0233, -0.0807],\n",
              "                      ...,\n",
              "                      [ 0.0279, -0.0269,  0.0067,  ..., -0.0544,  0.0216, -0.0515],\n",
              "                      [ 0.0732, -0.0795, -0.0019,  ..., -0.0107, -0.0523, -0.0365],\n",
              "                      [-0.0786, -0.0238, -0.0788,  ...,  0.0332, -0.0242, -0.0470]])),\n",
              "             ('encoder.encoder.2.bias',\n",
              "              tensor([-0.0643, -0.0848, -0.0247, -0.0050,  0.0421, -0.0798,  0.0653,  0.0817,\n",
              "                       0.0609,  0.0818,  0.0846,  0.0761, -0.0080, -0.0406, -0.0332, -0.0267,\n",
              "                       0.0714, -0.0670,  0.0062,  0.0522, -0.0032,  0.0441,  0.0317, -0.0012,\n",
              "                       0.0285, -0.0377,  0.0754,  0.0728, -0.0199,  0.0061, -0.0650,  0.0417,\n",
              "                       0.0342, -0.0543,  0.0459,  0.0411, -0.0395, -0.0237, -0.0338, -0.0746,\n",
              "                      -0.0697,  0.0623, -0.0119,  0.0521,  0.0039,  0.0760,  0.0246,  0.0721,\n",
              "                      -0.0051,  0.0290,  0.0781,  0.0084, -0.0240,  0.0175,  0.0340,  0.0518,\n",
              "                       0.0318, -0.0167, -0.0822, -0.0613, -0.0032, -0.0589, -0.0381, -0.0664])),\n",
              "             ('encoder.encoder.4.weight',\n",
              "              tensor([[ 0.0773,  0.0266, -0.0019,  ..., -0.0008,  0.1074, -0.0488],\n",
              "                      [ 0.0225, -0.1235,  0.0113,  ...,  0.1168,  0.0634,  0.0063],\n",
              "                      [ 0.0795,  0.0210, -0.1163,  ..., -0.0646,  0.0982,  0.1189],\n",
              "                      ...,\n",
              "                      [-0.0729, -0.0424,  0.0138,  ...,  0.0906, -0.0575, -0.0190],\n",
              "                      [ 0.0407,  0.0766, -0.1144,  ...,  0.1121,  0.0213,  0.0889],\n",
              "                      [-0.0913,  0.0319, -0.0947,  ...,  0.0553, -0.0511, -0.0220]])),\n",
              "             ('encoder.encoder.4.bias',\n",
              "              tensor([ 0.0699,  0.1092, -0.0347, -0.0365, -0.0465, -0.0210, -0.0346,  0.0671,\n",
              "                       0.0268, -0.0722, -0.0454,  0.0153,  0.0738, -0.1127, -0.0383,  0.0738])),\n",
              "             ('encoder.encoder.6.weight',\n",
              "              tensor([[ 0.1846, -0.1640,  0.0316,  0.2139, -0.0912, -0.1281,  0.2145,  0.0058,\n",
              "                        0.0156, -0.1693,  0.1104, -0.0610, -0.0849,  0.0546,  0.1146,  0.1225],\n",
              "                      [-0.1991,  0.0109, -0.1019,  0.1443,  0.1602,  0.1935,  0.0864,  0.1151,\n",
              "                       -0.0014, -0.1267, -0.2489,  0.0742,  0.0683, -0.0831, -0.0046,  0.1868],\n",
              "                      [ 0.1719,  0.0183,  0.0079,  0.1067, -0.1201, -0.0707, -0.1930,  0.0014,\n",
              "                        0.0425,  0.2463, -0.0616, -0.1337, -0.0889, -0.1849,  0.0453, -0.0107],\n",
              "                      [-0.2072, -0.1623,  0.2437, -0.1036,  0.0843,  0.0197,  0.2192,  0.0226,\n",
              "                       -0.0784, -0.0584,  0.1230, -0.0277,  0.1151,  0.2233, -0.0190,  0.0860],\n",
              "                      [-0.0620, -0.1981,  0.2426, -0.0677,  0.1520, -0.1395, -0.1532, -0.0859,\n",
              "                       -0.1532, -0.0349,  0.0572, -0.0796, -0.1324, -0.2031, -0.1710,  0.1221],\n",
              "                      [ 0.1293,  0.1037, -0.1337, -0.0920,  0.0150,  0.1877, -0.2175,  0.0525,\n",
              "                        0.2287,  0.0682,  0.1430, -0.2243, -0.1757,  0.1898, -0.1967,  0.0913],\n",
              "                      [-0.2081, -0.0023, -0.1077, -0.1744, -0.0322, -0.1875,  0.0196, -0.0611,\n",
              "                        0.1185,  0.0980, -0.0508, -0.0231, -0.2009,  0.0084, -0.0549, -0.0647],\n",
              "                      [-0.1468, -0.0169, -0.1066, -0.0540,  0.0310, -0.0974,  0.2256, -0.0800,\n",
              "                       -0.2322, -0.0776, -0.1866,  0.1261,  0.2092, -0.0947, -0.1636,  0.1385]])),\n",
              "             ('encoder.encoder.6.bias',\n",
              "              tensor([-0.0068, -0.1970,  0.0877, -0.0626,  0.0547, -0.2299, -0.0401, -0.1905])),\n",
              "             ('clf.classifier.0.weight',\n",
              "              tensor([[ 3.1830e-01,  2.8991e-01,  3.0021e-01, -1.1534e-01,  1.6069e-02,\n",
              "                       -1.7974e-01, -9.1215e-03, -3.1097e-01],\n",
              "                      [ 2.4035e-01,  1.5866e-01, -1.8113e-01, -2.8889e-02, -1.8389e-01,\n",
              "                       -3.0275e-01,  1.2645e-01,  2.5938e-01],\n",
              "                      [ 3.1172e-01, -2.2684e-02, -1.4949e-01,  2.0782e-01, -1.6584e-01,\n",
              "                        1.6988e-01, -4.4617e-02,  3.3408e-01],\n",
              "                      [ 4.7821e-02,  2.4349e-01,  2.7101e-02, -3.1925e-01,  3.1347e-01,\n",
              "                       -4.7301e-02, -1.4643e-01,  9.6862e-02],\n",
              "                      [-3.0706e-01,  2.3759e-01,  9.6529e-02,  1.5761e-01,  9.6702e-02,\n",
              "                        2.7747e-01,  3.3367e-01, -2.3305e-01],\n",
              "                      [ 2.1321e-01, -3.0098e-01,  9.7698e-02, -1.4870e-01,  2.3599e-01,\n",
              "                       -1.6699e-01, -2.7114e-01, -2.1696e-01],\n",
              "                      [ 2.9188e-01,  2.4003e-01,  1.0225e-01, -1.6349e-02,  2.5028e-01,\n",
              "                       -7.1145e-02,  1.0620e-01, -7.6666e-02],\n",
              "                      [-2.8395e-01, -2.8633e-01, -2.3362e-02, -2.7411e-01, -3.0247e-01,\n",
              "                       -7.1638e-02,  2.4725e-01,  3.1917e-01],\n",
              "                      [ 2.4574e-01,  2.2858e-01,  1.4110e-01,  1.0816e-01,  3.0159e-01,\n",
              "                        1.4601e-01, -7.1594e-02,  2.9091e-01],\n",
              "                      [ 2.6672e-01, -1.0567e-01, -2.0884e-01, -2.1968e-01,  3.2151e-01,\n",
              "                       -1.0623e-01,  1.8015e-01, -4.8628e-02],\n",
              "                      [ 3.0546e-01,  8.2465e-02,  2.1653e-01,  1.9795e-01, -3.2201e-01,\n",
              "                       -2.6598e-01, -2.9498e-01, -1.8083e-02],\n",
              "                      [ 7.3822e-02, -1.0965e-01,  8.7952e-02,  2.2088e-01,  1.6442e-01,\n",
              "                       -3.4937e-01, -6.9331e-02, -2.2546e-01],\n",
              "                      [ 2.8925e-01, -3.8343e-02, -7.1636e-02,  2.8074e-01,  2.9673e-02,\n",
              "                        2.8186e-01, -3.2141e-01,  1.3215e-01],\n",
              "                      [-2.1816e-01,  1.1700e-01, -1.7484e-01,  1.4522e-01,  2.0100e-01,\n",
              "                       -7.7958e-02,  7.1406e-03,  2.8807e-01],\n",
              "                      [ 2.3962e-01, -2.9025e-02, -2.1134e-01,  9.8070e-02, -1.5031e-01,\n",
              "                        2.1071e-01, -1.9174e-01,  2.5852e-01],\n",
              "                      [ 3.2829e-01, -1.5716e-01,  3.1636e-01,  7.1108e-02,  2.6209e-01,\n",
              "                       -3.0395e-01,  5.5046e-02,  1.0414e-01],\n",
              "                      [-2.8491e-01,  2.4249e-01, -3.0796e-01,  1.6389e-01, -1.3327e-01,\n",
              "                        2.9043e-02,  7.3633e-02, -2.9342e-01],\n",
              "                      [-3.3870e-01, -2.9686e-01,  1.6663e-01,  2.0385e-01,  2.2308e-01,\n",
              "                       -7.2210e-02, -8.6672e-02, -3.0264e-01],\n",
              "                      [ 3.3695e-01,  3.5340e-01, -8.2371e-02,  2.1707e-02, -8.3965e-02,\n",
              "                       -1.1274e-01, -1.2619e-02,  2.0609e-01],\n",
              "                      [ 7.2594e-02,  4.5698e-02, -1.0520e-01,  2.3469e-01,  6.5853e-02,\n",
              "                        2.0197e-01,  1.8232e-01,  2.2270e-01],\n",
              "                      [-1.4048e-01, -2.0995e-01,  2.5691e-01, -3.0160e-01, -3.4220e-01,\n",
              "                        2.5053e-02,  1.4218e-02,  3.9203e-02],\n",
              "                      [-1.8110e-01,  9.6097e-02, -4.8783e-02,  4.4498e-02,  3.1577e-01,\n",
              "                       -2.0273e-01,  2.6307e-01, -3.4398e-01],\n",
              "                      [ 7.5404e-02, -2.2157e-01, -4.0056e-02, -8.4497e-02,  2.0312e-01,\n",
              "                        2.0009e-01, -1.6628e-01,  1.6400e-01],\n",
              "                      [-3.3123e-01,  3.4002e-01,  3.2952e-01,  3.4448e-01,  2.7821e-01,\n",
              "                       -3.8466e-02,  2.1608e-01, -1.7977e-01],\n",
              "                      [ 2.6505e-01,  3.1227e-01,  1.7007e-02,  2.1312e-01, -1.0191e-01,\n",
              "                       -6.5847e-02,  1.4135e-01, -3.1466e-01],\n",
              "                      [ 3.9348e-02, -3.2757e-01, -1.7510e-01,  1.2293e-01, -5.3410e-02,\n",
              "                        1.9315e-01, -4.7873e-02,  4.7216e-02],\n",
              "                      [-2.1090e-01,  3.1483e-01,  2.3067e-01, -1.4529e-01,  2.3484e-01,\n",
              "                        1.6026e-01, -2.3848e-01,  1.8547e-01],\n",
              "                      [-2.6713e-01, -3.3777e-01,  2.0780e-01,  1.2676e-01, -2.6863e-02,\n",
              "                       -8.1756e-02, -2.4744e-01, -3.0583e-02],\n",
              "                      [-1.9140e-01,  1.7813e-01, -1.6730e-01,  2.8966e-01,  2.3973e-01,\n",
              "                       -3.3440e-01,  3.4864e-01, -9.1523e-02],\n",
              "                      [ 1.5784e-01,  1.1571e-01,  2.2489e-01, -1.1647e-01, -2.7661e-01,\n",
              "                       -1.7318e-01, -1.2689e-01,  3.0358e-01],\n",
              "                      [ 1.3433e-01, -2.3652e-01,  7.6723e-02,  1.7323e-01,  2.6786e-02,\n",
              "                       -2.5338e-02,  2.1882e-01, -2.4851e-01],\n",
              "                      [ 5.1629e-02, -2.1697e-01, -1.6358e-01, -2.8939e-01, -2.4904e-01,\n",
              "                        4.1455e-03, -3.2850e-01,  2.9004e-01],\n",
              "                      [ 2.4862e-01, -2.5017e-02, -3.2456e-01,  2.9661e-01,  1.0771e-01,\n",
              "                        1.4182e-01,  2.6752e-01, -1.6909e-01],\n",
              "                      [ 2.9759e-01, -2.4681e-01,  1.2899e-01,  1.3119e-01, -2.2432e-01,\n",
              "                        1.7786e-01,  3.0358e-01,  4.3139e-02],\n",
              "                      [-1.7385e-01,  1.5385e-01, -1.9838e-01, -1.8557e-01,  2.6023e-01,\n",
              "                       -3.5015e-01,  3.3454e-03,  2.2125e-01],\n",
              "                      [ 1.5151e-01, -3.2744e-01,  1.1958e-02,  1.5577e-01,  2.4501e-01,\n",
              "                       -1.1818e-01, -1.5600e-01,  9.7608e-02],\n",
              "                      [ 2.1846e-01,  6.3389e-02, -9.5354e-02, -3.3015e-01,  1.4782e-01,\n",
              "                       -1.8445e-01, -1.7265e-01, -8.4859e-02],\n",
              "                      [ 1.4881e-01, -1.5623e-01,  3.0269e-01,  2.8562e-01,  1.0443e-01,\n",
              "                       -4.4350e-02,  2.8126e-02, -1.1049e-01],\n",
              "                      [-1.9836e-01,  9.5609e-02, -2.9599e-01,  2.2475e-01,  7.6585e-02,\n",
              "                        1.5829e-01,  1.7652e-01,  1.3418e-01],\n",
              "                      [ 9.3959e-02, -2.1443e-01, -2.8477e-01,  2.0006e-01, -3.0604e-01,\n",
              "                        2.5221e-01, -8.8913e-02, -1.8628e-01],\n",
              "                      [ 2.3076e-01,  3.0825e-02,  2.6367e-01,  3.1137e-01, -2.8029e-01,\n",
              "                        9.4367e-02, -2.2578e-01, -2.5711e-01],\n",
              "                      [ 1.5681e-01, -1.1684e-01, -2.3237e-01, -8.4147e-02, -2.7953e-01,\n",
              "                       -2.6627e-01,  2.8395e-01,  1.0315e-02],\n",
              "                      [-1.4985e-01, -1.7040e-01,  2.8238e-04, -1.6290e-01, -1.0144e-02,\n",
              "                        1.0813e-01,  2.0771e-01,  1.8523e-01],\n",
              "                      [-1.8567e-02, -2.9213e-01, -1.2184e-01, -5.6427e-02,  2.6022e-01,\n",
              "                       -1.5267e-01,  2.0600e-01,  2.5785e-01],\n",
              "                      [ 2.0454e-01,  6.6945e-02, -7.1581e-02, -1.9927e-01,  1.0849e-01,\n",
              "                        2.2279e-01, -1.7317e-01, -2.6516e-01],\n",
              "                      [ 2.8074e-01,  2.2929e-01, -7.5863e-02,  1.0769e-01,  2.5462e-01,\n",
              "                        6.6055e-02, -6.0269e-02, -1.5054e-01],\n",
              "                      [ 1.4087e-01,  2.0708e-03,  4.2213e-02, -1.6587e-01, -2.0257e-01,\n",
              "                        1.1897e-01, -9.6707e-02,  6.4563e-02],\n",
              "                      [ 3.3687e-01, -1.0036e-01, -1.4607e-01,  1.8272e-01,  5.6975e-02,\n",
              "                       -2.3193e-01,  1.7019e-01, -2.8375e-01],\n",
              "                      [ 3.1850e-01, -2.4154e-01, -2.2006e-02, -2.1003e-01,  3.6923e-02,\n",
              "                       -1.0582e-01,  6.8674e-02,  7.5434e-02],\n",
              "                      [ 3.1838e-01, -1.7650e-01,  3.4994e-01, -1.6512e-01, -3.4435e-01,\n",
              "                       -3.1727e-01, -9.2672e-02,  2.2799e-01],\n",
              "                      [ 2.9751e-02, -2.0267e-01,  2.5526e-01,  3.4799e-01,  3.5267e-02,\n",
              "                       -2.8892e-01,  8.3137e-02,  7.6205e-02],\n",
              "                      [ 2.6159e-01,  5.7226e-02, -3.2717e-02, -8.0238e-02, -1.0281e-01,\n",
              "                        1.5710e-01, -2.9203e-01,  2.3012e-01],\n",
              "                      [-1.9112e-01, -2.7805e-01, -1.1762e-01,  3.4347e-02,  2.2232e-01,\n",
              "                        2.9453e-01, -2.0084e-01,  2.8816e-01],\n",
              "                      [-8.5081e-02,  2.8040e-02,  3.2902e-01, -1.6733e-01,  1.7073e-01,\n",
              "                       -3.1137e-01, -7.7327e-02, -2.2437e-01],\n",
              "                      [-8.0047e-02,  2.2035e-01, -3.0629e-01, -8.8741e-02, -1.5570e-01,\n",
              "                       -3.5097e-01, -1.0531e-01, -2.6269e-01],\n",
              "                      [ 2.2530e-01,  1.4838e-01, -2.2057e-01, -2.8509e-01, -1.1519e-01,\n",
              "                        3.5521e-03,  1.7814e-01,  3.3986e-01],\n",
              "                      [-2.5215e-02, -1.8327e-01,  3.6031e-02,  2.6418e-01,  6.6018e-02,\n",
              "                        2.0929e-01, -2.4148e-01, -1.8940e-01],\n",
              "                      [ 3.4802e-01,  6.9092e-02,  7.9455e-02, -1.5453e-01,  2.5118e-01,\n",
              "                        2.5874e-01,  2.9017e-01,  9.3104e-02],\n",
              "                      [ 4.5208e-02, -1.6257e-01,  1.3984e-01,  5.2422e-02,  2.8833e-01,\n",
              "                       -7.8469e-04, -1.1697e-01,  1.7210e-01],\n",
              "                      [ 2.2087e-01, -2.2227e-01, -1.5415e-01, -3.4038e-01,  1.7859e-01,\n",
              "                        4.4755e-02,  2.7669e-01, -3.2278e-01],\n",
              "                      [-1.2093e-02, -3.2637e-02,  1.0281e-01,  2.2605e-01,  2.2776e-01,\n",
              "                        3.8029e-02, -1.9131e-01, -1.4259e-01],\n",
              "                      [-1.1678e-01,  2.3294e-01,  1.9760e-01, -1.3504e-01, -2.0682e-01,\n",
              "                        2.4412e-01, -1.7884e-01,  2.8776e-01],\n",
              "                      [-2.9910e-01, -2.1482e-01,  3.4747e-01,  2.9484e-01, -3.4042e-01,\n",
              "                        6.0074e-02,  8.9609e-02, -1.9401e-01],\n",
              "                      [-2.9563e-01, -7.2984e-02, -6.9098e-02,  3.4923e-01,  2.1460e-01,\n",
              "                       -1.3671e-01,  3.3026e-01, -2.0934e-01]])),\n",
              "             ('clf.classifier.0.bias',\n",
              "              tensor([ 0.0074,  0.1870, -0.2587, -0.1204, -0.1225, -0.2733, -0.2478, -0.1417,\n",
              "                       0.3355, -0.1675,  0.2610,  0.0381, -0.2461, -0.1002, -0.1918,  0.1648,\n",
              "                       0.2887, -0.0021,  0.1046,  0.0663,  0.0881,  0.3297,  0.1739, -0.2125,\n",
              "                       0.0344,  0.2610,  0.2841,  0.2122,  0.3471,  0.0506, -0.0464, -0.2025,\n",
              "                      -0.2675,  0.0953,  0.2792, -0.2984, -0.2249, -0.2780,  0.2686,  0.3182,\n",
              "                       0.1331,  0.2870, -0.2279,  0.2864,  0.3496,  0.0013, -0.1494,  0.0947,\n",
              "                      -0.2157, -0.0719, -0.3194,  0.2167, -0.2710,  0.2415,  0.0256, -0.0280,\n",
              "                       0.2683, -0.2525, -0.1877,  0.2011, -0.3350, -0.2991,  0.2582, -0.0554])),\n",
              "             ('clf.classifier.2.weight',\n",
              "              tensor([[-0.0212,  0.0701, -0.0431,  ..., -0.0348, -0.1196, -0.0959],\n",
              "                      [ 0.0047,  0.0673,  0.0688,  ..., -0.1237,  0.0421,  0.0626],\n",
              "                      [-0.0969,  0.1134,  0.0755,  ..., -0.0157,  0.0602, -0.0672],\n",
              "                      ...,\n",
              "                      [-0.0744, -0.0398, -0.0905,  ...,  0.1060, -0.0871,  0.0604],\n",
              "                      [-0.0555,  0.0266, -0.0917,  ...,  0.1021,  0.0828,  0.0085],\n",
              "                      [-0.0570, -0.0133, -0.0255,  ..., -0.0159, -0.0585, -0.1216]])),\n",
              "             ('clf.classifier.2.bias',\n",
              "              tensor([-2.3688e-03,  3.4431e-02, -5.7096e-02, -4.2269e-02, -6.3928e-02,\n",
              "                       1.0553e-01, -3.5105e-02,  8.9648e-02,  2.7173e-02, -1.0763e-01,\n",
              "                      -3.9793e-02,  7.8206e-02, -1.5374e-04,  3.0301e-02,  6.6848e-02,\n",
              "                       1.3905e-02,  7.6456e-02, -4.8894e-02,  1.1290e-01,  2.7344e-05,\n",
              "                       1.3682e-02,  7.4568e-02, -9.7389e-02, -3.0083e-02,  1.1224e-01,\n",
              "                      -5.2071e-03,  4.0007e-03,  9.1141e-02,  8.1912e-02, -3.2884e-02,\n",
              "                      -1.1527e-01,  9.0644e-02])),\n",
              "             ('clf.classifier.4.weight',\n",
              "              tensor([[-0.0299, -0.1432,  0.0212, -0.0384,  0.0662,  0.0624,  0.0540, -0.0642,\n",
              "                        0.1118, -0.1042,  0.0848,  0.1603, -0.0040,  0.0146,  0.0028,  0.0746,\n",
              "                        0.1094,  0.1219,  0.1028,  0.1293, -0.0090,  0.1711,  0.1111, -0.0768,\n",
              "                       -0.1556, -0.0846,  0.0657,  0.0950, -0.1170,  0.1111,  0.0873,  0.0759],\n",
              "                      [ 0.1150, -0.1406, -0.0857, -0.0716, -0.0713, -0.1667, -0.0899,  0.0192,\n",
              "                       -0.1340,  0.1650,  0.1594,  0.0748,  0.0710,  0.0772,  0.1268,  0.0587,\n",
              "                       -0.1083, -0.0497,  0.0397, -0.1423,  0.1657, -0.0074,  0.0869,  0.0023,\n",
              "                       -0.0942,  0.1592, -0.0964,  0.1543,  0.1596,  0.0769, -0.1632, -0.1392],\n",
              "                      [ 0.1525,  0.0691, -0.1529, -0.1464, -0.1100,  0.0867, -0.0389, -0.1105,\n",
              "                       -0.1236,  0.1135,  0.0466,  0.0664, -0.0591,  0.1053, -0.1098, -0.0680,\n",
              "                        0.1396,  0.1326, -0.0241, -0.0630,  0.1087,  0.0814, -0.1501,  0.0069,\n",
              "                       -0.0080, -0.1290,  0.1739,  0.0296, -0.1678, -0.0188, -0.0065,  0.1381],\n",
              "                      [ 0.1715, -0.0481,  0.0010, -0.0723, -0.0408,  0.1167, -0.0398, -0.1416,\n",
              "                        0.0684, -0.0783,  0.1619,  0.1657, -0.1310,  0.0712, -0.1684, -0.0612,\n",
              "                        0.0451, -0.1699,  0.0988, -0.0808,  0.0337,  0.1634,  0.1017, -0.1268,\n",
              "                       -0.1124,  0.0216, -0.1552, -0.1310, -0.1103, -0.0779, -0.1001,  0.0331],\n",
              "                      [ 0.1445,  0.0024, -0.0357,  0.0813, -0.0372, -0.1559,  0.1296, -0.0942,\n",
              "                        0.1281, -0.0563,  0.0895, -0.0424,  0.0552, -0.0356,  0.0702, -0.0781,\n",
              "                        0.1373, -0.0555, -0.1072,  0.0264,  0.0936, -0.0784, -0.0656,  0.0836,\n",
              "                       -0.0071,  0.1477, -0.0051, -0.0039, -0.1132,  0.0360, -0.0927,  0.0328],\n",
              "                      [ 0.1187,  0.0569, -0.0928,  0.1714,  0.0445, -0.0445,  0.0695, -0.0978,\n",
              "                        0.0374, -0.1405,  0.0575, -0.1055, -0.0038, -0.0378, -0.0041, -0.0565,\n",
              "                       -0.1311, -0.1696, -0.0976, -0.1163,  0.1690, -0.1250, -0.1417,  0.1186,\n",
              "                        0.0276,  0.0091, -0.0768,  0.0671,  0.0445,  0.1286,  0.0854,  0.0344],\n",
              "                      [ 0.0635,  0.0824, -0.0191, -0.0534,  0.1634,  0.0730,  0.1642, -0.0726,\n",
              "                       -0.1161, -0.0365, -0.0011,  0.0234,  0.1738,  0.0164,  0.1507, -0.0295,\n",
              "                        0.1359,  0.1607,  0.1209, -0.0473, -0.0879,  0.0151, -0.1171, -0.0701,\n",
              "                        0.1049,  0.0768,  0.1329,  0.0673,  0.1058,  0.1128, -0.0907, -0.0978],\n",
              "                      [-0.1591, -0.1390,  0.1471, -0.0571, -0.0615, -0.0741, -0.0797,  0.0012,\n",
              "                       -0.1347,  0.0294, -0.1287, -0.0401,  0.1000,  0.0371, -0.1564, -0.1409,\n",
              "                        0.0525, -0.0214,  0.0214,  0.0290,  0.1141,  0.0759,  0.0539, -0.1393,\n",
              "                       -0.1645, -0.0239,  0.0399,  0.0254,  0.1447, -0.1534, -0.0563,  0.0824],\n",
              "                      [ 0.1260, -0.0458,  0.0670,  0.0620, -0.1186,  0.0459, -0.0875, -0.1006,\n",
              "                       -0.0919, -0.1198,  0.0554, -0.0237,  0.1216,  0.1334, -0.1765,  0.0632,\n",
              "                       -0.0807,  0.1574,  0.0519,  0.0662, -0.1684,  0.0687,  0.0928, -0.0916,\n",
              "                        0.0694, -0.1366, -0.0765, -0.0231,  0.1443, -0.0631,  0.1543, -0.0705],\n",
              "                      [ 0.1200,  0.1402,  0.1184,  0.0933, -0.0745,  0.0807, -0.0624, -0.0261,\n",
              "                       -0.1510,  0.0591, -0.1171, -0.1416,  0.0730,  0.1577,  0.1150,  0.1384,\n",
              "                       -0.1675, -0.0037, -0.1185, -0.0690, -0.1738,  0.0578,  0.0943,  0.0314,\n",
              "                        0.0224, -0.1095, -0.0150,  0.1026, -0.0349,  0.0568,  0.1722, -0.1689]])),\n",
              "             ('clf.classifier.4.bias',\n",
              "              tensor([-0.1096, -0.1097,  0.0579, -0.1669, -0.0374, -0.0926,  0.0973,  0.0276,\n",
              "                       0.0987, -0.1097]))])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfkZsnZZIltj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsTA46SFTL_x"
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_space, mode):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(784, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, latent_space)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "             nn.Linear(latent_space, 16),\n",
        "             nn.ReLU(),\n",
        "             nn.Linear(16, 64), \n",
        "             nn.ReLU(),\n",
        "             nn.Linear(64, 128),\n",
        "             nn.ReLU(),\n",
        "             nn.Linear(128, 784),\n",
        "             nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(latent_space, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        if self.mode == 'decoder':\n",
        "            out = self.decoder(encoded)\n",
        "        elif self.mode == 'classifier':\n",
        "            out = self.classifier(encoded)\n",
        "        else:\n",
        "            print('Choose the mode of NN')\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 81,
      "outputs": []
    }
  ]
}